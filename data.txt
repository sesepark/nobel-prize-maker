
==== FILE: 온톨로지 기반 Graph RAG 실습하기.pdf ====


-- PAGE 1 --

온톨로지 기반 Graph RAG 실습하기
본 가이드는 서울대학교 학식 데이터를 활용하여, 단순한 정보 검색을 넘어 
을 이
해하고 
하는 
 시스템 구축을 목표로 한다.
코드를 작성하기 전, 우리가 다루게 될 핵심 개념인 
와 
의 본질을 먼저 이해해야 한다.
맥락(Context)
추론(Reasoning)
Graph RAG
온톨로지(Ontology)
지식 그래프
(Knowledge Graph)
1. 핵심 개념: 온톨로지(Ontology)란?
1) 정의
현실 세계의 사물(Concept)과 그들 간의 관계(Relation)를 컴퓨터가 이해할 수 있는 언어로 명시화한 
구조적 설계도.
쉽게 말해, 온톨로지는 컴퓨터에게 주는 
다. "사람은 다리가 두 개
다", "사과는 과일이다" 같은 지식을 기계가 알아들을 수 있는 포맷으로 약속한 것이다.
세상을 이해하는 사전이자 규칙서
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
1/21

-- PAGE 2 --

2) 왜 등장했는가? (탄생 배경)
온톨로지는 갑자기 튀어나온 기술이 아니다. 과거 
의 등장과 맥을 같이 한
다.
시맨틱 웹(Semantic Web)
•
 과거의 컴퓨터는 웹상의 
이라는 단어가 '먹는 사과'인지 'IT 기업 애플'인지 구
분하지 못했다.
초기의 문제:
Apple
• 해결책: "단어에 꼬리표(Tag)를 달아 의미를 정의하자."
◦이것이 발전하여, 데이터 간의 관계를 정의하고 컴퓨터끼리 지식을 주고받을 수 있게 만든 것
이 온톨로지다.
3) 왜 지금 다시 필요한가? (현대 기술의 한계 극복)
최근 온톨로지가 다시 급부상한 이유는, 현재 주류 기술인 
와 
이 가진 치명적인 약점을 보
완해 줄 유일한 대안이기 때문이다.
RDBMS
LLM
• 관계형 데이터베이스(RDBMS)의 한계
◦
 행(Row)과 열(Column)로만 표현되므로, 인간이 미리 정의하지 않은 의미를 컴
퓨터가 해석할 수 없다. (예: 학점 
가 '만점'인지 '단순 숫자'인지 모름)
구조적 경직성:
4.5
◦
 날씨 DB, 식당 DB, 지도 DB가 서로 단절되어 있다. 이를 연결하려면 개발
자가 매번 복잡한 
(서로 다른 DB를 연결해주는 데이터베이스 조회 문법)을 짜야 하는 
비효율이 발생한다. 온톨로지를 사용하면 모든 DB가 
된다.
데이터 사일로(Silo):
JOIN 문
하나의 관계망 안에서 통합
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
2/21

-- PAGE 3 --

• 생성형 AI (LLM)의 한계
◦
 학습하지 않은 데이터(우리 학교 오늘 메뉴)에 대해 질문받으
면, 그럴듯한 거짓말을 만들어낸다.
할루시네이션(Hallucination):
◦
 왜 그 식당을 추천했는지 논리적인 근거를 설명하지 못한다.
블랙박스(Black Box):
• 벡터 검색(Vector RAG)의 한계
◦
 "비 오는 날"과 "파전"의 인과관계를 이해하는 것이 아니라, 단순히 두 단어가 같
이 자주 등장했는지만 본다.
단순 유사도:
⇒ 현대적인 관점에서 온톨로지의 역할 
온톨로지는 
한다. 이를 통해 AI는 거짓말을 하지 않고, 그
래프의 연결 관계를 근거로 
라고 설명할 수 있게 된다.
AI에게 논리적 사고의 틀과 팩트(Fact)를 제공
"A라서 B이고, B라서 C이다"
4) 흔한 오해와 진실
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
3/21

-- PAGE 4 --

• "온톨로지는 세상의 모든 지식을 연결해 만능 AI를 만드는 것이다?”
⇒ 아니다.
◦온톨로지는 "열려 있는 모든 질문(Open Domain)"에 답하기 위한 것이 아니다. 그렇게 만들 수
도 없을뿐더러 효율적이지도 않다.
◦온톨로지의 진짜 목적은 
 내에서 데이터에 
를 부
여하고 
를 만드는 틀을 제공하는 것이다.
특정 도메인(예: 학식, 법률, 의료)
합의된 의미
공유된 이해
◦기존 RDBMS와의 차이점:
▪
 데이터의 
가 주 목적이다. (잘 정리된 서류 캐비닛)
RDBMS:
효율적 저장과 조회
▪
 데이터 간의 
가 주 목적이다. (꼬리를 무는 마인드맵)
온톨로지:
관계와 맥락의 이해
2. 온톨로지 기반 지식그래프
설계도(온톨로지)만으로는 아무것도 할 수 없다. 여기에 실제 데이터(인스턴스)를 입혀야 비로소 컴퓨
터가 활용 가능한 
가 완성된다.
지식 그래프(Knowledge Graph)
지식 그래프의 개념을 더 구현적인 측면에서 이해하기 위해 실습 단계에서 우리가 파이썬을 통해 최종
적으로 생성하게 될 파일들의 정체와 문법을 먼저 명확히 이해하고 넘어가자.
1) 주요 개념 및 포맷
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
4/21

-- PAGE 5 --

1. 트리플 (Triple)
• 온톨로지에서 지식을 표현하는 가장 기본 단위(Atomic Unit)다. 
• 세상의 모든 지식을 
의 3단 구조로 쪼개어 표현한다.
주어 - 서술어 - 목적어
• 구조
◦주어(Subject) ⇒ 서술어(Predicate) ⇒ 목적어(Object)
▪
 ⇒ 
 ⇒ 
학생회관식당
위치한다
63동
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
5/21

-- PAGE 6 --

2. RDF (Resource Description Framework)
• 웹상의 모든 자원을 시맨틱(의미론적)하게 표현하기 위해 W3C에서 제정한 
이다.
국제 표준 규칙
(Framework)
◦기본적으로 위에서 설명한 
 구조를 따른다.
트리플(Triple)
◦데이터가 특정 애플리케이션(엑셀 등)에 종속되지 않고, 웹상에서 자유롭게 교환될 수 있
도록 돕는 규칙이다.
◦이 규칙(틀)에 따라 실제로 표현된 결과물이 아래에서 서술할 TTL이다. 이외에도 XML, N-
Triples, JSON-LD 등 다양한 결과물로 표현될 수 있다.
◦RDFS, OWL 등 더욱 엄밀한 제약을 갖는 규칙으로 진화할 수 있다.
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
6/21

-- PAGE 7 --

3. TTL (Turtle) 파일
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
7/21

-- PAGE 8 --

• RDF, RDFS, OWL 등의 표준 규칙을 적용하여 컴퓨터와 인간이 모두 쉽게 읽고 쓸 수 있도록 만
든 
이 바로 TTL(Turtle)이다.
실제 파일 포맷
◦XML이나 JSON보다 가독성이 좋아 온톨로지 구축 실습에서 가장 널리 사용된다.
◦실습에서는 파이썬으로 데이터를 크롤링한 후, 이 
 파일을 최종적으로 생성하여 
Graph Database(TDB, Neo4j 등)에 적재하게 된다.
.ttl
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
8/21

-- PAGE 9 --

◦이렇게 만들어진, 즉 개체와 개체 사이의 관계가 트리플의 구조를 따라 우리가 가진 모든 
데이터에 대해 구축된 순간 마침내 지식 그래프(Knowledge Graph)라 부를 수 있게 된다.
neo4j로 시각화된 ttl 파일 기반 지식 그래프
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
9/21

-- PAGE 10 --

▪흔한 오해: "온톨로지와 지식 그래프는 같은 말 아닌가요?"
⇒ 개념적으로 완전히 다르다.
•
는 데이터가 따라야 할 
다. "사람은 부모를 
가진다", "식당은 메뉴를 판다"와 같은 추상적인 규칙의 집합이다.
온톨로지(Ontology)
설계도(Schema)
•
는 그 설계도에 맞춰 실제 데이터를 채워 넣은 
이다. "이순신은 이정의 아들이다", "학생회관은 돈까스를 판다"와 
같은 구체적인 사실들의 네트워크다.
지식 그래프(Knowledge Graph)
결
과물(Instance)
• 온톨로지 없이도 지식 그래프 자체는 만들 수 있으나, 
과 같다.
설계도 없이 건물을 짓는 것
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
10/21

-- PAGE 11 --

• 실제 파일 예시
# 1. 접두어(Prefix) 정의: 긴 URL을 짧게 줄여 쓰기 위함 @prefix snu:
<http://snu.ac.kr/ontology/> . @prefix rdf: <http://www.w3.org/1999/02/22-rdf-
syntax-ns#> . @prefix xsd: <http://www.w3.org/2001/XMLSchema#> . # 2. 데이터
(Triple) 정의 # 주어(학생회관) -> 서술어(타입은) -> 목적어(식당이다) snu:StudentHall
rdf:type snu:Restaurant ; # 주어(학생회관) -> 서술어(위치한다) -> 목적어(63동에)
snu:locatedIn snu:Bldg63 . # 주어(63동) -> 서술어(가깝다) -> 목적어(정문과)
snu:Bldg63 snu:near snu:MainGate .
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
11/21

-- PAGE 12 --

.ttl로 표현된 지식 그래프
3. 온톨로지 기반 지식 그래프 구축: 실제 구현 프로세스
성공적인 구축을 위해서는 
의 3박자가 맞아야 한다. 서울
대 학식 데이터를 예시로, 단순한 데이터가 어떻게 
으로 진화하는지 단
계별로 살펴보자.
자재(데이터), 목표(질문), 설계도(온톨로지)
추론 가능한 의미 기반의 지식
데이터 수집 및 구조화 (Data Acquisition)
1) 
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
12/21

-- PAGE 13 --

가장 먼저 할 일은 지식의 재료를 모으는 것이다.
1.
에서 식당명, 메뉴, 가격 정보를 가져온다.
서울대 학식 크롤링: snuco.snu.ac.kr
2.
 KakaoMap API 를 이용해 각 식당이 위치한 '건물'의 위/경도 좌표를 확보한다.
공간 정보 확보:
3.
 수집된 데이터를 개발자와 컴퓨터 모두가 보기 편한 JSON 형태로 1차 정리하
여 데이터의 스키마를 파악한다.
1차 구조화 (JSON):
// 예시: 1차 가공된 데이터 { "restaurant": "자하연식당", "location": "자하연 건물 2층",
"menus": [ {"name": "돈까스", "price": 5000} ] }
2) 목표 질문 정의 (Defining Competency Questions)
질문 생성 Prompt
"우리가 만들 AI가 어떤 수준의 질문까지 대답해야 하는가?"를 미리 정의한다. 
이것이 핵심인데, 온톨로지는 
에 대해 근거와 답변을 함께 제공할 
수 있도록 설계되어야 한다.
우리가 반드시 받아보고 싶은 질문
모든 질문에 다 답변 가능한 온톨로지를 설계한다는 것은 아무것도 설계하지 않겠다는 것과 같다.
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
13/21

-- PAGE 14 --

• 기초 질문 (단순 조회): "오늘 학생회관 점심 메뉴 뭐 먹지?"
◦단순히 학생회관 건물에 존재하는 점심 시간대의 메뉴를 꺼내오면 되는 비교적 쉬운 질문들이
다.
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
14/21

-- PAGE 15 --

• 심화 질문 (복합 추론): "나 공대 쪽인데, 5,000원 이하로 면 요리 먹을 수 있는 곳 있어?"
◦원본 데이터의 한계:
▪데이터에는 "301동 식당", "302동 식당"만 있지, 그게 
인지는 안 적혀 있다.
"공대 쪽"
▪메뉴판에는 "라면", "잔치국수", "짜장면"만 있지, 그게 
라는 상위 분류는 없다.
"면 요리"
◦온톨로지의 역할:
▪
 "301동, 302동 
 공과대학 구역"이라는 지식을 미리 심어둔다. (
)
공간 추론:
⊂
partOf
▪
 "라면, 국수 
 면 요리"라는 음식 계층을 정의한다. (
)
의미 추론:
⊂
subClassOf
3) 온톨로지 설계도 구축 (schema.ttl)
우리가 준비한 질문들을 해결하기 위해, 데이터들이 어떻게 개념화되고 연결되어야 하는지 정의한 
를 설계한다.
지
식의 구조도
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
15/21

-- PAGE 16 --

• 설계 예시
◦
 개념은 
 개념을 포함한다.
장소(Place)
건물(Building)
◦
, 
 개념은 모두 
의 속성을 상속받
는다.
혼잡시간(BusyTime)
운영시간(OpenTime)
시간대(TimePeriod)
• 설계의 이유
◦단순히 "메뉴 보여줘"라면 엑셀 시트(Table)로 충분하다.
◦하지만 "시간(점심) + 장소(거리) + 상황(혼잡도)"가 얽힌 질문을 해결하려면, 각 데이터가 독
립적으로 존재하는 것이 아니라 서로 
되어 있어야 한다.
연결
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
16/21

-- PAGE 17 --

• 객체지향(OOP) Class와의 차이점:
◦얼핏 보면 프로그래밍의 Class 설계와 비슷해 보인다.
◦하지만 OOP가 
이 목적이라면, 온톨로지는 
과 
이 목적이다.
기능 구현(캡슐화)
의미 전달(공유)
논리적 추론
◦즉, 
와 같은 
과 
을 명시하여 컴퓨터
가 스스로 맥락을 판단하게 하는 것이 핵심이다.
"A는 B의 일종이며, C와는 배타적 관계이다"
제약 조건
규칙
더 구체적이고 구현적인 관점에서 접근해보자.
온톨로지 주로 아래와 같이 
로 나누어 설계된다.
TBox 설계, ABox 설계
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
17/21

-- PAGE 18 --

1. TBox 설계 (Terminological Box): "설계도 그리기”
데이터의 뼈대인 클래스(Class)와 속성(Property)을 정의한다.
•
, 
, 
, 
Class: Restaurant
Menu
Building
TimePeriod
•
 (식당이 메뉴를 판다), 
 (식당이 건물에 있다), 
 (건물이 어디 
근처다)
Property: sells
locatedIn
near
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
18/21

-- PAGE 19 --

2. ABox 구축 (Assertion Box): "데이터 채워 넣기"
설계도(TBox)에 맞춰 실제 데이터(Instance)를 생성한다. 파이썬 
을 사용해 
를 만든다.
rdflib
Raw ABox(초
기 데이터)
from rdflib import Graph, Literal, RDF, URIRef, Namespace # 1. 그래프 생성 및 네임스페
이스 바인딩 g = Graph() SNU = Namespace("http://www.snu.ac.kr/ontology#")
g.bind("snu", SNU) # 접두어 바인딩 (가독성 필수) # 2. 데이터 변환 (Triple 생성 - Raw
ABox) # [사실 1] 301동 식당은 301동에 있다. g.add((SNU.Rest301, SNU.locatedIn,
SNU.Bldg301)) # [사실 2] 301동은 공과대학 구역(EngineeringZone)의 일부다. # (이 정보는
메뉴판엔 없지만, 공간 정보 데이터에서 가져와 추가함) g.add((SNU.Bldg301, SNU.partOf,
SNU.EngineeringZone)) # 3. 1차 TTL 파일 저장
g.serialize(destination='snu_food_raw.ttl', format='turtle')
4) 검증 및 추론 (Reasoning & Materialization)
파이썬으로 생성한 
 파일은 아직 
과 같다. 이를 바로 DB에 넣으면 오류
가 발생하거나, 잘못된 추론을 할 수 있다. 따라서 
으로 불량품을 걸러내고, 
으로 지식을 확장하는 두 단계를 거치면 더 엄밀하게 지식 그래프를 구축할 수 있다.
abox.ttl
정제되지 않은 원석
검증(SHACL)
추론
(Reasoning)
* 온톨로지 구축 단계에서 가장 대중적으로 Protege는 SHACL(플러그인으로서)과 추론(Reasoning) 기
능을 모두 지원한다.
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
19/21

-- PAGE 20 --

1. 데이터 품질 검증 (SHACL): "지식의 불량품 걸러내기"
크롤링 과정에서 가격에 "무료"라는 텍스트가 들어가거나, 필수 정보인 식당 위치가 누락될 수 있
다. 이를 방지하기 위해 
을 사용하여 데이터의 유효성을 검
사한다.
SHACL(Shapes Constraint Language)
•
 데이터가 갖춰야 할 
과 
을 검사하는 
역할:
모양(Shape)
제약 조건(Constraint)
품질 관리자
• 검사 예시 (snu_shapes.ttl):
1.
 모든 
는 반드시 
 속성을 1개 가져야 한다.
필수 값 체크:
Menu
price
2.
의 값은 문자열이 아닌 
여야 한다.
타입 체크: price
정수(Integer)
3.
는 0보다 커야 한다.
범위 체크: price
• 왜 필요한가? (Why)
◦
 가격(정수) 영역에 “무료" 같은 문자열 데이터가 추론기에 
들어가면 연산 오류가 난다.
Garbage In, Garbage Out 방지:
◦
 OWL은 데이터가 없으면 "아직 모르는 것"으로 취급하지만, SHACL은 "에
러"로 판정하여 즉시 경고를 보낸다.
OWL과의 차이:
⇒ 이 단계에서 통과된 깨끗한 데이터만 다음 단계(추론)로 넘긴다.
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
20/21

-- PAGE 21 --

2. 추론 및 지식 확장 (Reasoning): "숨겨진 맥락 발견하기"
검증된 데이터에 
를 돌려, 명시되지 않은 암묵적인 관계를 찾아내어 데이터를 확
장(Evolution)한다.
Reasoner(추론기)
•
 규칙(Rule)을 기반으로 건너뛰기 연결을 계산하는 
역할:
논리적 과학자
• 추론 시나리오:
26. 1. 22. 오후 7:29
온톨로지 기반 Graph RAG 실습하기
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
21/21

==== FILE: 강연자료_디지털 인문학과 온톨로지.pdf ====


-- PAGE 1 --

2026년1월서울대빅데이터혁신융합대학동계캠프강연자료(2026년01월21일09:00-16:00)
인문학적사유가Triplets(S-P-O) 데이터와만날때
디지털인문학과온톨로지
전남대학교중어중문학과교수
유인태

-- PAGE 2 --

Homepage: http://redint.info
학부에서한문학을전공했습니다. 대학을졸업한직후다양한분야의사람들
을만나며창업을준비한끝에컴퓨터과학전공자들과함께협업을진행하여
IT 방면의팀창업에성공하였습니다. 초기앱스토어와안드로이드마켓의성
장을따라몇가지앱을개발해론칭하는경험또한해볼수있었습니다.
창업의길을계속걷지않고, 다시학교로돌아와대학원에진학했습니다. 석
사과정에서한문학을다시공부하게된인연으로, 이후지금까지다양한형식
의고전한문자료를대상으로한해독, 번역, 연구, 교육에꾸준히참여해오
고있습니다. 한편으로박사과정에서디지털인문학을전공한인연덕분에,
이후지금까지인문학자료를대상으로한데이터처리유관연구프로젝트
및교육을지속적으로기획-진행해왔습니다.
근래AI의비약적발달로덩달아디지털인문학에대한관심도커지고있습니
다. 그러한관심이단순한호기심으로끝나지않게끔, 인문학이현시대와발
맞춰나가야할방향에관해늘고민하고있습니다.
강연자소개. 무슨연구를하는사람인가?

-- PAGE 3 --


-- PAGE 4 --

디지털인문학이란무엇인가?

-- PAGE 5 --

디지털인문학
Digital Humanities
01
디지털인문학(Digital Humanities)을어떻게이해할것인가?
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 6 --

디지털인문학(Digital Humanities)을어떻게이해할것인가?
디지털인문학
Digital Humanities
02
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 7 --

디지털인문학vs 디지털인문학
_
띄어쓰기
。
붙여쓰기
띄어쓰기디지털인문학과붙여쓰기디지털인문학사이에는어떠한인식의간극이있다고생각합니다.
고작띄어쓰기하나가무어라고그렇게깊이생각해야하느냐는이야기를하시는분도계시겠지만,
저작은띄어쓰기는‘디지털’과‘인문학’ 사이의관계그리고기존의전통적인문학이아니라새로운인문학으로서
‘디지털인문학’을바라보는시선등DH에관한근본적생각이여러갈래로교차하는공간이라고생각합니다.
디지털인문학을인문학의일종으로볼것이냐, 기존의인문학으로정의하기어려운새로운학문으로볼것이냐.
디지털인문학은, 현재(디지털) 인문학에가까운가디지털(인문학)에가까운가등여러질문을만들어냅니다.
가령이런것이있다: ‘디지털인문학vs 디지털인문학’에관한시선
03
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 8 --

디지털
인문학
데이터베이스
구축
(SQL, No-SQL)
링크드
오픈데이터
(LOD, SPARQL)
자연어
처리
(NLP)
CMS
(Wiki, Omeka
Wordpress)
Web
(HTML, XML,
CSS)
웹프로그래밍
(Python,
JavaScript)
데이터
분석도구
(R, Gephi)
디지털인문학(Digital Humanities)에대한보편적인식: 디지털기술중심의인문학
Text
Analysis
Network 
Analysis
Digital
Contents
Digital
Archive
Data
Curation
HGIS
Data Visualization
04
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 9 --

디지털인문학(Digital Humanities)에대한오해: “첨단의디지털기술을다루어야한다”
전통적인문학대비디지털인문학의특징을, 첨단의디지털기술을활용해서연구를수행하고수행한연구결과물을가지고
근사한논문을쓰는것으로수용하는연구자들이적지않다. 이러한관점에서디지털인문학을수용할경우, 디지털인문학은
그저‘디지털기술을접목한논문을쓰기위한기능적채널’ 그이상도이하도아닌것으로귀결된다. 이러한풍조는‘기술을
다룰줄아는인문학연구자’에대한수요와‘논문을많이게재해야하는실적주의’에대한팽배가함께만들어낸, 학술활동
의부정적징후에가깝다. 무엇보다이러한시각을바탕으로디지털인문학교육을실행할경우, 그형식은대부분‘디지털방
법론(도구) 알려주기’에그치게된다. 인문학적문제의식을심화하기위한목적에서디지털환경을활용하는것이아니라, 그
저인문학자료를대상으로디지털분석도구를다루기위한, 그래서목적과수단이전도된활동을학생들에게전달하게된다.
레거시인문학vs 디지털인문학
05
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 10 --

디지털인문학(Digital Humanities)의실질적양상: 인문지식의데이터화
06
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 11 --

디지털테크놀로지가일종의‘콘텐츠개발’을위한도구정도로여겨지는배경에는, ‘글쓰기’로서의인문학에대한원형적인식이자리하고있다. 월터옹
Walter J. Ong과같은학자는테크놀로지로서글쓰기의이러한지점을‘내면화된어떠한정신상태’라고이야기하기도했다. 인문학연구는텍스트를읽고글
을쓰는과정을통해이루어지는것이기때문에, 읽고쓰기가아닌다른형식의리터러시literacy가주된요소로개입하게되면, 더이상인문학이아니라는생각
이작동하는것이다. 그와같은관점을따를경우디지털테크놀로지를동반한일련의접근은, 인문학연구의일환으로수용되기어려우며그저콘텐츠가공을
위한절차정도로여겨질뿐이다. 이러한관점은마치손으로직접찰흙을다루는것만을조형활동이라여기며, 레고와같은기성조립블록을다루는것은조형
활동으로보지않는입장과유사하다. 예컨대그와같은입장에설경우, 흙의질감을손끝에서직접느끼지못하는것은곧원초적단계에서대상을이해할수있
는기회를놓친다는것과다름이없다. 기성품으로서블록조립의결과물은또다른기성품의일종일수밖에없으며, 자기만의온전한조형을만들어내는것이
불가능함을의미한다. 대상에대한이해와대상을다루는과정그리고대상을가공한결과물에이르기까지, 찰흙빚기의온전함과충실함에비하면레고조립은
무언가부족해보일수밖에없는것이다. 한편으로레고조립이조형활동으로서의고유한정체성이전혀없는가하면그렇지도않다. 레고조립은분해와재조
립이언제든가능하다는특징이있다. 일종의원자료resource materials로서흙을직접다루며완결된조형을손끝의감각에의지해직관적으로만들어가는
것이아니라, 기성블록block 사이의조립가능성을토대로최선의조형을디자인해나갈수있다. 이과정에서기존블록만을사용하는것이아니라새로운형태
의블록을제안하는것도가능하다. 이로써볼때찰흙빚기는자기만의온전한조형을만들게되면그것으로더이상손댈것없는완결을얻는것이지만, 레고
조립은완결이란개념없이언제든분해해서다른형태로블록을재조립하는것이가능하다는묘미가있다.
류인태, 「쓰기테크놀로지의진화, 디지털인문학』, 『쓺』14호, 문학실험실, 2022.
레거시인문학과디지털인문학의차이: 찰흙빚기(글쓰기)와레고조립(데이터)의차이
07
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 12 --

그동안인문학환경은데이터와얼마나가까운관계를유지해왔을까?
08
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 13 --

1985년-1995년무렵
원자료를대상으로한
디지털아카이브구축
디지털아카이브
: 원자료의디지털화
1995년-2005년무렵
원자료의디지털이미지로
텍스트데이터베이스구축
데이터베이스
: 디지털화된자료의데이터화
2005년-2015년무렵
텍스트데이터베이스의
온라인서비스개발/론칭
웹사이트
: 데이터베이스의온라인화
2015년-현재
데이터모델링/라벨링을통한
디지털인문학연구
디지털인문학
: 인문데이터의연구/교육활용
인문학환경과데이터의접점: 인문학에서‘디지털화’가이루어져온과정
09
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 14 --

1985년-1995년무렵
원자료를대상으로한
디지털아카이브구축
디지털아카이브
: 원자료의디지털화
1995년-2005년무렵
원자료의디지털이미지로
텍스트데이터베이스구축
데이터베이스
: 디지털화된자료의데이터화
2005년-2015년무렵
텍스트데이터베이스의
온라인서비스개발/론칭
웹사이트
: 데이터베이스의온라인화
2015년-현재
데이터모델링/라벨링을통한
디지털인문학연구
디지털인문학
: 인문데이터의연구/교육활용
Digitization
대상자료의디지털화
Digitalization
자료형식의디지털화
Digital 
Transformation
연구내용의디지털화
인문학환경과데이터의접점: 인문학에서‘디지털화’가이루어져온과정
10
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 15 --

‘디지털화’의단계에관해생각해보면..
Digitalization
Digitization
Digital
Transformation
디지털아카이브
: 원자료의디지털이미지화
AI 기반데이터프로세싱
: 데이터의개방과활용
온라인텍스트데이터베이스
: 문자열검색의상용화
이3가지단계는순차적이면서도상호보완적관계를형성한다.
Digitization을통해생성된디지털데이터는Digitalization의기초자원이되고,
Digitalization으로구축된기초데이터는Digital Transformation을위한핵심자원이된다.
인문학환경과데이터의접점: 인문학에서‘디지털화’가이루어져온과정
11
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 16 --

기존시스템및과업프로세스의탈피및혁신
현단계에서의‘디지털화’의의미를알아야한다..
DVD 타이틀대여업체였던Netflix가
인터넷에접속해서DVD 타이틀대여를예약할수있는
웹사이트를만들어서온라인서비스모델을운용하는데그쳤다면,
Digitalization 차원의혁신에만머물렀을것이다.
그러나Netflix는온라인DVD 타이틀대여예약방식을뛰어넘어
서비스형식자체를스트리밍플랫폼으로탈바꿈하게되면서
Digital Transformation 차원의변신을이루어냈다.
Digital
Transformation
AI 기반데이터프로세싱
: 데이터의개방과활용
인문학환경과데이터의접점: 인문학에서‘디지털화’가이루어져온과정
12
인문학또한Digitalization이아니라Digital Transformation 차원의변신을꾀해야하는시기다.
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 17 --

디지털인문학(Digital Humanities)을어떻게이해할것인가?
디지털인문학
Digital Humanities
13
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 18 --

디지털인문학(Digital Humanities)의핵심은‘데이터로인문학하기’
디지털인문학
Digital Humanities
14
…디지털환경및데이터처리기술과인문학이만나는접점은‘데이터(Data)’다…
…인공지능(AI)을활용한인문학연구의핵심도마찬가지로‘데이터(Data)’다…
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 19 --

‘데이터로인문학하기’의핵심: 인문데이터(Cultural Data)에관한고민과실천
‘인문데이터(Cultural Data)’란도대체무엇인가?
15
첫번째이야기. 디지털인문학이란무엇인가?

-- PAGE 20 --

인문데이터에관한기초적이해

-- PAGE 21 --

데이터는일반적으로숫자(digit)로여겨진다. ‘데이터를처리한다’는것은‘수치화된무언가를다룬다’
는맥락정도로수용되는경우가일반적이다. 예를들어데이터분석(data analysis) 영역에서활용되
는통계·계량적기법과정량적분석방법론같은것을떠올려볼수있다. 소위데이터전처리(data
preprocessing)라고부르는절차는대규모비정형데이터를정규적성격의수치로환원해처리하기
위한시도와노력의과정으로여겨진다. 데이터전처리를통해정돈된데이터(tidy data)를얻고자하
는절차적관념은대개이공계(STEM)나사회과학(SS) 방면에서일반적으로활용하는분석방법론을
전제로수용되는경우가보편적이다. 질적(qualitative) 연구에주력해온전통적인문학즉문사철계
열의연구영역은상대적으로이공계나사회과학방면의연구영역과비교할때숫자(digit)에대한인
식과다소거리가있다. 물론인문학에서도양적(quantitative) 연구가없는것은아니지만계량적접
근자체가온전한연구방법론으로다루어지는경우는좀처럼보기어렵다. 질적연구로서해석
(interpretation)을이끌어내기위한목적으로양적분석(analysis)이연구의중간단계에서소용되
는경우는종종있지만, 분석을통해나온수치가그자체로연구의결론으로제시되는경우는거의없다.
인문데이터(Cultural Data): 인문학적관점에기초한데이터
두번째이야기. 인문데이터에관한기초적이해
16

-- PAGE 22 --

넓은의미에서데이터는의미있는정보를가진모든값, 사람이나자동기기가생
성또는처리하는형태로표시된것을뜻한다. 어떠한사실, 개념, 명령또는과학적
인실험이나관측결과로얻은수치나정상적인값등실체의속성을숫자, 문자, 기
호등으로표현한것이며데이터에특정한의미가부여될때정보가된다. 데이터
자체는단순한사실에불과하지만, 일련의처리과정에따라특정한목적에소용되
는정보를만들기위한재료로사용되는것이다. 데이터를통해만들어진정보는또
다른정보를위한자료, 즉데이터로사용될수있다. 협의적의미로는주로컴퓨터
용어로정보를작성하기위해필요한자료를뜻한다. 데이터를처리하기위해서는
컴퓨터프로그램등을통해개별값들을읽고처리하며저장하는등의작업이수행
된다. 이때, 데이터는숫자, 영자혹은주기(period), 정부(+, -) 부호등의특수
문자에의해구성되며디지털의기본단위로서0과1의이진법으로표기된다.
두산백과doopedia, ‘데이터(data)’ 항목.
생각해보기: 데이터(data)의사전적의미와맥락
두번째이야기. 인문데이터에관한기초적이해
17

-- PAGE 23 --

넓은의미에서데이터는의미있는정보를가진모든값, 사람이나자동기기가생
성또는처리하는형태로표시된것을뜻한다. 어떠한사실, 개념, 명령또는과학적
인실험이나관측결과로얻은수치나정상적인값등실체의속성을숫자, 문자, 기
호등으로표현한것이며데이터에특정한의미가부여될때정보가된다. 데이터
자체는단순한사실에불과하지만, 일련의처리과정에따라특정한목적에소용되
는정보를만들기위한재료로사용되는것이다. 데이터를통해만들어진정보는또
다른정보를위한자료, 즉데이터로사용될수있다. 협의적의미로는주로컴퓨터
용어로정보를작성하기위해필요한자료를뜻한다. 데이터를처리하기위해서는
컴퓨터프로그램등을통해개별값들을읽고처리하며저장하는등의작업이수행
된다. 이때, 데이터는숫자, 영자혹은주기(period), 정부(+, -) 부호등의특수
문자에의해구성되며디지털의기본단위로서0과1의이진법으로표기된다.
두산백과doopedia, ‘데이터(data)’ 항목.
“
”
생각해보기: 데이터(data)의사전적의미와맥락①실체의표현
두번째이야기. 인문데이터에관한기초적이해
18

-- PAGE 24 --

생각해보기: 실체의표현으로서데이터(data)의내포는무엇일까?
두번째이야기. 인문데이터에관한기초적이해
데이터의가장근본적인성격을밝혀내는한가지좋은방법은데이터를지우고, 손상시키고, 상실한다는것이무슨의미인지
이해해보고자노력하는것이다. 미지의언어로쓰인어떤책의지면을상상해보라. 그데이터가그림문자의형식으로되어있
다고가정하자. 규칙적인패턴들은어떤구조화된구문론을준수하고있음을암시한다. 우리는모든데이터를갖고있으나그
것의의미를알지못한다. 그러므로우리에겐아직아무런정보도없다. 이제그림문자의절반을지워보자. 우리는이번에도
역시데이터를절반으로줄였다고말할수있다. 만일이지움의과정을계속해나가서오로지하나의그림문자만남았어도,
여전히우리는데이터란모종의표상을요구한다거나혹은그런표상과동일시될수있다고말하고싶은마음이들지모른다.
그러나이제그마지막그림문자를마저지워보자. 우리에게는백지만남겨지겠지만그래도데이터가전혀없는것은아니다.
왜냐하면지금눈앞에나타난그백지와, 무언가가쓰여있거나쓰였을수있었던지면과의차이가존재하는한, 그백지한장
도여전히하나의데이터이기때문이다. 이를‘묵시적동의’라는흔히보는현상과비교해보라. 침묵, 즉지각가능한데이터가
없는그상태는어떤소리가들릴때못지않게하나의데이터가될수있다. 그것은이진법체계의‘0’과매우유사하다.
-루치아노플로리디지음/석기용옮김, 『정보철학입문』, 필로소픽, 2022, 48쪽.
19

-- PAGE 25 --

넓은의미에서데이터는의미있는정보를가진모든값, 사람이나자동기기가생
성또는처리하는형태로표시된것을뜻한다. 어떠한사실, 개념, 명령또는과학적
인실험이나관측결과로얻은수치나정상적인값등실체의속성을숫자, 문자, 기
호등으로표현한것이며데이터에특정한의미가부여될때정보가된다. 데이터
자체는단순한사실에불과하지만, 일련의처리과정에따라특정한목적에소용되
는정보를만들기위한재료로사용되는것이다. 데이터를통해만들어진정보는또
다른정보를위한자료, 즉데이터로사용될수있다. 협의적의미로는주로컴퓨터
용어로정보를작성하기위해필요한자료를뜻한다. 데이터를처리하기위해서는
컴퓨터프로그램등을통해개별값들을읽고처리하며저장하는등의작업이수행
된다. 이때, 데이터는숫자, 영자혹은주기(period), 정부(+, -) 부호등의특수
문자에의해구성되며디지털의기본단위로서0과1의이진법으로표기된다.
두산백과doopedia, ‘데이터(data)’ 항목.
“
”
생각해보기: 데이터(data)의사전적의미와맥락②정보의재료
두번째이야기. 인문데이터에관한기초적이해
20

-- PAGE 26 --

한반에15명은남자, 나머지15명은여자로구성된30명의학급이있다. 이학생들의키를측정하였다고하면30개의숫자
들이나열될것이고, 그것은“데이터”이다. 데이터는단지숫자들의나열로, 그30개데이터를‘가공’하여평균을내보았을
때평균키가170cm로나왔다고한다면우리는“이반아이들의키가이정도이구나”라는“정보”를얻게될것이다. 이정
보는책상의크기를정할때사용할수있고세면대의높이를정할때에도사용할수있다. 이처럼다양하게활용될수있는
유용한것이“정보”이다. 나아가남학생들의키의평균은173cm이고, 여학생들키의평균은165cm라고하는또다른“정
보”를얻어낼수도있다. 이정보는또다른의미를우리에게줄수있다. 하지만이정보는단지이특정한반학생들에게만
적용될수있는정보이다. 다른학년의학생들에게나, 혹은독일학생들에게도적용될수있는정보는아니다. 그럼에도우리
가찾은이정보에서우리는또다른상위레벨의패턴을찾아낼수있다. “아, 남학생들의키가일반적으로여학생들의키보
다크구나”라는패턴을생각해낼수있다. 그리고이패턴이이특정한반학생들뿐만아니라일반적으로적용할수있는것
이라고할때우리는이것을“지식”이라고부를수있게된다.
-김현철, 『데이터로표현하는세상: 정보적사고의시작』, 고려대학교출판문화원, 2014, 9쪽.
두번째이야기. 인문데이터에관한기초적이해
생각해보기: 데이터(data)에서정보(information)로, 다시지식(knowledge)으로
21

-- PAGE 27 --

DIKW 모델: 데이터의가공및활용과정을표현한모델
데이터(Data) →정보(Information) → 지식(Knowledge)
Cartoon by David Somerville, based on a two pane version by Hugh McLeod.
두번째이야기. 인문데이터에관한기초적이해
생각해보기: 데이터(data)에서정보(information)로, 다시지식(knowledge)으로
22

-- PAGE 28 --

넓은의미에서데이터는의미있는정보를가진모든값, 사람이나자동기기가생
성또는처리하는형태로표시된것을뜻한다. 어떠한사실, 개념, 명령또는과학적
인실험이나관측결과로얻은수치나정상적인값등실체의속성을숫자, 문자, 기
호등으로표현한것이며데이터에특정한의미가부여될때정보가된다. 데이터
자체는단순한사실에불과하지만, 일련의처리과정에따라특정한목적에소용되
는정보를만들기위한재료로사용되는것이다. 데이터를통해만들어진정보는또
다른정보를위한자료, 즉데이터로사용될수있다. 협의적의미로는주로컴퓨터
용어로정보를작성하기위해필요한자료를뜻한다. 데이터를처리하기위해서는
컴퓨터프로그램등을통해개별값들을읽고처리하며저장하는등의작업이수행
된다. 이때, 데이터는숫자, 영자혹은주기(period), 정부(+, -) 부호등의특수
문자에의해구성되며디지털의기본단위로서0과1의이진법으로표기된다.
두산백과doopedia, ‘데이터(data)’ 항목.
“
”
생각해보기: 데이터(data)의사전적의미와맥락③디지털자원
두번째이야기. 인문데이터에관한기초적이해
23

-- PAGE 29 --

인간은항상인공적대상과자연적대상으로둘러싸인혼합환경속에서살아왔다. 인공적인것과자연적인것은별개의두
영역이아니며, 인공적대상또한단순히자연적인것을정복하기위한도구일뿐인것도아니다. 대신그것들은인간의경험
과존재를조건짓는역동적체계를구성한다. 그리고다름아니라지속적으로보다큰구체화를향해발달하기때문에인공
적인것은그것에독특한역사적조건에대한지속적성찰을요구한다. 우리가그안에서살고있는‘환경’ 또한변해왔다. 비
디오테이프는유튜브비디오로대체되어왔으며, 저녁식사초대장은더이상편지로발송되지않으며, 전화를걸거나이메일
로알려오는일은점점더줄어들고페이스북행사초대를통해알려오는경우가점점더빈번해지고있다. 그대상은기본적
으로데이터이며, 공유가능하고제어가능하다. 시스템설정을통해가시적인것으로만들거나비가시적인것으로만들수
있다…(중략)…내가‘디지털적대상’이라는말로의미하는것은화면위에서형성되는또는컴퓨터프로그램의백엔드속에
숨어있는대상인데, 데이터와메타데이터로구성되는그것은구조나스키마에의해조절된다. 메타데이터란말그대로데이
터에관한데이터를의미한다. 스키마란메타데이터에의미론적기능적의미를부여하는구조를말한다. 컴퓨팅세계에서는
또한온톨로지ontology로불리기도한다.
-육후이Yuk Hui 지음/조형준·이철규·임완철옮김, 『디지털적대상의존재에대하여』, 새물결, 2021, 51쪽.
생각해보기: 데이터(data)는디지털환경을구성하는기초적자원이다
두번째이야기. 인문데이터에관한기초적이해
24

-- PAGE 30 --

넓은의미에서데이터는의미있는정보를가진모든값, 사람이나자동기기가생
성또는처리하는형태로표시된것을뜻한다. 어떠한사실, 개념, 명령또는과학적
인실험이나관측결과로얻은수치나정상적인값등실체의속성을숫자, 문자, 기
호등으로표현한것이며데이터에특정한의미가부여될때정보가된다. 데이터
자체는단순한사실에불과하지만, 일련의처리과정에따라특정한목적에소용되
는정보를만들기위한재료로사용되는것이다. 데이터를통해만들어진정보는또
다른정보를위한자료, 즉데이터로사용될수있다. 협의적의미로는주로컴퓨터
용어로정보를작성하기위해필요한자료를뜻한다. 데이터를처리하기위해서는
컴퓨터프로그램등을통해개별값들을읽고처리하며저장하는등의작업이수행
된다. 이때, 데이터는숫자, 영자혹은주기(period), 정부(+, -) 부호등의특수
문자에의해구성되며디지털의기본단위로서0과1의이진법으로표기된다.
두산백과doopedia, ‘데이터(data)’ 항목.
생각해보기: 데이터(data)의사전적의미와맥락3가지
두번째이야기. 인문데이터에관한기초적이해
25

-- PAGE 31 --

생각해보기: 데이터(data)의3가지사전적의미와인문학의접점은무엇일까?
두번째이야기. 인문데이터에관한기초적이해
실체의
표현
정보의
재료
디지털
자원
26

-- PAGE 32 --

두번째이야기. 인문데이터에관한기초적이해
실체의
표현
생각해보기: 데이터(data)의3가지사전적의미와인문학의접점은무엇일까?
실체(substance)에대한인문학적표현으로‘글쓰기’ 외에또다른방식이있을까? 있다면무엇일까?
27

-- PAGE 33 --

두번째이야기. 인문데이터에관한기초적이해
정보의
재료
인문학에서다루는지식(knowledge)을, 정보(information)와데이터(data)의위상으로이해할수있을까?
생각해보기: 데이터(data)의3가지사전적의미와인문학의접점은무엇일까?
28

-- PAGE 34 --

두번째이야기. 인문데이터에관한기초적이해
디지털
자원
생각해보기: 데이터(data)의3가지사전적의미와인문학의접점은무엇일까?
인문학을디지털환경에서수행할수있을까? 할수있다면그방법론(methodology)은무엇일까?
29

-- PAGE 35 --

실체의
표현
정보의
재료
두번째이야기. 인문데이터에관한기초적이해
디지털
자원
생각해보기: 데이터(data)의3가지사전적의미와인문학의접점은무엇일까?
인문학을디지털환경에서수행할수있을까? 할수있다면그방법론(methodology)은무엇일까?
인문학에서다루는지식(knowledge)을, 정보(information)와데이터(data)의위상으로이해할수있을까?
실체(substance)에대한인문학적표현으로‘글쓰기’ 외에또다른방식이있을까? 있다면무엇일까?
30

-- PAGE 36 --

두번째이야기. 인문데이터에관한기초적이해
인문데이터(Cultural Data): 데이터(data)의3가지내포와인문학적문제의식의조우
인문학을디지털환경에서수행할수있을까? 할수있다면그방법론(methodology)은무엇일까?
인문학에서다루는지식(knowledge)을, 정보(information)와데이터(data)로분절할수있을까?
실체(substance)에대한인문학적표현으로‘글쓰기’ 외에또다른방식이있을까? 있다면무엇일까?
31

-- PAGE 37 --

…물론, 우리는책을폐지하려고하는것이아니다. 오히려지식의생산을위해출판이여러가지형식의미디어로흡수되
는네오혹은포스트출판모델(neo- or post-print model)을제안하고자한다. 건축과디자인의특성은연구질문
(research questions)이던져지고만들어지고다듬어질뿐만아니라체계적으로표현될수있는방법을보여줄수있다.
정보와데이터그리고지식으로의접속방법을알아내고디자인하는것이쓰기와큐레이팅및코디네이팅만큼이나중요
하게된이순간이믿을수없을만큼놀랍다. / 생산이라는육체노동(manual)의영역과사고라는정신적(mental) 영
역간의이분화는오해의소지가있다. 새로운시대에낡은이론이나활용논란은반향을불러일으키지않는다. 지식
(Knowledge)은단어, 소리, 냄새, 지도, 다이어그램, 장치, 주변환경, 데이터리포지터리(data repositories), 표
(tables) 등다양한형식(forms)을갖는다. 물리적조작, 디지털디자인, 우아하고효과적인글다듬기; 이미지배열; 움
직이는몽타주; 소리의조합– 이모든것이생산이다…
-
｢A DIGITAL HUMANITIES MANIFESTO｣(2009.5.29.).
URL: https://www.humanitiesblast.com/manifesto/Manifesto_V2.pdf
디지털인문학(Digital Humanities): 인문데이터(Cultural Data)를다루는활동
두번째이야기. 인문데이터에관한기초적이해
32

-- PAGE 38 --

표현
전달
공유
협업
분석
연산
다양한정보의개방적공유를가능하게하는디지털환경의운용: ‘공유(共有, sharing)’를통한‘협업(cooperation)’의확대
복잡한정보의입체적표현을가능하게하는디지털매체의활용: ‘표현(表現, representation)’을통한‘전달(communication)’의촉진
대규모정보의효과적분석을가능하게하는디지털기술의적용: ‘분석(分析, analysis)’을통한‘연산(computation)’의강화
인문학에서데이터를어떻게그리고왜다룰것인가에관한근본적문제의식3가지
두번째이야기. 인문데이터에관한기초적이해
33
인문데이터(Cultural Data) 다루기의핵심줄기: 공유, 표현, 분석

-- PAGE 39 --

공유
협업
표현
전달
분석
연산
아날로그기반의
인문학연구환경에서
‘공유’와‘협업’은
어떻게이루어져왔는가?
인문데이터(Cultural Data) 다루기의큰줄기: ①공유와협업
두번째이야기. 인문데이터에관한기초적이해
34

-- PAGE 40 --

전통적인인문학은, 연구결과물로서지식을학술논문이나단행
본에담아정리해서출간을통해사람들에게그것을전달하고또
공유하는방식을취하였다. 연구한내용을지식중심으로전달-공
유하는방식은종이책이중심적인커뮤니케이션미디어로기능했
던과거에는유효했지만, 웹과컴퓨터로대표되는디지털환경에
서는지식단위가아니라데이터단위의공유가가능하다. 인문학
은전통적으로지식중심의전달방식을취해왔기에, 데이터기반
의공유모델을갑작스럽게현실화하는것이쉽지않은상황이다.
연구데이터
학술논문/단행본
인문데이터(Cultural Data) 다루기의큰줄기: ①공유와협업
두번째이야기. 인문데이터에관한기초적이해
35

-- PAGE 41 --

공유
협업
표현
전달
분석
연산
아날로그기반의
인문학연구환경에서
‘표현’과‘전달’은
어떻게이루어져왔는가?
인문데이터(Cultural Data) 다루기의큰줄기: ②표현과전달
두번째이야기. 인문데이터에관한기초적이해
36

-- PAGE 42 --

시각화
글쓰기
전통적인인문학은글쓰기에중심을두고글을통해자신의생각
을표현-전달하고자하였다. 유려한글쓰기는단순히잘꾸며진
결과물이아니라, 그안에담긴내용을잘전달하고표현하는중요
한역량으로수용되어왔다. 한편으로, 디지털환경의경우, 데이
터를시각화함으로써다채로운지식을표현할수있다. 아날로그
환경에서글쓰기가지니고있는선형적(linear) 방식을벗어나서
비선형적(non-linear) 방식의데이터수집-시각화가가능한것
이다. 이는글쓰기와대립하는것이아니라보완되는무언가이다.
인문데이터(Cultural Data) 다루기의큰줄기: ②표현과전달
두번째이야기. 인문데이터에관한기초적이해
37

-- PAGE 43 --

공유
협업
표현
전달
분석
연산
아날로그기반의
인문학연구환경에서
‘분석’과‘연산’은
어떻게이루어져왔는가?
인문데이터(Cultural Data) 다루기의큰줄기: ③분석과연산
두번째이야기. 인문데이터에관한기초적이해
38

-- PAGE 44 --

소규모자료를
대상으로한
의미의해석
대규모자료를
대상으로한
데이터분석
인문데이터(Cultural Data) 다루기의큰줄기: ③분석과연산
전통적인인문학은소규모자료를대상으로한질적(qualitative)
접근을중심적인연구방법론으로삼아왔다. 소규모자료를다루어
온것은, 연구자가자료를하나씩살피면서그에담긴내용을정리하
고그로부터특정의미를도출하는방식이기에, 현실적으로개인연
구자가큰규모의자료를다루기가쉽지않기때문이다. 컴퓨터를활
용할경우대규모자료를대상으로한양적(quantitative) 접근이
가능하다. 기존에는살피지못했던자료의전체적규모와패턴을파
악함으로써, 인문학연구에기여하는바가많을것이라생각한다.
두번째이야기. 인문데이터에관한기초적이해
39

-- PAGE 45 --

표현
전달
공유
협업
분석
연산
다양한정보의개방적공유를
가능하게하는디지털환경의운용
‘공유(共有, sharing)’를통한
‘협업(cooperation)’의확대
인문데이터(Cultural Data) 다루기의핵심줄기: 공유, 표현, 분석
복잡한정보의입체적표현을
가능하게하는디지털매체의활용
‘표현(表現, representation)’을통한
‘전달(communication)’의촉진
대규모정보의효과적분석을
가능하게하는디지털기술의적용
‘분석(分析, analysis)’을통한
‘연산(computation)’의강화
두번째이야기. 인문데이터에관한기초적이해
40

-- PAGE 46 --

온톨로지와지식그래프에관하여

-- PAGE 47 --

인문데이터(Cultural Data): 인문학적성격의데이터?
○물리학: 온도, 압력, 속도측정값
○의학: 혈압, 심박수, 체온등의수치
○화학: pH 수치, 분자량, 반응속도
○생물학: DNA 염기서열개수, 세포분열횟수, 개체수
○지구과학: 지진규모, 강수량, 대기압
○컴퓨터과학: 초당연산횟수, 메모리용량, 네트워크속도
○통계학: 평균, 표준편차, 상관계수
○경제학: GDP, 인플레이션율, 주가지수
○심리학(실험): 반응시간, 정확도비율, 점수
과학(Science) 분야의데이터
●언어: 특정시기또는공간에서의언어적양상
●문학: 시에서단일어휘가출현하는빈도와양상
●문학: 소설에서특정한문체가지속되는빈도와양상
●문학: 작품속등장인물간의관계양상과특징
●역사: 특정사료에서확인되는단일키워드의출현빈도
●역사: 특정사료의이본간에발견되는편찬형식의차이
●역사: 특정용어가사료들사이에서연계하는양상
●철학: 각종주석에서확인되는특정개념어간관계양상
●예술: 특정시기를기준으로한예술양식의변동흐름
인문학(Humanities) 분야의데이터
세번째이야기. 온톨로지와지식그래프에관하여
41

-- PAGE 48 --

인문데이터(Cultural Data): 인문학적성격의데이터?
42
○과학(Science) 분야의데이터: 일반적대상에대한계량과측정분석의자원
○인문학(Humanities) 분야의데이터: 고유한대상을향한관계와맥락짚기의단서
→대상을일반적인것(Universal Thing)으로환원해서, 단일원리를발견하는데집중
→“얼마나많이/빠르게/높게?”
→물온도100°C, 반응속도5초, 세포개수1,000개
→분석결과로서의수치가그자체로어떠한현상을설명하는단서가됨
→대상이지닌고유함(Singularity)에초점을두고, 그특징을해부하는데집중
→문학의경우, 작가-작품-독자간의관계, 텍스트간상호텍스트성을어떻게정보화할것인가?
→역사학의경우, 시대-인물-장소간의연관성, 원인과결과의맥락을어떻게정보화할것인가?
→철학의경우, 개념들간의논리적관계, 사상가들간의영향관계를어떻게정보화할것인가?
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 49 --

43
정리하자면
인문학분야의데이터는,
‘대상의고유함을바라보기’, ‘관계와맥락을이해하기’가중요하고.
‘관계와맥락의이해’는대상들이어떻게관계맺고있는가에관한인식이며.
대상들사이의관계맺음의양상은대상의‘같고다름’에관한인식에서출발한다.
대상들사이에무엇이‘같고’ 무엇이‘다른’ 지를인식하는대표적양상은
분류(分類, Classification), 범주화(範疇化, Categorization)와같은접근이다.
인문데이터(Cultural Data): 고유함, 관계와맥락이중심
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 50 --

44
관계와맥락에의거하여대상을분류하고범주화하는방법은많다
계층구조
그래프구조
패러다임
패싯분류
Hierarchies(Trees)
Graph
Paradigms
Facet
연역성○
상호배타성○
종속과상속○
연역성○
상호배타성X
종속과상속X
예시:
문학사의시대구분(고전→근세→근대→현대)
예시:
작가들사이의문학적영향관계네트워크
현상을구성하는여러
요소들사이의관계와
상호작용에기초한
일종의‘틀’ 또는‘관점’
대상을여러독립적
측면(facet)으로
나누어분류하고,
이를조합하는방식
예시:
역사학연구에서사건-원인-맥락-결과분석틀
예시:
시대+장르+주제+형식을조합한작품분류
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 51 --

45
인문데이터(Cultural Data): 고유함, 관계와맥락이중심
LGBTQ
(Lesbian, Gay, Bisexual, Transgender, Queer)
성(姓)을어떻게구분하는것인‘옳은가’?
생물학적구분(sex) 또는사회적구분(gender)으로서,
성에대한관념은가치의문제일까?
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 52 --

46
메타데이터(Meta Data): 정보관리확대와데이터베이스기술의등장
도서관사서들은2000년이상사물을서술하는일을해오면서결국두어가지를알아냈다. 도서관학의원칙들은사물을어떻게효과적으로서
술할수있는지에대한많은통찰력을바깥세상에제공했다. 기술description 원칙을공부한사서들덕분에이원칙들을서술이필요한곳어
디라도적용할수있게되었다. 더욱이데이터베이스가발명되어서구조화된자료보관이가능해지면서메타데이터를정기적으로만들고보관
하는것이가능해졌다. 도서관사서들은컴퓨터와데이터베이스의얼리어답터이긴하지만유일한사용자는전혀아니다. 소형컴퓨터의개발
전에는도서관메타데이터가서가목록그리고카드목록과같은전문화된맞춤보관소에보관되었다. 소형컴퓨터개발후에는도서관의메타
데이터역시, 모든이들이사용하고있는동일한기술을활용하여보관되었다. 데이터베이스의등장으로도서관소장자료에대한기술식메타
데이터뿐만아니라모든것에대해서구조화된자료를만들고보관할수있게되었다. 특히기업과정부에서는단순한서술목적외에도조직화
된자료를항상수집·보관해왔는데, 예를들면손익계산서, 재고, 세금, 통계등이종이나심지어그보다더오래된기술로수천년동안존재해
왔다. 그러나이것들은메타데이터가아니고단순히사업체와정부그리고여타조직의활동중에생성되고활동을운영할수있게해주는문서
일뿐이다. 이런활동들이컴퓨터를활용하여실행되기시작하면서관련서류에서대상물을찾는것뿐아니라파일에서그대상물에실제로연
결해줄수도있게되었다. 이런기능성은현대생활에깊이뿌리박혀있어서서류가관리되는방식에얼마나급격한변화를일으켰는지모른다.
(※일부표현수정)
-제프리포머란츠지음/전주범옮김, 『메타데이터』, 한울, 2019, 22-23쪽.
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 53 --

47
메타데이터(Cultural Data): 고유함, 관계와맥락이중심
MetaData
而上的(상위의)
데이터
데이터에관한데이터(Data about Data)
→ 특정데이터를설명하는상위정보
●기술적정의: 데이터의속성, 내용, 품질, 조건, 접근방법등을기술하는구조화된정보
●기능적정의: 데이터를효과적으로찾고, 이해하고, 사용하고, 관리하기위한정보
●실용적정의: “이데이터가무엇이며, 어떻게사용해야하는지”를알려주는정보
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 54 --

Scheme
추상화구조화된
체계
Value
성분에해당하는구체적정보
Element
기술(description)을위한성분
메타데이터를구성하는3요소: Scheme, Element, Value
48
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 55 --

“예술작품으로서수많은회화를어떻게체계적으로정리할수있을까?”
○제목작품에부여된대표적명칭
○작가작품을그린주체로서인물
○연도작품이그려져창작된연도
○크기작품의가로와세로크기
○기법작품을그린방법
○제목모나리자(La Joconde, portrait de Monna Lisa)
○작가레오나르도다빈치(Leonardo da Vinci)
○연도1503-1506년(추정)
○크기77 X 53cm
○기법패널에유채(Huile sur bois)
Value
성분에해당하는구체적정보
Element
기술(description)을위한성분
Scheme
추상화구조화된체계
메타데이터를구성하는3요소: Scheme, Element, Value
49
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 56 --

메타데이터에도다양한형식이있다?
통제어휘
Controlled
Vocabulary
온톨로지Ontology
시소러스Thesaurus
통제어휘용어를
네트워크구조로조직화한컬렉션. 
어휘사이의다양한관계를
정의하는것이핵심.
텍사노미Taxonomy
온톨로지체계(형식)를통해
개체와관계의유형을정의하고
개체와관계사이의
다양한의미적관계를
정의하는가장복잡한체계.
통제어휘용어를
계층적구조로조직화한컬렉션.
동의어-이형어기반의계층화.
50
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 57 --

메타데이터의대표적형식①통제어휘(controlled vocabulary)
통제어휘
Controlled
Vocabulary
●정의: 특정분야에서사용할용어를미리정의하고통일한어휘목록
●특징
- 가장기본적인형식
- 동의어, 이형어통제
- 일관성있는색인과검색보장
○인문학적예시
문학장르에대해통제어휘를적용할경우,
가령소설(Novel)을기준으로할시,
‘장편소설’과‘픽션’과같은표현은모두‘소설’로통일하기로함.
51
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 58 --

메타데이터의대표적형식②텍사노미(taxonomy)
텍사노미
taxonomy
●정의: 개념들을계층적으로분류하여상하위관계를명확히한체계
●특징
- 상위-하위관계(is-a relationship)
- 트리구조
- 포괄성과상호배타성
○인문학적예시
문학의갈래에대해텍사노미를적용할경우,
시기를기준으로크게고전문학, 현대문학으로분류.
고전문학은고대문학, 중세문학, 근세문학으로, 현대문학은개화기문학, 식민지문학, 해방이후문학으로분류.
52
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 59 --

메타데이터의대표적형식③시소러스(thesaurus)
시소러스
thesaurus
●정의: 용어들간의다양한관계(동의어, 관련어, 상하위어)를체계적으로연결한어휘체계
●특징
- 동등관계(USE, UF(Use For)
- 계층관계(BT(Broader Term), NT(Narrower Term))
- 연관관계(RT(Related Term))
○인문학적예시
‘조선왕조’를대상으로한시소러스를구성할경우,
USE: 조선시대, 이조
BT: 한국사, NT: 조선전기, 조선후기, RT: 임진왜란, 세종대왕, 한글창제
53
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 60 --

메타데이터의대표적형식④온톨로지(ontology)
온톨로지
ontology
●정의: 특정도메인의개념들과그들간의복잡한관계를형식적으로명시한지식표현체계
●특징
- 다양한개체와관계의유형정의
- 논리적추론가능, 기계가이해할수있는형식
- 가장복잡하고정교한형식
○인문학적예시
‘조선왕실’ 온톨로지를거칠게표현하면:
개체: 왕, 신하, 궁궐, 정책, 사건
관계: 왕→거주함→궁궐, 왕→임명함→신하, 정책→야기함→사건
54
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 61 --

메타데이터의대표적형식4가지
55
텍사노미
taxonomy
어떠한형식의메타데이터를활용할것인가?
: 대상이무엇이며, 어떠한목적과맥락에그것을다룰것인가의고민필요
시소러스
thesaurus
통제어휘
Controlled
Vocabulary
온톨로지
ontology
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 62 --

메타데이터의대표적형식4가지
56
규모가작고단순한프로젝트의경우통제어휘를, 체계적분류가중요한프로젝트의경우텍사노미를, 검색기능이
중요한프로젝트의경우시소러스를, 복잡한관계분석이목표인프로젝트의경우온톨로지를선택해서활용할수
있다. 이4가지형식은상호배타적이아니라상호보완적이며, 목적과규모에따라적절히선택. 조합할수있다.
어떠한형식의메타데이터를활용할것인가?
: 대상이무엇이며, 어떠한목적과맥락에그것을다룰것인가의고민필요
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 63 --

존재론을가리키는Ontology는on과logos라는그리스어에서왔다. On은einai의현
재분사로, ‘있음’이라는의미이다. Logos는legein에서온말로, ‘언급되고있는것‘ 또
는하이데거말을빌리면‘밖으로끌어내어앞에내어놓음’이라는의미이다.
-육후이Yuk Hui 지음/조형준·이철규·임완철옮김, 『디지털적대상의존재에대하여』, 새물결, 2021, 100~101쪽.
온톨로지란무엇인가: 어원과그의미
57
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 64 --

Ontology
영어-logy는
희랍어-λογία(-logía)에해당하며
‘사고, ‘탐구’, ‘학문’을의미
희랍어ὄντος (óntos)는
영어Being에해당하며
‘존재’를의미
존재론
존재에대한탐구
온톨로지란무엇인가: 어원과그의미
58
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 65 --

존재를탐구한다는것은무엇인가?
세계내에존재하는것들을탐구대상으로삼아
개별대상이지닌본질적특징을파악하고
이를토대로
각대상을분류하고
여러대상사이의관계를분석하여
대상의존재체계를온전히해명하는것.
온톨로지란무엇인가: 어원과그의미
59
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 66 --

예를들자면…
지도
박물관
백과사전
온톨로지란무엇인가: 일상에서의온톨로지적용사례
60
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 67 --

그런데널리통용되는온톨로지는…
정보기술방면에서
활용되는
온톨로지이다.
온톨로지란무엇인가: 넓은범주의온톨로지와좁은범위의온톨로지
61
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 68 --

“An Ontology is a formal, explicit specification
of a shared conceptualization of a domain of interest.”
-Thomas R. Gruber & Pim Borst
*formal
:컴퓨터가처리할수있는정형화된형태로
*explicit specification
:개념의유형과사용규칙을명백하게명시함
*shared
:각분야를넘나들며공통적으로사용될수있는
*conceptualization
:대상을개념화하여추상적으로체계화한모델
온톨로지란무엇인가: 정보기술영역에서온톨로지의정의
62
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 69 --

어원적맥락에서추론가능한온톨로지의의미와
정보기술영역에서정의되는온톨로지개념에있어
분명한차이가있다면,
정보기술영역의온톨로지정의에서는
컴퓨터기술과웹환경을통해
대상을분류하고대상간의관계를이해하는체계가
온톨로지임을확실히하고있다는점이다.
“정보화의대상이되는분야의기본개념과해당개념들간의상관관계를,
다양한영역에서공유가능한표준적형태에근거해
전자적으로표현할수있도록구성한데이터기술체계”
온톨로지란무엇인가: 정보기술영역에서온톨로지의정의
63
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 70 --

많은양의데이터를효율적으로분류하고
데이터간의관계를정의할수있는
기준이나체계가없을경우,
인간이그모든데이터를
일일이검색할수없기에
데이터의활용영역이좁아질뿐더러
그로부터발견가능한
다양한지식의외연이
무가치한것으로전락할수있다.
온톨로지는, 대상자료(data)의성격이점점세분화되고그규모가차츰커지고있는현재
즉, 초연결사회이자빅데이터시대에그중요성과활용가치가더욱더커지고있다.
온톨로지란무엇인가: 정보기술영역에서온톨로지의정의
64
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 71 --

온톨로지의탄생: 인공지능기술의일환
65
정보와지식의
표현체계
귀납적인지에의한학습
연역적규칙을통한추론
판단으로서
의사결정
지능: 지식을체계적으로표현하는토대에근거해자료를학습하고정보를조합해추론함으로써의사결정을내리는활동
지능은어떻게작동하는가…
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 72 --

기호주의적접근(symbolism AI) : 규칙기반
연결주의적접근(connectionism AI) : 신경망기반
의식-명시적지식-연역추론
전문가시스템(Expert System)
온톨로지(Ontology)
지식그래프(Knowledge Graph)
1950년대~1980년대주류인공지능기술
논리, 규칙, 지식표현중심
무의식-암묵적지식-귀납추론
퍼셉트론(Perceptron)
인공신경망(Neural Network)
거대언어모델(Large Language Model)
1990년대이후주류인공지능기술
학습, 패턴인식중심
온톨로지의탄생: 인공지능기술의일환
66
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 73 --

Google의Search Engine
지식그래프(Knowledge Graph)에서
더욱발전한형식의
지식패널(Knowledge Panel) 서비스
OpenAI의ChatGPT
인공신경망(Neural Network) 분야의
고도화된알고리즘의발명과
거대언어모델(LLM) 서비스로의진화
기호주의적접근(Symbolic AI): 규칙기반
연결주의적접근(connectionism AI): 신경망기반
67
온톨로지의진화: 웹(web) 환경과의융합
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 74 --

온톨로지: 기호주의인공지능기술의끝판왕?
68
기호주의AI의단계적발전과한계
1950s: 논리시스템→“기계가논리적추론을”
1960s: 전문가시스템→“기계가전문지식을”
1970s: 지식표현→“기계가세상을이해하려면?”
1980s: 지식공학→“어떻게지식을체계화할까?”
1990s: 온톨로지→“지식의표준화와공유”
→“지식획득병목
(Knowledge Acquisition Bottleneck)”
→각시스템마다다른지식표현방식
→지식공유와재사용의어려움
온톨로지가해결하려던문제와방향
●상호운용성: 다른시스템간지식공유
●명시성: 암묵적지식을명시적으로표현
●재사용성: 한번구축한지식의활용확대
→형식적명세: 기계가이해할수있는정확한정의
→추론능력: 기존지식에서새로운지식도출
→표준화: 지식표현의통일된방법론
온톨로지의한계와전환
1990년대말: 연결주의(딥러닝)의부상. 온톨로지는시맨틱웹
으로진화. “온톨로지는기호주의AI가추구했던‘기계가세상을
이해하게하자’는꿈의가장정교한구현체”
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 75 --

69
도메인온톨로지(Domain Ontology)의전환과활용
온톨로지의원대한이상이있다면…
“모든지식(Knowledge)을체계적으로표현하자!”
“기계(Machine)가이해할수있는완벽한지식체계를만들어내자!”
그러나현실의벽은너무높았다…
수많은지식을모두포괄하고자했던온톨로지의방향성은
그자체로너무복잡하고추상적이며, 구축비용과시간의부담이크고,
연구이론과현장실무사이의괴리가심했다.
“완벽한온톨로지”는현실에있을수없는무언가로여겨지게되었다.
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 76 --

70
도메인온톨로지(Domain Ontology)의전환과활용
기존의온톨로지에대한접근
도메인온톨로지에대한접근
○철학적기초→논리적구조→완벽한체계→현실적적용
●결과: 이론적으로는완벽하지만실질적활용성부족
○현실적문제→제한적상황→점진적발전→실질적활용
●결과: 이론적으로불완전하지만현실적유용함확보
완벽한온톨로지에서유용한온톨로지개념으로의패러다임전환:
이론적으로완벽한온톨로지vs 현실적으로유용한온톨로지
기존의온톨로지에서도메인온톨로지로이행의핵심
①범위의제한: 기존의온톨로지: “모든지식을다표현하자”
①범위의제한: 도메인온톨로지: “우리분야의필요한지식만다루자”
②활용성강조: 기존의온톨로지: “이론적으로완벽해야해”
①범위의제한: 도메인온톨로지: “현실에서활용할수있어야해”
③데이터기반: 기존의온톨로지: “개념을먼저정립하고데이터구축”
①범위의제한: 도메인온톨로지: “데이터를먼저구축하고개념을정립”
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 77 --

71
도메인온톨로지(Domain Ontology)의전환과활용
도메인온톨로지가성공한대표적사례는무엇일까?
SNOMED CT(https://www.snomed.org/)
“의료분야의도메인온톨로지”
CIDOC CRM(https://cidoc-crm.org/)
“문화분야의도메인온톨로지”
○목표: 의학용어의표준화
○범위: 질병, 증상, 치료, 약물
○성과: 전세계병원에서실제사용
○핵심: 완벽한의학지식이아닌“진료에필요한만큼”
●목표: 박물관정보의통합
●범위: 문화유산, 사람, 사건, 장소, 시간
●성과: 전세계주요박물관의정보화표준
●핵심: 철학적완벽성보다“박물관업무에활용가능한”
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 78 --

72
온톨로지(Ontology)와지식그래프(Knowledge Graph)
이미지출처: Medium의「Challenges of Knowledge Graphs: From Strings to Things — An Introduction」
(url: https://medium.com/@sderymail/challenges-of-knowledge-graph-part-1-d9ffe9e35214)
지식그래프는현실세계의지식(Knowledge)을구성하고있는여러개체(Entity)와
그들사이의관계(Relationship)를그래프(Graph) 형식으로구조화하여표현한지식베이스다.
①그래프구조: Node(개체)와Edge(관계)로구성
②의미적연결: 연결을통한의미있는관계표현
③기계가독성: 컴퓨터가이해.추론할수있는형식
④지식의확장: 새로운지식을계속확장가능함
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 79 --

73
지식그래프(Knowledge Graph)의탄생과발달과정
01단계. 시맨틱웹의이상(1990-2000년대초반)
●배경: 팀버너스리의시맨틱웹비전
●맥락: 기계가이해할수있는웹데이터
●기술: RDF, OWL, SPARQL 개발
●현실: 복잡성, 실용성부족
02단계. 링크드데이터의등장(2000년대중반)
●배경: 웹기반의대규모데이터베이스개념
●맥락: 웹상의데이터를표준화된방식으로연결
●기술: URI 사용, HTTP 접근, RDF 표준
●현실: DBpedia, Freebase 등대규모데이터셋구축
03단계. 구글의지식그래프선언(2010년대초반)
●배경: 구글이“Knowledge Graph” 용어대중화
●맥락: 문자열(string)이아닌개체(thing) 중심검색
●기술: 검색결과에구조화된정보패널제공
●현실: 학술용어에서산업표준으로전환
04단계. 다양한기술에연계.활용(현재까지)
●배경: Amazon, Palantir 등빅테크전략
●맥락: Wikidata, YAGO, ConceptNet 오픈소스확산
●기술: 딥러닝과지식그래프의융합(Neuro-symbolic AI)
●현실: 추천시스템, 질의응답, 자동화등산업적활용
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 80 --

74
지식그래프(Knowledge Graph)의유효함과미래적가치
이미지출처: SBS 데이터저널리즘팀마부작침X 계정
(url: https://x.com/SBSDataJ/status/1944645976872178093)
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 81 --

75
지식그래프(Knowledge Graph)의유효함과미래적가치
“지식그래프는,
현재가장유효한지식표현기술중하나”
●기술적성숙: 20년이상의연구개발로안정적기술확보
●실용성증명: 구글, 아마존등글로벌기업의핵심기술
●학술적가치: 인문학포함여러분야의새로운연구방법론
●미래지향성: 인공지능, 메타버스등차세대기술의기반
“인공지능(AI)과의시너지”
○설명가능한AI: 딥러닝의블랙박스한계보완
○퓨few-샷shot 러닝: 적은데이터로도학습가능
○지식증강: 대규모언어모델(LLM)의성능향상
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 82 --

Node
(Vertex)
A
Node
(Vertex)
C
Node
(Vertex)
B
Link
(Edge)
1
Link
(Edge)
2
네트워크그래프(Network Graph)란, 접점(Node)과개별접점을잇는연
결(Link)의형식또는꼭지점(Vertex)과꼭지점을잇는연결선(Edge)의
형태로조직되는관계망구조의그래프. 그래프상에서접점또는꼭지점에
해당하는항목을특정한정보를내포한개체(entity)로볼경우네트워크그
래프는각양각색의정보를연결한일종의지식그래프로서기능할수있다.
네트워크그래프는특정값이나항목사이의관계를
연결망형식으로표현한도형을의미한다.
지식그래프(Knowledge Graph) 구현: 네트워크그래프형식의지식연결망
76
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 83 --

isUncleOf
isFriendOf
HellBoy
MarshmallowMan
Dave
HellBoy
isUncleOf
Dave
Source
Target
Relation
HellBoy
isFriendOf
MarchmallowMan
네트워크그래프를시각화하기위해서는‘주어-서술어-목적어’ 형식의데이터를기술해야한다.
지식그래프(Knowledge Graph) 구현: Triple(S-P-O) 형식의데이터기술이핵심
77
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 84 --

78
Triplets(S-P-O)이란무엇인가?
누가? (주어: 세종대왕) 
어떻게? (서술어: 창제하다)
무엇을? (목적어: 한글)
“세종대왕이한글을창제했다.”
“셰익스피어가햄릿을저술했다.”
Triplets은‘S-P-O’의형태, 즉트리플형식의데이터를가리킨다. 
누가? (주어: 셰익스피어)
어떻게? (서술어: 저술하다) 
무엇을? (목적어: 햄릿)
Subject(주어) - Predicate(서술어) - Object(목적어)
개체
관계
개체/속성
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 85 --

79
Triplets(S-P-O)은대부분의온톨로지기반기술과관련있다.
RDF에서, 데이터의조직논리
→RDF의기본단위= Triplets, (Subject, Predicate, Object) = RDF Statement
→N-Triples 형식: <http://example.org/세종대왕> <http://example.org/창제하다> <http://example.org/한글>
SPARQL(SPARQL Protocol and RDF Query Language)에서, 질의어의구성방식
→SPARQL 쿼리= Triplets 패턴매칭, WHERE { ?subject ?predicate ?object }
→SPARQL 쿼리: SELECT ?작품WHERE { 조건ex:세종대왕ex:창제하다?대상. }
LOD(Linked Open Data)에서, 데이터의공유체계
→LOD 데이터셋= 공개된Triplets 집합, 링크= 데이터셋간Triplets 연결
→DBpedia와Wikidata 상의‘세종대왕’ 연결: dbpedia:세종(조선) owl:sameAs wikidata:Q37682 .
Triplets(S-P-O)이란무엇인가?
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 86 --

80
Triplets(S-P-O)은온톨로지기술생태계의공통분모
Triplets(S-P-O)이란무엇인가?
“대부분의온톨로지유관기술이Triplets(S-P-O)을중심으로연결되어있다.”
RDF ↔SPARQL ↔OWL ↔KnowledgeGraph ↔SemanticWeb ↔LOD
표기
●RDF 형식: (Subject, Predicate, Object)
●Graph 형식: Subject →[Predicate]→Object
●자연어: “Subject가Object를Predicate한다”
장점
●표준화: 모든지식을동일한형식으로표현함
●연결성: 다른Triplets와자연스럽게연결함
●확장성: 새로운데이터를쉽게추가할수있음
→ Triplets(S-P-O)은컴퓨터가이해하고처리할수있는기계가독형데이터라는사실이중요!
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 87 --

81
인문학에서Triplets(S-P-O)의활용은……?
Triplets(S-P-O)이란무엇인가?
활용의여지가크다?
한계가명확하다?
○관계의중심: 맥락에기초한인문학적사유와일치
○해석의단서: 복잡한논리로얽힌정보의해석시도
○지식의연계: 전공분야간지식을연결하는시도가능
●단순화위험: 복잡한지식관계를단순화할위험존재
●맥락의손실: 미묘한뉘앙스, 해석의다층성누락가능
●주관의개입: 관계정의에서연구자의주관개입가능
Triplets(S-P-O)은기본적으로정보공학영역에서활용되는기술적논리이지만, 한편으로인문학적사고를
표현하는유용한수단이될수있다. 정보를정확하게기술하는것을목적으로삼지않고, 정보들사이의유
의미한관계를명시적으로표현하는데초점을둔다면, 연구와교육의차원에서활용가능성이무궁무진하다.
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 88 --

82
Triplets 기반의데이터처리가인문학에제공하는새로운가능성은무엇인가…?
Triplets(S-P-O)이란무엇인가?
지식의관계적탐색
→개별연구를매개로파편화되어있던지식을, 온톨로지를통해통합적지식관계망으로재현
의미의명시적표현
→연구자개인의해석에의존하던의미에서, 온톨로지를통해의미적해석을정의하고공유
반성적사유의촉진
→“우리는왜이렇게맥락을정보화했는가?”라는고민을통해연구자의문제의식을명시화
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 89 --

Triplets(S-P-O) 기반데이터기술: 시맨틱데이터모델(Semantic Data Model)
종래의데이터베이스관리시스템(DBMS)의논리적데이터
구조는‘hierarchical’, ‘network’, ‘relational’ 여부와상관
없이DBMS에서사용하는구현전략에대한범위가제한되고
편향되어있기때문에, 데이터의개념적정의에대한요구사
항을완전히충족할수없었다. 이와같은이유로정교한의미
체계를서술할수있는데이터베이스모델의필요성이제기됨
에따라, Ontology와같은시맨틱데이터모델이개발되었다.
시맨틱데이터모델(Semantic Data Model): 의미체계기술을위해개발된데이터모델
83
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 90 --

그래프데이터베이스: 온톨로지를다루기에더없이좋은도구이자환경
84
GSD (Graph Schema Diagram)
그래프데이터베이스의구조를시각적으로표현하는다이어그램으로,
노드(Node)와노드간의관계(Relationship)를네트워크형태로나타낸설계도
●개체: Node, 그래프상의개체또는객체
●개체: (예시) →작가, 작품, 출판사
●관계: Edge, 개체들사이의의미적연결고리
●관계: (예시) →창작관계, 출판관계등의미적정의
●속성: Property, 개체와관계가지니는성질
●속성: (예시) →작가의국적, 작품의분량, 출판연도
○직관적관계표현: 복잡한네트워크를손쉽게시각화
○유연한구조: 새로운노드와관계를쉽게추가
○탐색적분석: 의미적관계를매개한효과적탐색
○응용가능성: 의미맥락을지닌다양한정보에활용가능
작가
(Writer)
출판사
(Publisher)
작품
(Work)
성명(String)
성별(String)
국적(String)
제목(String)
장르(String)
분량(Int)
명칭(String)
소재지(String)
설립연도(Int)
creates(창작하다)
publishes
(출판하다, year: 출판연도)
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 91 --

85
최근의기술혁신: LLM과시맨틱데이터처리기술의결합
소위Neuro-Symbolic AI 계열의연구는기호주의와연결주의가
각기안고있던문제와한계를보완하고조금더완성도높은인공
지능을구현하기위한기술적접근이라할수있다. 기호적맥락의
체계와연결적맥락의모델을어떻게종합할것인가에관한기술
적차원의고민과유관논의가현재다각도로이루어지고있다. 텍
스트를대상으로한인공지능기술개발과유관담론의영역또한
그연장선상에있다. 텍스트를대상으로한기계가독데이터처리
가기본적으로어느정도선에서유효한것인지, 지식그래프형식
의지식을신경망모델이어떻게학습할수있으며, 그결과가얼마
나효과적인지에관한검토가꾸준히이루어지고있다.
Haoran Luo 외10인, 「Graph-R1: Towards Agentic GraphRAG Framework
via End-to-end Reinforcement Learning」, 2025.07. (URL: https://arxiv.org/abs/2507.21892)
세번째이야기. 온톨로지와지식그래프에관하여

-- PAGE 92 --

사례: 지암일기데이터아카이브

-- PAGE 93 --

윤이후(尹爾厚, 1636-1699)
자는재경(載卿), 호는지암(支菴). 고산윤선도의손자이자공재윤두서의생부이다. 아버지윤의미(尹義美, 윤선도의둘째아들)가24
살에요절하였고, 어머니또한윤이후를낳고얼마되지않아식음을전폐하여목숨을끊는바람에졸지에고아가되어윤선도의슬하에서
성장했다. 1679년생원(生員)이되었고, 1689년증광시(增廣試)에급제하여, 성균관전적(成均館典籍), 병조정랑(兵曺正郞), 선혜청
랑(宣惠廳郞), 사간원정언(司諫院正言), 사헌부지평(司憲府持平)에제수되었으며, 1691년함평현감(咸平縣監) 자리에오른지1년만
에고향인해남으로돌아왔다. 숙종조남인들이화를입은‘갑술옥사(1694)’의시기를즈음하여더욱더세상에뜻을접고해남의죽도(竹
島)에별서를마련해노년을보냈으며, 이시기를즈음한약8년간의생활을기록한『지암일기』를남겼다.
윤이후가관직에서은퇴한1692년부터사망한1699년까지의기간즉, 약8년(95개월)간의삶을기록한생
활일기로서, 간척, 농사, 어로, 노비, 날씨, 교유, 여행, 통신, 유배, 시, 음악, 미술, 건축, 조경, 원예, 풍수, 의
약등조선시대양반이영위한다채로운일상정보를담고있어, 현재까지발굴된사적성격의기록가운데서
도생활관련정보가가장풍부한자료라할수있다. 또한일기의내용가운데많은부분이『조선왕조실록』과
『승정원일기』등의관찬사료의내용과연결되고, 장서각에서디지털자원으로제공중인〈해남윤씨문중고문
서〉자료와도연결되어, 향촌에은거한지역양반의입장에서쓴생활기록이정사(正史)의기록과어떻게다
른지, 일기와고문서에담긴정보가서로어떻게연결될수있는지에대한다채로운탐색이가능하다.
국내의대표적디지털인문학연구사례: 『지암일기』데이터아카이브(2016~2019)
네번째이야기. 사례: 지암일기데이터아카이브
86

-- PAGE 94 --

kakao map
『지암일기』의공간적배경: 전라남도해남, 강진, 영암일대
네번째이야기. 사례: 지암일기데이터아카이브
87

-- PAGE 95 --

흑산도(黑山島)
우이도(牛耳島)
진도(珍島)
보길도(甫吉島)
노아도(露兒島)
신지도(薪智島)
고금도(古今島)
수영(水營)
해남읍(海南邑)
강진읍(康津邑)
영암읍(靈巖邑)
목장(牧場)
속금도(束今島)
별진역(別珍驛)
팔마(八馬)
연동(蓮洞)
죽도(竹島)
백포(白浦)
병영(兵營)
구림(鳩林)
『지암일기』의공간적배경: 전라남도해남, 강진, 영암일대
88

-- PAGE 96 --

서헌강작가님사진
팔마(八馬)
89
『지암일기』의공간적배경: 전라남도해남, 강진, 영암일대

-- PAGE 97 --

죽도(竹島)
서헌강작가님사진
『지암일기』의공간적배경: 전라남도해남, 강진, 영암일대
90

-- PAGE 98 --

『지암일기』서지정보(하단)
한국학중앙연구원장서각에마이크로필름으로소장.
『지암일기』의보관: 한국학중앙연구원장서각(사본소장처)
네번째이야기. 사례: 지암일기데이터아카이브
91

-- PAGE 99 --

『지암일기』의외형: 마이크로필름상의모습
네번째이야기. 사례: 지암일기데이터아카이브
92

-- PAGE 100 --

『지암일기』의외형: 마이크로필름상의모습
네번째이야기. 사례: 지암일기데이터아카이브
93

-- PAGE 101 --

*현재『지암일기』원본은연동해남윤씨가문에서소장하고있으며,
본연구에서대상으로삼은자료는한국학중앙연구원에소장된마이크로필름이다.
조선시대일기내용을데이터로전환해서들여다본다면어떨까?
일기데이터베이스를구축하고탐구하는과정을온전히경험하게되면,
그로부터얻을수있는학술적의미와시사점이있지않을까?
『지암일기』디지털인문학연구가이루어진배경은무엇인가?
네번째이야기. 사례: 지암일기데이터아카이브
94

-- PAGE 102 --

●참여인원: 역사학, 사회학, 미학, 미술사학, 인문정보학등연구자8명
●석문·번역기간: 2013.11-2017.03(3년5개월)
●교열기간: 2017.06 – 2018.07(1년1개월)
●석문·번역본출간연월: 2020년1월
●사업구분: 한국연구재단지원인문전략연구부속디지털인문학연구
●사업기간: 2016.09-2019.08(3년)
●참여인원: 기존연구인력+ 미디어학, 문헌정보학, 컴퓨터과학전공자
●연구결과물도메인: http://jiamdiary.info
석문및번역
세미나
디지털인문학
연구사업
『지암일기』디지털인문학연구는어떻게이루어졌는가?
네번째이야기. 사례: 지암일기데이터아카이브
95

-- PAGE 103 --

RDB
(SQL)
XML
Data
Wiki
Document
JSON
Data
RDF
Data
Data
Visualization
(JavaScript)
Linked
Open Data
(SPARQL)
Ontology
Design
(OWL)
Creating
Ontology-based
Wiki Document
Converting
Wiki
to XML
Loading
XML
with RDB
Graph
DB
(Cypher)
Graph
Data
Transforming Data: Triple(S-P-O) Data
Collaborative
Research
Machine-readable
Data format
『지암일기』디지털인문학연구방법론: Semantic Data Curation
네번째이야기. 사례: 지암일기데이터아카이브
96

-- PAGE 104 --

여러연구자가협업할수있는온라인상의연구공간으로서, 미디어위키(MediaWiki) 플랫폼을구축함.
미디어위키를활용해여러연구자가함께『지암일기』원문과번역문텍스트를입력해나가면서기초데이터를축적하고,
이를바탕으로어떻게데이터를기술(記述, description)할것인지에대한기초논의를진행함. 
MediaWiki
支
庵
日
記
연구1단계: MediaWiki를활용한텍스트데이터베이스구축협업
네번째이야기. 사례: 지암일기데이터아카이브
97

-- PAGE 105 --

1697년2월26일
흐리다맑음
지금묵고있는주인(主人) 김여성(金礪聲)이내가여행할양식을마련하는데어려움을겪고있다는것을알고쌀한말, 말린해삼과
개조개약간을전별품으로주었다.
이웃사람신동걸(申東傑)이담배2파(把)를바쳤다.
지난번에고성의길에서행상을하는고(故) 병사(兵使) 목임기(睦林奇)의노(奴)를만났다. 또광주(廣州) 경안(慶安)에서몇년전
에상둔덕(上屯德)으로유배온상놈이있는데, 목임기의노와동행하여견내량(見乃梁) 나루를함께건너왔다. 그사람이오늘와서
만났는데, 담배1파(把)를바쳤다. 그도양식조달에어려움을겪고있으면서나에게음식을준것이니, 인정이가상하다.
이곳은해산물이부족한것은아니지만, 값이비싸얻기어렵다. 우럭조개와개조개는홍합처럼맛이단데, 해남에는없다고한다. 노
인(奴人)에게분부하여행낭에넣도록했다.
김봉학(金奉鶴)이말먹이콩세되를보냈다.
윤별감(別監)이담배1파, 해삼, 우럭조개약간을전별품으로보냈다. 마을사람모두가헤어지기아쉬워하니진실로고맙다.
이마을동쪽으로3리쯤되는곳에작은암자가있는데산방사(山房寺)라고부른다. 노승지종(智宗)이와서알현했다.
○종아(宗兒)에게권면하고경계하라는내용의시를지어주었다.
육순옹이젊은아들을방문하니, 궁벽한산골봄바람불고눈이개었을때라네
네가이곳에서열심히반성하여, 나중에올바른사람이되기를바라노라
일기,
Diary
내용,
Entry
작품
Literature
연구2단계: 데이터설계를위한기초체계마련
네번째이야기. 사례: 지암일기데이터아카이브
98

-- PAGE 106 --

1697년2월26일
흐리다맑음
지금묵고있는주인(主人) 김여성(金礪聲)이내가여행할양식을마련하는데어려움을겪고있다는것을알고쌀한말, 말린해삼과
개조개약간을전별품으로주었다.
이웃사람신동걸(申東傑)이담배2파(把)를바쳤다.
지난번에고성의길에서행상을하는고(故) 병사(兵使) 목임기(睦林奇)의노(奴)를만났다. 또광주(廣州) 경안(慶安)에서몇년전
에상둔덕(上屯德)으로유배온상놈이있는데, 목임기의노와동행하여견내량(見乃梁) 나루를함께건너왔다. 그사람이오늘와서
만났는데, 담배1파(把)를바쳤다. 그도양식조달에어려움을겪고있으면서나에게음식을준것이니, 인정이가상하다.
이곳은해산물이부족한것은아니지만, 값이비싸얻기어렵다. 우럭조개와개조개는홍합처럼맛이단데, 해남에는없다고한다. 노
인(奴人)에게분부하여행낭에넣도록했다.
김봉학(金奉鶴)이말먹이콩세되를보냈다.
윤별감(別監)이담배1파, 해삼, 우럭조개약간을전별품으로보냈다. 마을사람모두가헤어지기아쉬워하니진실로고맙다.
이마을동쪽으로3리쯤되는곳에작은암자가있는데산방사(山房寺)라고부른다. 노승지종(智宗)이와서알현했다.
○종아(宗兒)에게권면하고경계하라는내용의시를지어주었다.
육순옹이젊은아들을방문하니, 궁벽한산골봄바람불고눈이개었을때라네
네가이곳에서열심히반성하여, 나중에올바른사람이되기를바라노라
인물,
Person
노비,
Slave
공간,
Place
물품,
Object
용어
Term
연구2단계: 데이터설계를위한기초체계마련
네번째이야기. 사례: 지암일기데이터아카이브
99

-- PAGE 107 --

수물(受物)
1697년2월26일
흐리다맑음
지금묵고있는주인(主人) 김여성(金礪聲)이내가여행할양식을마련하는데어려움을겪고있다는것을알고쌀한말, 말린해삼과
개조개약간을전별품으로주었다.
이웃사람신동걸(申東傑)이담배2파(把)를바쳤다.
지난번에고성의길에서행상을하는고(故) 병사(兵使) 목임기(睦林奇)의노(奴)를만났다. 또광주(廣州) 경안(慶安)에서몇년전
에상둔덕(上屯德)으로유배온상놈이있는데, 목임기의노와동행하여견내량(見乃梁) 나루를함께건너왔다. 그사람이오늘와서
만났는데, 담배1파(把)를바쳤다. 그도양식조달에어려움을겪고있으면서나에게음식을준것이니, 인정이가상하다.
이곳은해산물이부족한것은아니지만, 값이비싸얻기어렵다. 우럭조개와개조개는홍합처럼맛이단데, 해남에는없다고한다. 노
인(奴人)에게분부하여행낭에넣도록했다.
김봉학(金奉鶴)이말먹이콩세되를보냈다.
윤별감(別監)이담배1파, 해삼, 우럭조개약간을전별품으로보냈다. 마을사람모두가헤어지기아쉬워하니진실로고맙다.
이마을동쪽으로3리쯤되는곳에작은암자가있는데산방사(山房寺)라고부른다. 노승지종(智宗)이와서알현했다.
○종아(宗兒)에게권면하고경계하라는내용의시를지어주었다.
육순옹이젊은아들을방문하니, 궁벽한산골봄바람불고눈이개었을때라네
네가이곳에서열심히반성하여, 나중에올바른사람이되기를바라노라
생활,
Lifestyle
사건,
Event
*1697년2월26일자일기는‘윤종서거제적소방문행’ 사건을다루는기록이다.
자료
Reference
*1696년8월11일자『승정원일기』11번째기사는‘윤종서의처벌’에관한내용을다룬다.
연구2단계: 데이터설계를위한기초체계마련
네번째이야기. 사례: 지암일기데이터아카이브
100

-- PAGE 108 --

『지암일기』
텍스트를이루는형식요소
문맥에서추출한내용요소
문맥을재구성한의미요소
구성요소
구성요소
구성요소
구성요소
개별일자일기
개별일자일기
개별일자일기
내용1
내용2
내용3
작품
포함하거나
동등한요소
인물
노비
공간
물품
문헌
용어
사건
생활
자료
연구2단계: 데이터설계를위한기초체계마련
네번째이야기. 사례: 지암일기데이터아카이브
101

-- PAGE 109 --

『지암일기』데이터클래스다이어그램
- 일기(Diary)
- 작품(Literature)
- 내용(Entry)
- 인물(Person)
- 노비(Slave)
- 공간(Place)
- 물품(Object)
- 문헌(Book)
- 용어(Term)
- 생활(Lifestyle)
- 사건(Event)
- 자료(Reference)
연구3단계: 온톨로지(Ontology) 디자인
네번째이야기. 사례: 지암일기데이터아카이브
102

-- PAGE 110 --

MediaWiki
Database
XML
Document
RDB
(SQL)
Data Sheet
(EXCEL)
Creating an XML document
from the contents of a Wiki page
produced by many researchers.
Putting XML data into RDB.
The data(EXCEL) is shared and 
reviewed
by individual researchers.
Use SQL
to secure basic data 
sheets
연구4단계: 데이터편찬(Data Compilation)
네번째이야기. 사례: 지암일기데이터아카이브
103

-- PAGE 111 --

Node 데이터: 총17,900 여건
Edge 데이터: 총약64,300 여건
●일기(Diary) : 2,918건
●작품(Literature) : 243건
●내용(Entry) : 9,135건
●인물(Person) : 2,521건
●공간(Place) : 848건
●노비(Slave) : 252건
●물품(Object) : 666건
●문헌(Book) : 64건
●용어(Term) : 733건
●생활(Lifestyle) : 70건
●사건(Event) : 255건
●참고자료(Reference) : 186건
●작품(Literature) 기준: 236건
●내용(Entry) 기준: 62,370건
●인물(Person) 기준: 1,371건
●노비(Slave) 기준: 323건
연구4단계: 데이터편찬(Data Compilation)
네번째이야기. 사례: 지암일기데이터아카이브
104

-- PAGE 112 --

미디어위키(MediaWiki)
텍스트데이터베이스구축
파이썬(Python)
시각화를위한데이터프로세싱
네오포제이(Neo4j)
그래프데이터베이스구축
아파치제나푸세키(Apache Jena Fuseki)
링크드오픈데이터(LOD) 구축
디쓰리제이에스(D3.js)
데이터시각화구현
리플릿제이에스(Leaflet.js)
공간데이터시각화구현
연구5단계: 다양한기술을활용한데이터처리(Data Processing)와결과물구현
네번째이야기. 사례: 지암일기데이터아카이브
105

-- PAGE 113 --

텍스트데이터베이스
그래프데이터베이스
링크드오픈데이터(LOD)
생활데이터캘린더뷰시각화
인물데이터네트워크시각화
공간데이터전자지도시각화
사건데이터타임라인시각화
노비데이터컨셉트맵시각화
Database
Construction
Data
Visualization
연구5단계: 다양한기술을활용한데이터처리(Data Processing)와결과물구현
네번째이야기. 사례: 지암일기데이터아카이브
106

-- PAGE 114 --

XML
JSON
RDF
CSV
웹환경에서보편적으로통용되는표준적포맷의데이터공유.
XML과RDF 포맷의데이터는시맨틱웹아키텍쳐를구성하는핵심
적인웹언어이자데이터포맷으로서해당데이터를웹환경에서공
유한다는것은시맨틱웹기반의데이터를자유롭게활용할수있다
는것을의미한다.
JSON은자바스크립트(JavaScript)를토대로개발되었으며, 데이
터객체를속성·값의쌍형태로표현하는형식이다. 여러프로그래밍
언어와연계해서사용할수있는독립형언어이며, 텍스트로기술하
여사람도쉽게읽고작성할수있다.
CSV는쉼표(comma)를기준으로항목을구분하여저장한데이터
를말한다. 엑셀과같은데이터처리소프트웨어를통해편집·저장하
는것이가능한보편적데이터포맷이다.
연구6단계: 데이터공유③RDF, XML, JSON, CSV 등다양한포맷의데이터지원
네번째이야기. 사례: 지암일기데이터아카이브
107

-- PAGE 115 --

지암일기
위키
페이지
지암일기
시각화
페이지
Wiki DB
RDB(SQL)
Graph DB(No-SQL)
웹서비스
지암일기
LOD
페이지
지암일기
DATA 다운로드
페이지
지암일기
Graph DB
페이지
서버에Media wiki 설치
XML 전자문서를통해작성된
지암일기텍스트(원문, 석문, 역문)를
서버에설치된Wiki DB의위키문서로변환
서버에Maria DB 설치
AWS(아마존웹서버) 호스팅
웹서버및DB
온톨로지설계
설계된온톨로지내용을토대로
XML 전자문서와엑셀데이터정리
RDB에구축된데이터를
Cypher Query를이용해서
Graph DB 형식으로전환
XML
RDF
OWL
RDF
NoSQL
서버에구축한Noe4j 웹페이지를통해
시맨틱그래프데이터베이스서비스제공
RDB에구축된데이터를JSON과CSV 포맷으로변환
기존에구축된XML 전자문서및RDF 데이터와함께
총4가지포맷으로다운로드데이터제공
온톨로지명세서(OWL)를작성하고그에기초하여
RDB에구축된데이터를RDF 형식으로변환함으로써
이데이터를활용해LOD 서비스제공
RDB에서SQL을이용해시각화에필요한데이터를추출하고
PYTHON을이용해해당데이터를가공한다음
D3.JS를이용해데이터와시각요소연계해서시각화구현
서버에구축한Wiki DB를통해
원문이미지/석문/번역문텍스트정보서비스제공
XML 전자문서와엑셀을
통해정리한전체데이터를
RDB에입력
서버에Neo4j 설치
지암일기원문/번역문서비스
지암일기시각화콘텐츠서비스
지암일기데이터검색및공유서비스
전체시스템개발절차
네번째이야기. 사례: 지암일기데이터아카이브
108

-- PAGE 116 --

「데이터로읽는17세기재지사족의일상」
-『지암일기(1692-1699)』데이터베이스편찬연구-
http://dh.aks.ac.kr/~red/wiki/index.php/JiamDiary
http://jiamdiary.info
『지암일기』연구를통해정리된원자료이미지, 해독문과번역문텍스트를포
함해, 각종데이터베이스와시각화구현결과물및여러포맷의데이터에이르
기까지, 모든연구내용을정리·제공하고있다.
『지암일기』디지털인문학연구배경및과정그리고
결과물을분석하고해석한내용을정리한연구논문.
연구7단계: 연구과정과결과물을정리한웹사이트론칭과논문발표
네번째이야기. 사례: 지암일기데이터아카이브
109

-- PAGE 117 --


==== FILE: 온톨로지와 지식그래프 실습.pdf ====


-- PAGE 1 --

(¨\À| 0˘<\ \
ÀÝ øŸ| 0˘<\ \
•É ˝D¤ lX0
tä¤ Ìlõ

-- PAGE 2 --

¬ Ái
(¨\À X ãà  µx tt 

-- PAGE 3 --

¬ Ái
(¨\À X ãà  µx tt 
üp lD `  ¨—
´»„ h9´|`À t H 4

-- PAGE 4 --

¬ Ái
(¨\À X ãà  µx tt 
(ÜÐ  \ Á )
D! (¨\Àﬂ ä˝\ t„ Ý¼lŸ
D! (¨\Àﬂ ä˝\ t„ ¬©t ü ˘ ‹lŸ
(x¬t¸) 
üp... °ü<D T Ÿ Ìä0 t˝ﬂ(
(¨\À 0˘ ÀÝ øŸ  T Ÿ $Ä˘´| X$
üp... (¨\À 0˘ ÀÝ øŸ| T Ÿ $ÄX0 t˝ﬂ(
°m È8(t°Xà’ Xﬂ 8˝)•0 –Ut|XﬂlŸ!
üp lD `  ¨—
´»„ h9´|`À t H 4
l  Ð˝ ´x p À tt ( ¡0)
Ð ôtﬂ üü °ü< Ux
ä(\ ˝D¤ Ìä0
tä¤ Ìlõ ($Ÿ)

-- PAGE 5 --

¬ Ái
(¨\À X ãà  µx tt 
(ÜÐ  \ Á )
D! (¨\Àﬂ ä˝\ t„ Ý¼lŸ
D! (¨\Àﬂ ä˝\ t„ ¬©t ü ˘ ‹lŸ
(x¬t¸) 
üp... °ü<D T Ÿ Ìä0 t˝ﬂ(
(¨\À 0˘ ÀÝ øŸ  T Ÿ $Ä˘´| X$
üp... (¨\À 0˘ ÀÝ øŸ| T Ÿ $ÄX0 t˝ﬂ(
°m È8(t°Xà’ Xﬂ 8˝)•0 –Ut|XﬂlŸ!
üp lD `  ¨—
´»„ h9´|`À t H 4
l  Ð˝ ´x p À tt ( ¡0)
Ð ôtﬂ üü °ü< Ux
ä(\ ˝D¤ Ìä0
tä¤ Ìlõ ($Ÿ)

-- PAGE 6 --

¬ Ái
(¨\À X ãà  µx tt 
t˝ (¨\À  TÀ Uä‹ L€´.
tx ´»„ ˝D¤Ð˝ ð„  ÀÄ ’ð¤ý„ ø$8!
(¨\À 0˘ ÀÝ øŸ $Ä ¹È
´|
l  Ð˝ ´x p À tt ( ¡0)
Ð ôtﬂ üü °ü< Ux
ä(\ ˝D¤ Ìä0
tä¤ Ìlõ ($Ÿ)
üp lD `  ¨—
´»„ h9´|`À t H 4
(ÜÐ  \ Á )
D! (¨\Àﬂ ä˝\ t„ Ý¼lŸ
D! (¨\Àﬂ ä˝\ t„ ¬©t ü ˘ ‹lŸ
(x¬t¸) 
üp... °ü<D T Ÿ Ìä0 t˝ﬂ(
(¨\À 0˘ ÀÝ øŸ  T Ÿ $Ä˘´| X$
üp... (¨\À 0˘ ÀÝ øŸ| T Ÿ $ÄX0 t˝ﬂ(
°m È8(t°Xà’ Xﬂ 8˝)•0 –Ut|XﬂlŸ!

-- PAGE 7 --

¬ Ái
(¨\À X ãà  µx tt 
t˝ (¨\À  TÀ Uä‹ L€´.
tx ´»„ ˝D¤Ð˝ ð„  ÀÄ ’ð¤ý„ ø$8!
(¨\À 0˘ ÀÝ øŸ $Ä ¹È
´|
(¨\À Á $Ä
˝D¤ Ü\ D1
¨ (tä¤)
üp lD `  ¨—
´»„ h9´|`À t H 4
(ÜÐ  \ Á )
D! (¨\Àﬂ ä˝\ t„ Ý¼lŸ
D! (¨\Àﬂ ä˝\ t„ ¬©t ü ˘ ‹lŸ
(x¬t¸) 
üp... °ü<D T Ÿ Ìä0 t˝ﬂ(
(¨\À 0˘ ÀÝ øŸ  T Ÿ $Ä˘´| X$
üp... (¨\À 0˘ ÀÝ øŸ| T Ÿ $ÄX0 t˝ﬂ(
°m È8(t°Xà’ Xﬂ 8˝)•0 –Ut|XﬂlŸ!
l  Ð˝ ´x p À tt ( ¡0)
Ð ôtﬂ üü °ü< Ux
ä(\ ˝D¤ Ìä0
tä¤ Ìlõ ($Ÿ)

-- PAGE 8 --

ì‹ `ä¨8\ (¨\À,
\ ‹ T Úà ˘´Üä.

-- PAGE 9 --

(¨\À•?
현실 세계의 사물(Concept)과 
그들 간의 관계(Relation)를 
컴퓨터가 이해할 수 있는 언어로 
명시화한 구조적 설계
ôè0
€Y (D¬¤€T¤ H)
8ÁÐ t¬Xﬂ ¨à …ä@ ˝Pü  Ä(ð°)\ \  ˘ ‹ä.
}„ Ðt, ôè0Ð„ üﬂ 8ÁD ttXﬂ ¬t’ ÜY˝.
"¬„@ ä¬  P ˝ä", "¬üﬂ ü|tä" ˇ@ ÀÝD 0Ä  LDäD ˘ ‹ﬂ ì÷<\ }“\ ….

-- PAGE 10 --

xX tt
lpT ü
`사람(Person)` 개념은 `학생(Student)` 개념을 포함한다.
`혼잡시간(BusyTime)`, `운영시간(OpenTime)` 개념은 모두 `시간대(TimePeriod)`의 속성을 상속받는다
ôè0  tt` ˘ ‹„ ì
(.xml, .ttl | ñ)
D1˝ $ÄÄ  \ (¨\À
(¨\À•?

-- PAGE 11 --

xX tt
lpT ü
`사람(Person)` 개념은 `학생(Student)` 개념을 포함한다.
`혼잡시간(BusyTime)`, `운영시간(OpenTime)` 개념은 모두 `시간대(TimePeriod)`의 속성을 상속받는다
ôè0  tt` ˘ ‹„ ì
D1˝ $ÄÄ  \ (¨\À
(¨\À•?
t˝ ˝ä˝ pt0˛|
(¨\À $ÄÄ| 0| lŁ\ ˝
D\„ (¨\À 0˘ ˝ÀÝ øŸ"  ˝ä.

-- PAGE 12 --

\ (¨\À (¨\À XŸ?

-- PAGE 13 --

(¨\À  ÆX ôè0 8Á
¬„ 1
¬„ 2
xX ¬„ Ì  $ÄÄ
ù\X (¨\À
˝´| 9D p ﬂœ•˛
`... ´| D(äX ? øü tÀ KK
˝D(äXp tŸ 9’˛
¬„ 1
˙ ôè0
˝´| 9D p ﬂœ•˛
...
¬„ 1
àx AI
˝´| 9D p ﬂœ•˛
„ ÀÐ ½ }0
8Át °µÐ?
AIX ¨¸..
..
if ¬©’  ˝´|"t|à Xt...
if ¬©’  ˝9D p"|à Xt...
if D  $t...
... => return 
(1950 ~ 1970D

-- PAGE 14 --

(¨\À  ‹ﬂ ôè0 8Á
¬„ 1
à (¨\À 0˘ õÀ
˝´| 9D p ﬂœ•˛
´| ™ €Ü ™ 2025.01.15 ™
€( ™ P¼ ™ 90 ‰@ LÝ
™ 
온톨로지(미리 구조화한 지식) 위에서
관계를 이해하고 
의미 기반(Semantics) 추론 가
øìŸ, t ¨à  Ä| XXà ð°Xﬂ 
0 lŁ D©t Dø˝  x [D » 
(1980 ~ 1990D
AIX ¨¸@ ]ŸÀ JXä.

-- PAGE 15 --

xõ à½ÝX 1õ,   AI Ü , (¨\ÀX ¬É
¬„ 1
LLM
˝´| 9D p ﬂœ•˛
¬„ 1
Vector RAG
˝8˝ 0˘<\
´| 9D p ﬂœ•˛
문서를 읽는다
비슷한 부분을 가져와서 말해준
Black box
¨tt `èÜ$tX
U` u4È
Xø@  Ä  DÌ
è˝ HÄ@  ¬Ä 0˘
LLM@ è˝‹ ˝U`", ˝ ¬Ä" |  Àà õÀ\ä.
›, °üÐ  \ üp| ˝ÜXÀ » \ä.

-- PAGE 16 --

  XøX (¨\À
(¨\Àﬂ AIÐ„ |¬ ¬àX Àü )¸(Fact)| ˝õ\ä. 
t| µt AIﬂ pÓÐD XÀ Jà, 
øŸX ð°  Ä| üp\ "A|˝ Btà, B|˝ Ctä"|à $–` ˘ ‹„ ˝ä.
=> $–  ¥\ AI (eXplainable AI - XAI) \˝X Xø| „ (. P
=> LLM<\ xt 0 lŁ D©Ä ´Ð.

-- PAGE 17 --

(¨\À| 0˘<\ \
ÀÝ øŸ| 0˘<\ \
•É ˝D¤ lX0

-- PAGE 18 --

(¨\À| 0˘<\ \
ÀÝ øŸ| 0˘<\ \
•É ˝D¤ lX0
lpT˝ ÀÝ $ÄÄ| 0˘<\
ä˝ pt0| $Ä  lŁXà
$–  ¥\ •É ˝D¤ lX0
l´T

-- PAGE 19 --

(¨\À| 0˘<\ \
ÀÝ øŸ| 0˘<\ \
•É ˝D¤ lX0
lpT˝ ÀÝ $ÄÄ| 0˘<\
ä˝ pt0| $Ä  lŁXà
$–  ¥\ •É ˝D¤ lX0

-- PAGE 20 --

äµ X½ lŁ
Google Antigravity IDE 다운로드 
https://antigravity.google/
실습 데이터 셋 다운로드 후 Antigravity로 폴더 열기 
https://drive.google.com/drive/folders/1PFC1LpakqQzBgAGwrmAdKVU3ZYZbkeJW?usp=sharing
노션 가이드 열어두기 
https://dramatic-ceiling-522.notion.site/Graph-RAG-2e64f85249428026a715f49093a5a65b
Google AI API 준

-- PAGE 21 --

\©` pt0 1: ˝¸ YP YÝ ô (ù ldÁ)
식당이 다양함
메뉴도 매우 다양함
가격, 운영 시간, 혼잡 시간 등 존재
 => 다양한 관계를 정의하고 복합적인 질의 가
 Ý t 
menus.json

-- PAGE 22 --

\©` pt0 2: t<Ä X pt0 (tt$õ API)
식당 건물의 위치 정보와 특정 위치 정보를 기반으로 
보다 실용적인 서비스 구축
서로 다른 DB를 지식 그래프로 중앙화하는 사례
서울대는 캠퍼스가 매우 커서 식당 위치가 중요함..
 Ý t 
venues_location.json

-- PAGE 23 --

lŁ 1èÄ: pt0  õÀt|Xﬂ È8 l1X0 P
온톨로지 기반 지식 그래프는 “모든 질문에 대답하는 만능 AI”를 목적으로 구축된 것이 아니다.
오히려 어디로 튈지 모르는 LLM을 더 통제 가능하게, 우리가 정의한 개념과 관계 영역 내에서 검색하고 
근거를 제시하게끔 설계된 것.
그러기 위해서는 데이터가 답변해야하는 질문(문제 의식)이 명확해야한다
\  ¥ <  È8D l1t|Xﬂ ?
Ü) $Ÿ ì<\ h¬ 9D ˘ ‹ﬂ üŸ |Ý Tt ﬂœt˘
=> ˝$Ÿ˛, ˝ì", ˝h¬", ˝üŸ", ˝|Ý"Ð  t Xø@  Ä| ttXà Qõ  ¥XÄ] (¨\À  lŁ˘´| h.
$Ÿ ™ 2025.01.16
Ýù ™ ì Ü ™ 11:00 ~ 14:00
  Ýù ™ <¡ Ü ™ 12:00 ~ 13:00
Ü$ |X ™ ﬂ¬ —X ™ Japan
È8t –UXÀ Jät ˝Pü  Ä| XXà è` 0 t Æﬂ ….
¨àx ä X€äﬂ …@ D4…Ä XÀ J€äﬂ …ü ˇL.

-- PAGE 24 --

lŁ 1èÄ: pt0  õÀt|Xﬂ È8 l1X0 P => $Ÿ ˘Å tÄ
온톨로지 기반 지식 그래프는 “모든 질문에 대답하는 만능 AI”를 목적으로 구축된 것이 아니다.
오히려 어디로 튈지 모르는 LLM을 더 통제 가능하게, 우리가 정의한 개념과 관계 영역 내에서 검색하고 
근거를 제시하게끔 설계된 것.
그러기 위해서는 데이터가 답변해야하는 질문(문제 의식)이 명확해야한다
\  ¥ <  È8D l1t|Xﬂ ?
Ü) $Ÿ ì<\ h¬ 9D ˘ ‹ﬂ üŸ |Ý Tt ﬂœt˘
=> ˝$Ÿ˛, ˝ì", ˝h¬", ˝üŸ", ˝|Ý"Ð  t Xø@  Ä| ttXà Qõ  ¥XÄ] (¨\À  lŁ˘´| h.
$Ÿ ™ 2025.01.16
Ýù ™ ì Ü ™ 11:00 ~ 14:00
  Ýù ™ <¡ Ü ™ 12:00 ~ 13:00
Ü$ |X ™ ﬂ¬ —X ™ Japan
È8t –UXÀ Jät ˝Pü  Ä| XXà è` 0 t Æﬂ ….
¨àx ä X€äﬂ …@ D4…Ä XÀ J€äﬂ …ü ˇL.
°ü L¤¸| \ È8 ©]: competency_questions.md

-- PAGE 25 --

lŁ 2èÄ: È8Ð Qõ  ¥\ (¨\À 0˘ ÀÝ øŸ lŁ => ´|
“질문 기반” 도메인 온톨로지 구축 (Protege 등 활용) => tbox.ttl
실제 데이터로 만들어낸 지식 그래프 구축 => abox.ttl

지식 그래프 내 각 데이터들이 정의한 온톨로지의 규칙을 어기지 않는지 검증 (SHACL 활용)
필수 값 체크: 모든 Menu는 반드시 price 속성을 1개 가져야 한다.
타입 체크: price의 값은 문자열이 아닌 정수(Integer)여야 한다.
범위 체크: price는 0보다 커야 한다.
검증된 데이터에 추론기(Reasoner)를 돌려서 암묵적 관계 찾고 지식 확장
입력 (Fact): "301동 식당은 301동에 있다." + "301동은 공과대학 구역에 속한다."
규칙 (Rule): “A ( B 이고 B ( C 이면, A ( C 이다." (장소의 전이성)
결과 (Inference): "301동 식당은 공과대학 구역에 있다." (새로운 데이터 생성)

검증과 추론을 마친 최종 지식 그래프 도

-- PAGE 26 --

lŁ 2èÄ: È8Ð Qõ  ¥\ (¨\À 0˘ ÀÝ øŸ lŁ => ´|
“질문 기반” 도메인 온톨로지 구축 (Protege 등 활용) => tbox.ttl
실제 데이터로 만들어낸 지식 그래프 구축 => abox.ttl

지식 그래프 내 각 데이터들이 정의한 온톨로지의 규칙을 어기지 않는지 검증 (SHACL 활용)
필수 값 체크: 모든 Menu는 반드시 price 속성을 1개 가져야 한다.
타입 체크: price의 값은 문자열이 아닌 정수(Integer)여야 한다.
범위 체크: price는 0보다 커야 한다.
검증된 데이터에 추론기(Reasoner)를 돌려서 암묵적 관계 찾고 지식 확장
입력 (Fact): "301동 식당은 301동에 있다." + "301동은 공과대학 구역에 속한다."
규칙 (Rule): “A ( B 이고 B ( C 이면, A ( C 이다." (장소의 전이성)
결과 (Inference): "301동 식당은 공과대학 구역에 있다." (새로운 데이터 생성)

검증과 추론을 마친 최종 지식 그래프 도출 => abox_inferred.tt
abox_inferred.ttl

-- PAGE 27 --

t˝ °¬ﬂ?
명확한 질문을 가지고 있다.
이 질문이 바로 데이터를 통해 해결하고자 하는 “문제”이다
질문을 해결해줄 수 있는 방식으로 온톨로지를 설계했다
온톨로지(설계도)를 기반으로 검증과 추론을 마친 지식 그래프(실제 데이터)를 가졌다.
이를 (주어) - (술어) - (목적어) 구조의 .ttl 파일 형식으로 표현했다
øìŸ |@ || Ð... ä˝\  ¬  ¥X„ tüﬂ Äl  Dﬂ
tl rdflib |tì¬
ttl |D }à
T¨¬Ð øŸ| Ý1Xà
SPARQL 8ŁD µ\ pt0 •É  p‚ ÀÐ

-- PAGE 28 --

ÀÝ øŸ 0˘ •É ˝D¤ $Ä
    ’ð´\ ÈX
˝P $Ä
ÀÝ øŸÐ˝ ô p„
p„˝ ô| 0˘<\ õÀ ˝õ

-- PAGE 29 --

ÀÝ øŸ 0˘ •É ˝D¤ $Ä
    ’ð´\ ÈX
˝P $Ä
l $Ä
User
LLM
질문 의도 파악
온톨로지 구성 정보와 매핑
데이터 조회 코드 (SPARQL) 작
LLM
˙@ pt0| 0˘<\ ÈXÐ Þﬂ ﬂ} Ý1
Graph DB (In Memory)
Ý1˝ SPARQLÐ 0| pt0| QD˝ ì
’ð´ ÈX
User
\– °ü Ux  X¬°
ÀÝ øŸÐ˝ ô p„
p„˝ ô| 0˘<\ õÀ ˝õ

-- PAGE 30 --

ÀÝ øŸ 0˘ •É ˝D¤ $Ä
    ’ð´\ ÈX
˝P $Ä
l $Ä
User
LLM
질문 의도 파악
온톨로지 구성 정보와 매핑
데이터 조회 코드 (SPARQL) 작
LLM
˙@ pt0| 0˘<\ ÈXÐ Þﬂ ﬂ} Ý1
Graph DB (In Memory)
Ý1˝ SPARQLÐ 0| pt0| QD˝ ì
’ð´ ÈX
User
\– °ü Ux  X¬°
ÀÝ øŸÐ˝ ô p„
p„˝ ô| 0˘<\ õÀ ˝õ

-- PAGE 31 --

데이터 조회 코드 (SPARQL) 작
받은 데이터를 기반으로 질의에 맞는 요약 생
생성된 SPARQL에 따라 데이터를 뽑아서 전
자연어 질
최종 결과 확인 및 의사결
$–  ¥\ AI\˝ 0¥XÄ] ˝D¤T
: Python Streamlit ¬©Xì ù UI lŁ
User: 자연어 질의
LLM: 데이터 조회 코드 (SPARQL) 작성
내 질문의 의미를 보고 이렇게 조회를 했구나
Graph: 생성된 SPARQL에 따라 데이터를 뽑아서 전달
그 결과 이런 결과가 뽑혔구나
이 결과는 이런 “의미를 기반으로 연결”되는구나
LLM: 받은 데이터를 기반으로 질의에 맞는 요약 생성
그 결과를 바탕으로 이렇게 대답한거구나
User: 최종 결과 확인 및 의사결

-- PAGE 32 --

추가적으로 해결하고 싶은 질문은 무엇인가요
그 질문을 온톨로지로 해결할 수 있을까요
데이터 추가 수집이 더 필요하진 않을까요?
외부 API 활용이 필요하게 될까요?
LLM에서 개선이 필요한 부분은 없을까요?
..

-- PAGE 33 --

¬ Ái
(¨\À X ãà  µx tt 
t˝ (¨\À  TÀ Uä‹ L€´.
tx ´»„ ˝D¤Ð˝ ð„  ÀÄ ’ð¤ý„ ø$8!
(¨\À 0˘ ÀÝ øŸ $Ä ¹È
´|
(¨\À Á $Ä
˝D¤ Ü\ D1
¨ (tä¤)
üp lD `  ¨—
´»„ h9´|`À t H 4
(ÜÐ  \ Á )
D! (¨\Àﬂ ä˝\ t„ Ý¼lŸ
D! (¨\Àﬂ ä˝\ t„ ¬©t ü ˘ ‹lŸ
(x¬t¸) 
üp... °ü<D T Ÿ Ìä0 t˝ﬂ(
(¨\À 0˘ ÀÝ øŸ  T Ÿ $Ä˘´| X$
üp... (¨\À 0˘ ÀÝ øŸ| T Ÿ $ÄX0 t˝ﬂ(
°m È8(t°Xà’ Xﬂ 8˝)•0 –Ut|XﬂlŸ!
l  Ð˝ ´x p À tt ( ¡0)
Ð ôtﬂ üü °ü< Ux
ä(\ ˝D¤ Ìä0
tä¤ Ìlõ ($Ÿ)

-- PAGE 34 --

D! (¨\Àﬂ ä˝\ t„ Ý¼lŸ
¹ ÄTx ÀÝX lpT˝ $ÄÄ
LLMX \Ä| ùõ` ˘ ‹ﬂ Äl\ äÜ ü©˙ﬂ 
üp... °ü<D T Ÿ Ìä0 t˝ﬂ
(¨\À 0˘ ÀÝ øŸ  T Ÿ $Ä˘´| X$
원천 데이터 자체에 파싱 오류 등이 없는가?
준비된 질문에 답변하기에 원천 데이터가 충분한가?
준비된 질문에 답변하기에 온톨로지가 충분히 엄밀한가?
온톨로지는 충분히 검증되고 추론되었는가?
 + LLM이 데이터를 충분히 잘 검색할 수 있게 지도했는가
D! (¨\À| ä˝\ t„ ¬©t ü ˘ ‹lŸ
Xø@  Ä 0˘X šp|  Àà $–Xﬂ AI
©\ ì1 •

-- PAGE 35 --

FIN.
©\ ì1 •
üp... (¨\À 0˘ ÀÝ øŸ| T Ÿ $ÄX0 t˝ﬂ(
°m È8•0 –Ut|XﬂlŸ!

-- PAGE 36 --

FIN.
©\ ì1 •
üp... (¨\À 0˘ ÀÝ øŸ| T Ÿ $ÄX0 t˝ﬂ(
°m È8•0 –Ut|XﬂlŸ!
t°Xà’ Xﬂ 8˝  4Çx ?

-- PAGE 37 --

FIN.
©\ ì1 •
üp... (¨\À 0˘ ÀÝ øŸ| T Ÿ $ÄX0 t˝ﬂ(
°m È8•0 –Ut|XﬂlŸ!
****˝D¤ $ÄX uì**
***
t°Xà’ Xﬂ 8˝  4Çx ?

-- PAGE 38 --

FIN.
©\ ì1 •
üp... (¨\À 0˘ ÀÝ øŸ| T Ÿ $ÄX0 t˝ﬂ(
°m È8•0 –Ut|XﬂlŸ!
****˝D¤ $ÄX uì**
***
àü... Ü‚XT|€à?
t°Xà’ Xﬂ 8˝  4Çx ?

==== FILE: 발표자료(김응희).pdf ====


-- PAGE 1 --

온톨로지및지식그래프: 2차수업
When Ontology Met Machine learning
김응희
eungheekim@snu.ac.kr
2026.01.20.
1 / 125

-- PAGE 2 --

출처: <해리가 샐리를 만났을 때> 포스터 ⓒ 씨네그루
·  출처: reel.real.english (https://www.youtube.com/shorts/DvaZKcgEgMA)
발표자료 개요
2 / 125

-- PAGE 3 --

발표자료 개요
자료요약
Harry Burns
냉소적 현실주의자, 논리 무장 회의론자
논리와 규칙으로 세상을 닫는 성향
Sally Albright
낙관적 이상주의자, 정서 중심 질서정연
감정과 관계로 세상을 여는 성향
상이한 특성
소통 충돌
오해 유발
공통 언어
따뜻한 감정 창발
영화 한 줄 요약
Ontology
명시적 지식 설계자, 규칙 기반 지식 관리자
정의와 제약으로 세계를 규정
Machine learning
확률적 감각의 학습자, 데이터 기반 적응자
통계적 경험으로 세계를 확장
상이한 패러다임
표현 간극
규칙과잉 · 통계착시
상호 보완
기술적 시너지 창발
발표 한 줄 요약
3 / 125

-- PAGE 4 --

발표자료 개요
자료구성
• 발표자료 개요
• 기계학습과 데이터
• 온톨로지가 기계학습을 만났을 때
【1차 수업】
김홍기 교수님
【1차 특강】
팀빌딩  프로그램
【2차 수업】
김응희 교수님
【3차 수업】
김학래 교수님
…
국내 온톨로지
도입·확산 선구자
4 / 125

-- PAGE 5 --

기계학습과 데이터
5 / 125

-- PAGE 6 --

기계학습과 데이터
Take-home messages I
• Representative image of deep learning
?
!
6 / 125

-- PAGE 7 --

기계학습과 데이터
Take-home messages II
기계학습과데이터는           에 관한 것
공간
7 / 125

-- PAGE 8 --

기계학습과 데이터
Take-home messages III
인공지능 = 의사결정 지원자
인공지능 ≠의사결정자
8 / 125

-- PAGE 9 --

기계학습과 데이터
퍼셉트론
Data
Learning from data
Perceptron
-1: Normal
+1: Cancer
Candidate
Selected candidate
: New patient
Perceptron
(Artificial neuron)
Multilayer perceptron
(Artificial neural network)
Deep neural network
child of
child of
9 / 125

-- PAGE 10 --

-1
-1
-1
-1
-1
-1
-1
-1
-1
-1
+1
+1
+1+1
+1
+1
+1
+1
+1
+1
-1
-1
-1
-1
-1
-1
-1
-1
-1
-1
+1
+1
+1+1
+1
+1
+1
+1
+1
+1
기계학습과 데이터
퍼셉트론
Training data
𝑥 
𝑦 
label
𝒅𝟏 
30
20
+1
𝒅𝟐 
10
5
-1
𝒅𝟑 
40
50
+1
𝒅𝟒 
35
15
+1
𝒅𝟓 
5
10
-1
… 
…
…
…
𝒅𝒏 
8
9
-1
-1
-1
-1
-1
-1
-1
-1
-1
-1
-1
+1
+1
+1+1
+1
+1
+1
+1
+1
+1
Non-linear classifier
space
Linear classifier
Floating in 
space
Learning
model
selection
Perceptron
10 / 125

-- PAGE 11 --

기계학습과 데이터
퍼셉트론
𝑦= 𝑎𝑥+ 𝑏
slope-intercept form
𝑏= −𝑎𝑥+ 𝑦
𝑏= −𝑎𝑥1 + 𝑥2
< 𝑥←𝑥1,𝑦←𝑥2 >
< 𝜔1 ←−𝑎, 𝜔2 ←+1 >
-1
-1
-1
-1
-1
-1
-1
-1
-1
-1
+1
+1
+1+1
+1
+1
+1
+1
+1
+1
𝑥
𝑥1
rename
𝑦
𝑥2
rename
𝑏= 𝜔1𝑥1 + 𝜔2𝑥2
standard form
11 / 125

-- PAGE 12 --

기계학습과 데이터
퍼셉트론
𝑦= 𝑎𝑥+ 𝑏
slope-intercept form
𝑏= −𝑎𝑥+ 𝑦
𝑏= −𝑎𝑥1 + 𝑥2
< 𝑥←𝑥1,𝑦←𝑥2 >
< 𝜔1 ←−𝑎, 𝜔2 ←+1 >
-1
-1
-1
-1
-1
-1
-1
-1
-1
-1
+1
+1
+1+1
+1
+1
+1
+1
+1
+1
𝑥
𝑥1
rename
𝑦
𝑥2
rename
𝑏= 𝜔1𝑥1 + 𝜔2𝑥2
standard form
If 𝜔1𝑥1 + 𝜔2𝑥2 < 𝑏,
it belongs to -1
If 𝜔1𝑥1 + 𝜔2𝑥2 > 𝑏,
it belongs to +1
Decision rule of perceptron
𝑏: threshold
12 / 125

-- PAGE 13 --

기계학습과 데이터
퍼셉트론
data
𝒙= (𝑥1, 𝑥2, … , 𝑥𝑚)
label: -1 or +1
𝜔1𝑥1 + 𝜔2𝑥2 + ⋯+ 𝜔𝑚𝑥𝑚
Perceptron
𝜔1𝑥1 +
𝜔2𝑥2 +
… +
𝜔𝑚𝑥𝑚 
< 𝑏
𝜔1𝑥1 +
𝜔2𝑥2 +
… +
𝜔𝑚𝑥𝑚 
> 𝑏
Decision
rule
𝒙belongs to -1
𝒙belongs to +1
෍
𝑖=1
𝑚
𝜔𝑖𝑥𝑖
෍
𝑖=1
𝑚
𝜔𝑖𝑥𝑖< 𝑏
෍
𝑖=1
𝑚
𝜔𝑖𝑥𝑖> 𝑏
𝒙belongs to -1
𝒙belongs to +1
13 / 125

-- PAGE 14 --

기계학습과 데이터
퍼셉트론
෍
𝑖=1
𝑚
𝜔𝑖𝑥𝑖< 𝑏
෍
𝑖=1
𝑚
𝜔𝑖𝑥𝑖> 𝑏
𝒙belongs to -1
𝒙belongs to +1
𝑠𝑖𝑔𝑛෍
𝑖=1
𝑚
(𝜔𝑖𝑥𝑖) −𝑏
𝒙belongs to -1
𝒙belongs to +1
𝒙belongs to -1
𝒙belongs to +1
negative
positive
𝑠𝑖𝑔𝑛෍
𝑖=1
𝑚
(𝜔𝑖𝑥𝑖) + 𝜔𝑚+1
negative
positive
𝒙belongs to -1
𝒙belongs to +1
𝑠𝑖𝑔𝑛෍
𝑖=1
𝑚+1
𝜔𝑖𝑥𝑖
negative
positive
< 𝜔𝑚+1 = −𝑏>
bias dimension
𝑥𝑚+1 = 1
14 / 125

-- PAGE 15 --

기계학습과 데이터
퍼셉트론
𝑥1 
𝑥2 
…
𝑥𝑚 
𝒅𝟏 
30
20
…
17
𝒅𝟐 
10
5
…
29
𝒅𝟑 
40
50
…
31
𝒅𝟒 
35
15
…
22
𝒅𝟓 
5
10
…
87
… 
…
…
…
…
𝒅𝒏 
8
9
…
14
𝑠𝑖𝑔𝑛෍
𝑖=1
𝑚
(𝜔𝑖𝑥𝑖) + 𝜔𝑚+1
𝜔1 
𝜔2 
…
𝜔𝑚 
× 
× 
…
× 
+ 𝜔𝑚+1
𝑥1 
𝑥2 
…
𝑥𝑚 
𝑥𝑚+1 
𝒅𝟏 
30
20
…
17
1
𝒅𝟐 
10
5
…
29
1
𝒅𝟑 
40
50
…
31
1
𝒅𝟒 
35
15
…
22
1
𝒅𝟓 
5
10
…
87
1
… 
…
…
…
…
…
𝒅𝒏 
8
9
…
14
1
𝑠𝑖𝑔𝑛෍
𝑖=1
𝑚+1
𝜔𝑖𝑥𝑖
𝜔1 
𝜔2 
…
𝜔𝑚 𝜔𝑚+1 
× 
× 
…
× 
×
bias
dimension
bias dimension
𝑥𝑚+1 = 1
𝑠𝑖𝑔𝑛𝝎∙𝒙
by def. of
dot product
15 / 125

-- PAGE 16 --

기계학습과 데이터
퍼셉트론
• Vector 𝒗= (5, 12)
•
It has its dimension, direction & length (magnitude)
𝒗= (5, 12)
direction
features
label
𝑥1 
𝑥2 
…
𝑥𝑚 
𝑦 
𝒅𝟏 
30
20
…
17
+1
𝒅𝟐 
10
5
…
29
-1
𝒅𝟑 
40
50
…
31
+1
𝒅𝟒 
35
15
…
22
+1
𝒅𝟓 
5
10
…
87
-1
… 
…
…
…
…
…
𝒅𝒏 
8
9
…
14
-1
𝑥
𝑥1
rename
𝑦
𝑥2
rename
feature vector
label
𝒙𝒊 
𝑦𝑖 
𝒙𝟏 
(30, 20, …, 17)
+1
𝒙𝟐 
(10, 5, …, 29)
-1
𝒙𝟑 
(40, 50, …, 31)
+1
𝒙𝟒 
(35, 15, …, 22)
+1
𝒙𝟓 
(5, 10, …, 87)
-1
…
…
…
𝒙𝒏 
(8, 9, …, 14)
-1
dimension: 2
16 / 125

-- PAGE 17 --

기계학습과 데이터
퍼셉트론
• Operations for two given vectors 𝒗= (5, 12) and 𝒖= (3, 4)
•
Addition      : 𝒗+ 𝒖= 5 + 3, 12 + 4 = (8, 16)
•
Subtraction   : 𝒗−𝒖= 5 −3, 12 −4 = (2, 8)
•
Multiplication: 𝒗∙𝒖= 5 × 3 + 12 × 4 = 63
•
Dot product (Inner product)  
𝑠𝑖𝑔𝑛෍
𝑖=1
𝑚+1
𝜔𝑖𝑥𝑖
𝑠𝑖𝑔𝑛𝝎∙𝒙
by def. of
dot product
17 / 125

-- PAGE 18 --

기계학습과 데이터
퍼셉트론
• Operations for two given vectors 𝒗= (5, 12) and 𝒖= (3, 4)
•
Addition      : 𝒗+ 𝒖= 5 + 3, 12 + 4 = (8, 16)
•
Subtraction   : 𝒗−𝒖= 5 −3, 12 −4 = (2, 8)
•
Multiplication: 𝒗∙𝒖= 5 × 3 + 12 × 4 = 63
•
Dot product (Inner product)
𝒗= (5, 12)
𝑥1
𝑥2
𝒖= (3, 4)
𝑥1
𝑥2
𝑥1
𝑥2
addition
subtraction
𝒗+ 𝒖= (𝟖, 𝟏𝟔)
𝒗= (5, 12)
𝒖= (3, 4)
𝒗= (5, 12)
𝒖= (3, 4)
𝒗−𝒖= (𝟐, 𝟖)
18 / 125

-- PAGE 19 --

기계학습과 데이터
퍼셉트론
• Operations for two given vectors 𝒗= (5, 12) and 𝒖= (3, 4)
•
Addition      : 𝒗+ 𝒖= 5 + 3, 12 + 4 = (8, 16)
•
Subtraction   : 𝒗−𝒖= 5 −3, 12 −4 = (2, 8)
•
Multiplication: 𝒗∙𝒖= 5 × 3 + 12 × 4 = 63
•
Dot product (Inner product)  
𝒗= (5, 12)
𝑥1
𝑥2
𝒖= (3, 4)
𝑥1
𝑥2
𝑥1
𝑥2
addition
subtraction
𝒗+ 𝒖= (𝟖, 𝟏𝟔)
𝒗= (5, 12)
𝒖= (3, 4)
𝒗= (5, 12)
𝒖= (3, 4)
𝒗−𝒖= (𝟐, 𝟖)
19 / 125

-- PAGE 20 --

기계학습과 데이터
퍼셉트론
• Operations for two given vectors 𝒗= (5, 12) and 𝒖= (3, 4)
•
Addition      : 𝒗+ 𝒖= 5 + 3, 12 + 4 = (8, 16)
•
Subtraction   : 𝒗−𝒖= 5 −3, 12 −4 = (2, 8)
•
Multiplication: 𝒗∙𝒖= 5 × 3 + 12 × 4 = 63
•
Dot product (Inner product): 𝒗∙𝒖= |𝒗| × |𝒖| × cos 𝜃
why not |𝒗| × |𝒖|
𝑥1
𝑥2
𝒗
𝒖
20 / 125

-- PAGE 21 --

기계학습과 데이터
퍼셉트론
• Operations for two given vectors 𝒗= (5, 12) and 𝒖= (3, 4)
•
Addition      : 𝒗+ 𝒖= 5 + 3, 12 + 4 = (8, 16)
•
Subtraction   : 𝒗−𝒖= 5 −3, 12 −4 = (2, 8)
•
Multiplication: 𝒗∙𝒖= 5 × 3 + 12 × 4 = 63
•
Dot product (Inner product): 𝒗∙𝒖= |𝒗| × |𝒖| × cos 𝜃
Multiplication of real numbers
0
3
5
-3
3 × 5 =
15
−3 × 5 = −15 
∵real numbers share their direction
𝑥1
𝑥2
𝒗
𝒖
21 / 125

-- PAGE 22 --

기계학습과 데이터
퍼셉트론
• Operations for two given vectors 𝒗= (5, 12) and 𝒖= (3, 4)
•
Addition      : 𝒗+ 𝒖= 5 + 3, 12 + 4 = (8, 16)
•
Subtraction   : 𝒗−𝒖= 5 −3, 12 −4 = (2, 8)
•
Multiplication: 𝒗∙𝒖= 5 × 3 + 12 × 4 = 63
•
Dot product (Inner product): 𝒗∙𝒖= |𝒗| × |𝒖| × cos 𝜃
Do |𝒗| × |𝒖| share their direction?
Nope
How much different?
𝜃
Steps we should follow
1. Set the direction of 𝒗& 𝒖to be the same.
2. Multiply them in the same way as ℝ.
𝑥1
𝑥2
𝒗
𝒖
𝜃
22 / 125

-- PAGE 23 --

기계학습과 데이터
퍼셉트론
• Operations for two given vectors 𝒗= (5, 12) and 𝒖= (3, 4)
•
Addition      : 𝒗+ 𝒖= 5 + 3, 12 + 4 = (8, 16)
•
Subtraction   : 𝒗−𝒖= 5 −3, 12 −4 = (2, 8)
•
Multiplication: 𝒗∙𝒖= 5 × 3 + 12 × 4 = 63
•
Dot product (Inner product): 𝒗∙𝒖= |𝒗| × |𝒖| × cos 𝜃
𝑥1
𝑥2
𝒗
𝒖
𝜃
Steps we should follow
1. Set the direction of 𝒗& 𝒖to be the same.
2. Multiply them in the same way as ℝ.
cos 𝜃= 𝑏
ℎ≡𝑏= ℎ× cos 𝜃
∙ Length of      : |𝒗| × cos 𝜃
∴𝒗∙𝒖= |𝒗| × |𝒖| × cos 𝜃
23 / 125

-- PAGE 24 --

기계학습과 데이터
퍼셉트론
• Operations for two given vectors 𝒗= (5, 12) and 𝒖= (3, 4)
•
Addition      : 𝒗+ 𝒖= 5 + 3, 12 + 4 = (8, 16)
•
Subtraction   : 𝒗−𝒖= 5 −3, 12 −4 = (2, 8)
•
Multiplication: 𝒗∙𝒖= 5 × 3 + 12 × 4 = 63
•
Dot product (Inner product): 𝒗∙𝒖= |𝒗| × |𝒖| × cos 𝜃
𝑥1
𝑥2
𝒗
𝒖
𝜃
Steps we should follow
1. Set the direction of 𝒗& 𝒖to be the same.
2. Multiply them in the same way as ℝ.
∴𝒗∙𝒖= |𝒗| × |𝒖| × cos 𝜃
24 / 125

-- PAGE 25 --

기계학습과 데이터
퍼셉트론
𝑠𝑖𝑔𝑛𝝎∙𝒙
𝒙belongs to -1
𝒙belongs to +1
𝜔1𝑥1 + 𝜔2𝑥2 + ⋯+ 𝜔𝑚𝑥𝑚
𝜔1𝑥1 +
𝜔2𝑥2 +
… +
𝜔𝑚𝑥𝑚 
< 𝑏
𝜔1𝑥1 +
𝜔2𝑥2 +
… +
𝜔𝑚𝑥𝑚 
> 𝑏
𝒙belongs to -1
𝒙belongs to +1
negative
positive
…
Time to train (fit) 
𝝎 based on training data 𝐷𝑡𝑟𝑎𝑖𝑛
25 / 125

-- PAGE 26 --

기계학습과 데이터
퍼셉트론
• Perceptron: 𝑠𝑖𝑔𝑛(𝝎∙𝒙)
• Training data: 𝐷𝑡𝑟𝑎𝑖𝑛= { 𝒙𝟏, 𝑦1 , 𝒙𝟐, 𝑦2 , … , (𝒙𝒏, 𝑦𝑛)}
•
𝑦𝑖∈{+1, −1}
feature vector
label
𝒙𝒊 
𝑦𝑖 
𝒙𝟏=(30, 20, …, 17)
𝑦1 = +1
𝒙𝟐=(10, 5, …, 29)
𝑦2 =-1
𝒙𝟑=(40, 50, …, 31)
𝑦3 =+1
𝒙𝟒=(35, 15, …, 22)
𝑦4 =+1
𝒙𝟓=(5, 10, …, 87)
𝑦5 =-1
…
… 
𝒙𝒏=(8, 9, …, 14)
𝑦𝑛=-1
Training data 𝐷𝑡𝑟𝑎𝑖𝑛
Learning algorithm
Step 1: Initialize 𝝎randomly.
Step 2: Pick a misclassified point 𝒙𝒊s.t. 𝑠𝑖𝑔𝑛(𝝎∙𝒙𝒊) ≠𝑠𝑖𝑔𝑛(𝑦𝑖)
Step 3: Update 𝝎: 𝝎𝒏𝒆𝒘←𝝎+ 𝑦𝑖× 𝒙𝒊
Step 4: Repeat step 2 & 3 until there is no misclassified point.
26 / 125

-- PAGE 27 --

• Perceptron: 𝑠𝑖𝑔𝑛(𝝎∙𝒙)
• Training data: 𝐷𝑡𝑟𝑎𝑖𝑛= { 𝒙𝟏, 𝑦1 , 𝒙𝟐, 𝑦2 , … , (𝒙𝒏, 𝑦𝑛)}
•
𝑦𝑖∈{+1, −1}
• Learning algorithm
1. Initialize 𝝎randomly.
2. Pick a misclassified point 𝒙𝒊s.t. 𝑠𝑖𝑔𝑛(𝝎∙𝒙𝒊) ≠𝑠𝑖𝑔𝑛(𝑦𝑖)
3. Update 𝝎: 𝝎𝒏𝒆𝒘←𝝎+ 𝑦𝑖× 𝒙𝒊
4. Repeat step 2 & 3 until there is no misclassified point.
기계학습과 데이터
퍼셉트론
(𝒙𝒊, 𝑦𝑖)
∙ 𝑦𝑖
= +1
∙ 𝑠𝑖𝑔𝑛(𝝎∙𝒙𝒊) = negative
∙ 𝑦𝑖
= -1
∙ 𝑠𝑖𝑔𝑛(𝝎∙𝒙𝒊) = positive
27 / 125

-- PAGE 28 --

• Perceptron: 𝑠𝑖𝑔𝑛(𝝎∙𝒙)
• Training data: 𝐷𝑡𝑟𝑎𝑖𝑛= { 𝒙𝟏, 𝑦1 , 𝒙𝟐, 𝑦2 , … , (𝒙𝒏, 𝑦𝑛)}
•
𝑦𝑖∈{+1, −1}
• Learning algorithm
1. Initialize 𝝎randomly.
2. Pick a misclassified point 𝒙𝒊s.t. 𝑠𝑖𝑔𝑛(𝝎∙𝒙𝒊) ≠𝑠𝑖𝑔𝑛(𝑦𝑖)
3. Update 𝝎: 𝝎𝒏𝒆𝒘←𝝎+ 𝑦𝑖× 𝒙𝒊
4. Repeat step 2 & 3 until there is no misclassified point.
기계학습과 데이터
퍼셉트론
(𝒙𝒊, 𝑦𝑖)
∙ 𝑦𝑖
= +1
∙ 𝑠𝑖𝑔𝑛(𝝎∙𝒙𝒊) = negative
∙ 𝑦𝑖
= -1
∙ 𝑠𝑖𝑔𝑛(𝝎∙𝒙𝒊) = positive
𝝎
𝒙𝒊
𝝎𝒏𝒆𝒘
28 / 125

-- PAGE 29 --

• Perceptron: 𝑠𝑖𝑔𝑛(𝝎∙𝒙)
• Training data: 𝐷𝑡𝑟𝑎𝑖𝑛= { 𝒙𝟏, 𝑦1 , 𝒙𝟐, 𝑦2 , … , (𝒙𝒏, 𝑦𝑛)}
•
𝑦𝑖∈{+1, −1}
• Learning algorithm
1. Initialize 𝝎randomly.
2. Pick a misclassified point 𝒙𝒊s.t. 𝑠𝑖𝑔𝑛(𝝎∙𝒙𝒊) ≠𝑠𝑖𝑔𝑛(𝑦𝑖)
3. Update 𝝎: 𝝎𝒏𝒆𝒘←𝝎+ 𝑦𝑖× 𝒙𝒊
4. Repeat step 2 & 3 until there is no misclassified point.
기계학습과 데이터
퍼셉트론
(𝒙𝒊, 𝑦𝑖)
∙ 𝑦𝑖
= +1
∙ 𝑠𝑖𝑔𝑛(𝝎∙𝒙𝒊) = negative
∙ 𝑦𝑖
= -1
∙ 𝑠𝑖𝑔𝑛(𝝎∙𝒙𝒊) = positive
𝝎
𝒙𝒊
𝝎𝒏𝒆𝒘
29 / 125

-- PAGE 30 --

기계학습과 데이터
퍼셉트론
30 / 125

-- PAGE 31 --

기계학습과 데이터
퍼셉트론
• Representative image of deep learning
31 / 125

-- PAGE 32 --

기계학습과 데이터
퍼셉트론
• Representative image of deep learning
32 / 125

-- PAGE 33 --

기계학습과 데이터
퍼셉트론
이미지 출처: http://www.asimovinstitute.org/neural-network-zoo/?fbclid=IwAR3mfuYMai9snzyOMEd-Yzsf8xEoFK4cYbp7bS0D9PO-usV282xrF50gXoI
33 / 125

-- PAGE 34 --

기계학습과 데이터
퍼셉트론
• Real world problem
-1
-1
-1
-1
-1
-1
-1
-1
-1
-1
+1
+1
+1 +1
+1
+1
+1
+1
+1
+1
-1
-1
-1
-1
-1
-1
-1
-1
-1
-1
+1
+1
+1 +1
+1
+1
+1
+1
+1
+1
w/ linear classifier
w/ non-linear classifier
34 / 125

-- PAGE 35 --

기계학습과 데이터
퍼셉트론
• Simple example of non-linearly separable problem
•
1-dimensional space
•
4 training samples
𝑥1
∑
1
𝜔1
𝜔2
0
+1
-1
: -1
: +1
2
3
4
5
6
7
8
𝑥1
35 / 125

-- PAGE 36 --

기계학습과 데이터
퍼셉트론
• Simple example of non-linearly separable problem
𝑥1
∑
1
1
−3
0
+1
-1
𝑥1 −3
3
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 3
+1, 𝑖𝑓𝑥1 > 3
Perceptron 𝑃𝑎
2
3
4
5
6
7
8
𝑥1
: -1
: +1
wrong
correct
correct
correct
36 / 125

-- PAGE 37 --

기계학습과 데이터
퍼셉트론
• Simple example of non-linearly separable problem
2
3
4
5
6
7
8
𝑥1
: -1
: +1
wrong
wrong
correct
correct
𝑥1
∑
1
1
−5
0
+1
-1
𝑥1 −5
5
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 5
+1, 𝑖𝑓𝑥1 > 5
Perceptron 𝑃𝑏
37 / 125

-- PAGE 38 --

기계학습과 데이터
퍼셉트론
• Simple example of non-linearly separable problem
2
3
4
5
6
7
8
𝑥1
: -1
: +1
correct
wrong
correct
correct
𝑥1
∑
1
1
−7
0
+1
-1
𝑥1 −7
7
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 7
+1, 𝑖𝑓𝑥1 > 7
Perceptron 𝑃𝑐
38 / 125

-- PAGE 39 --

기계학습과 데이터
퍼셉트론
• What we need
2
3
4
5
6
7
8
𝑥1
: -1
: +1
3
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 3
+1, 𝑖𝑓𝑥1 > 3
𝑷𝒂
5
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 5
+1, 𝑖𝑓𝑥1 > 5
𝑷𝒃
7
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 7
+1, 𝑖𝑓𝑥1 > 7
𝑷𝒄
39 / 125

-- PAGE 40 --

기계학습과 데이터
인공신경망
• What we need
2
3
4
5
6
7
8
𝑥1
: -1
: +1
3
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 3
+1, 𝑖𝑓𝑥1 > 3
𝑷𝒂
5
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 5
+1, 𝑖𝑓𝑥1 > 5
𝑷𝒃
7
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 7
+1, 𝑖𝑓𝑥1 > 7
𝑷𝒄
they collaborate wisely?
40 / 125

-- PAGE 41 --

기계학습과 데이터
인공신경망
• What we need
2
3
4
5
6
7
8
𝑥1
: -1
: +1
they collaborate wisely?
3
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 3
+1, 𝑖𝑓𝑥1 > 3
𝑷𝒂
5
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 5
+1, 𝑖𝑓𝑥1 > 5
𝑷𝒃
7
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 7
+1, 𝑖𝑓𝑥1 > 7
𝑷𝒄
𝑷𝒂−𝑷𝒃+ 𝑷𝒄
41 / 125

-- PAGE 42 --

기계학습과 데이터
인공신경망
• What we need
2
3
4
5
6
7
8
𝑥1
: -1
: +1
3
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 3
+1, 𝑖𝑓𝑥1 > 3
𝑷𝒂
5
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 5
+1, 𝑖𝑓𝑥1 > 5
𝑷𝒃
7
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 7
+1, 𝑖𝑓𝑥1 > 7
𝑷𝒄
they collaborate wisely?
𝑷𝒂−𝑷𝒃+ 𝑷𝒄
𝑥1 = 2 
(−1) −−1 + −1 = −𝟏
correct
42 / 125

-- PAGE 43 --

기계학습과 데이터
인공신경망
• What we need
2
3
4
5
6
7
8
𝑥1
: -1
: +1
they collaborate wisely?
3
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 3
+1, 𝑖𝑓𝑥1 > 3
𝑷𝒂
5
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 5
+1, 𝑖𝑓𝑥1 > 5
𝑷𝒃
7
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 7
+1, 𝑖𝑓𝑥1 > 7
𝑷𝒄
𝑷𝒂−𝑷𝒃+ 𝑷𝒄
𝑥1 = 4 
+1 −−1 + −1 = +𝟏
correct
43 / 125

-- PAGE 44 --

기계학습과 데이터
인공신경망
• What we need
2
3
4
5
6
7
8
𝑥1
: -1
: +1
they collaborate wisely?
3
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 3
+1, 𝑖𝑓𝑥1 > 3
𝑷𝒂
5
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 5
+1, 𝑖𝑓𝑥1 > 5
𝑷𝒃
7
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 7
+1, 𝑖𝑓𝑥1 > 7
𝑷𝒄
𝑷𝒂−𝑷𝒃+ 𝑷𝒄
𝑥1 = 6 
+1 −+1 + −1 = −𝟏
correct
44 / 125

-- PAGE 45 --

기계학습과 데이터
인공신경망
• What we need
2
3
4
5
6
7
8
𝑥1
: -1
: +1
they collaborate wisely?
3
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 3
+1, 𝑖𝑓𝑥1 > 3
𝑷𝒂
5
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 5
+1, 𝑖𝑓𝑥1 > 5
𝑷𝒃
7
−1
+1
ቊ−1, 𝑖𝑓𝑥1 < 7
+1, 𝑖𝑓𝑥1 > 7
𝑷𝒄
𝑷𝒂−𝑷𝒃+ 𝑷𝒄
𝑥1 = 8 
+1 −+1 + +1 = +𝟏
correct
45 / 125

-- PAGE 46 --

기계학습과 데이터
인공신경망
• The process so far in one picture
: -1
: +1
2
3
4
5
6
7
8
𝑥1
𝑥1
1
∑
+1
-3
46 / 125

-- PAGE 47 --

기계학습과 데이터
인공신경망
• The process so far in one picture
: -1
: +1
2
3
4
5
6
7
8
𝑥1
𝑥1
1
∑
∑
+1
+1
-3
-5
47 / 125

-- PAGE 48 --

기계학습과 데이터
인공신경망
• The process so far in one picture
: -1
: +1
2
3
4
5
6
7
8
𝑥1
𝑥1
1
∑
∑
∑
+1
+1
+1
-3
-5
-7
48 / 125

-- PAGE 49 --

기계학습과 데이터
인공신경망
• The process so far in one picture
: -1
: +1
2
3
4
5
6
7
8
𝑥1
𝑥1
1
∑
∑
∑
∑
+1
+1
+1
-3
-5
-7
+1
-1
+1
1
0
49 / 125

-- PAGE 50 --

기계학습과 데이터
인공신경망
• Terminology
𝑥1
1
∑
∑
∑
∑
1
+1
+1
+1
-3
-5
-7
+1
-1
+1
0
Input
layer
Hidden
layer
Output
layer
bias
activation
function
weight
50 / 125

-- PAGE 51 --

기계학습과 데이터
인공신경망
• Activation functions
이미지출처: https://sefiks.com/2020/02/02/dance-moves-of-deep-learning-activation-functions/
51 / 125

-- PAGE 52 --

기계학습과 데이터
인공신경망
• XOR problem
Operand
Logical operator
𝑥1 
𝑥2 
AND
OR
NAND
XOR
1
1
1
1
0
0
1
0
0
1
1
1
0
1
0
1
1
1
0
0
0
0
1
0
52 / 125

-- PAGE 53 --

기계학습과 데이터
인공신경망
• XOR problem
: 0 (false)
: 1 (true)
AND problem
OR problem
XOR problem
Operand
Logical operator
𝑥1 
𝑥2 
AND
OR
NAND
XOR
1
1
1
1
0
0
1
0
0
1
1
1
0
1
0
1
1
1
0
0
0
0
1
0
(0, 1)
(0, 0)
(1, 1)
(1, 0)
(0, 1)
(0, 0)
(1, 1)
(1, 0)
(0, 1)
(0, 0)
(1, 1)
(1, 0)
𝑥1
𝑥2
𝑥1
𝑥2
𝑥1
𝑥2
53 / 125

-- PAGE 54 --

𝑜
ℎ2
• XOR problem
ℎ1
기계학습과 데이터
인공신경망
(0, 1)
(0, 0)
(1, 1)
(1, 0)
𝑥1
𝑥2
∑
∑
𝜙
𝜙
∑
𝜙
1
1
𝑥1
𝑥2
Activation function 𝜙
Neural network
Problem
20
-20
20
-20-10
30
20
20
-30
Logistic curve 𝜎
𝜎(20𝑥1 + 20𝑥2 −10)
𝜎(−20𝑥1 −20𝑥2 + 30)
𝜎(20ℎ1 + 20ℎ2 −30)
Input node
Hidden node
Output node
𝑥1
𝑥2
ℎ1
ℎ2
𝑜
1
1
σ(20·1 + 20·1 - 10) ≈ 1
σ(-20·1 - 20·1 + 30) ≈ 0
σ(20·1 + 20·0 - 30) ≈ 0
1
0
σ(20·1 + 20·0 - 10) ≈ 1
σ(-20·1 - 20·0 + 30) ≈ 1
σ(20·1 + 20·1 - 30) ≈ 1
0
1
σ(20·0 + 20·1 - 10) ≈ 1
σ(-20·0 - 20·1 + 30) ≈ 1
σ(20·1 + 20·1 - 30) ≈ 1
0
0
σ(20·0 + 20·0 - 10) ≈ 0
σ(-20·0 - 20·0 + 30) ≈ 1
σ(20·0 + 20·1 - 30) ≈ 0
: 0 (false)
: 1 (true)
54 / 125

-- PAGE 55 --

𝑜
ℎ2
• XOR problem
ℎ1
기계학습과 데이터
인공신경망
𝑥1
𝑥2
∑
∑
𝜙
𝜙
∑
𝜙
1
1
20
-20
20
-20-10
30
20
20
-30
𝜎(20𝑥1 + 20𝑥2 −10)
𝜎(−20𝑥1 −20𝑥2 + 30)
𝜎(20ℎ1 + 20ℎ2 −30)
Input node
Hidden node
𝑥1
𝑥2
ℎ1
1
1
σ(20·1 + 20·1 - 10) ≈ 1
1
0
σ(20·1 + 20·0 - 10) ≈ 1
0
1
σ(20·0 + 20·1 - 10) ≈ 1
0
0
σ(20·0 + 20·0 - 10) ≈ 0
(0, 1)
(0, 0)
(1, 1)
(1, 0)
𝑥1
𝑥2
OR
Interpretation of hidden node ℎ1
55 / 125

-- PAGE 56 --

𝑜
ℎ2
• XOR problem
ℎ1
기계학습과 데이터
인공신경망
𝑥1
𝑥2
∑
∑
𝜙
𝜙
∑
𝜙
1
1
20
-20
20
-20-10
30
20
20
-30
𝜎(20𝑥1 + 20𝑥2 −10)
𝜎(−20𝑥1 −20𝑥2 + 30)
𝜎(20ℎ1 + 20ℎ2 −30)
Input node
Hidden node
𝑥1
𝑥2
ℎ2
1
1
σ(-20·1 - 20·1 + 30) ≈ 0
1
0
σ(-20·1 - 20·0 + 30) ≈ 1
0
1
σ(-20·0 - 20·1 + 30) ≈ 1
0
0
σ(-20·0 - 20·0 + 30) ≈ 1
(0, 1)
(0, 0)
(1, 1)
(1, 0)
𝑥1
𝑥2
NAND
Interpretation of hidden node ℎ1
56 / 125

-- PAGE 57 --

𝑜
ℎ2
• XOR problem
ℎ1
기계학습과 데이터
인공신경망
𝑥1
𝑥2
∑
∑
𝜙
𝜙
∑
𝜙
1
1
20
-20
20
-20-10
30
20
20
-30
𝜎(20𝑥1 + 20𝑥2 −10)
𝜎(−20𝑥1 −20𝑥2 + 30)
𝜎(20ℎ1 + 20ℎ2 −30)
Input node
Output node
ℎ1
ℎ2
𝑜
1
0
σ(20·1 + 20·0 - 30) ≈ 0
1
1
σ(20·1 + 20·1 - 30) ≈ 1
1
1
σ(20·1 + 20·1 - 30) ≈ 1
0
1
σ(20·0 + 20·1 - 30) ≈ 0
(0, 1)
(0, 0)
(1, 1)
(1, 0)
𝑥1
𝑥2
AND
Interpretation of output node 𝑜
OR
NAND
57 / 125

-- PAGE 58 --

𝑜
ℎ2
• XOR problem
ℎ1
기계학습과 데이터
인공신경망
𝑥1
𝑥2
∑
∑
𝜙
𝜙
∑
𝜙
1
1
20
-20
20
-20-10
30
20
20
-30
OR gate
NAND gate
AND gate
Operand
𝑥1 
𝑥2 
1
1
1
0
0
1
0
0
Operator
OR
1
1
1
0
Operator
NAND
0
1
1
1
Operator
XOR
0
1
1
0
AND
=
58 / 125

-- PAGE 59 --

• Perceptron vs. Artificial neural network (Multilayer perceptron)
기계학습과 데이터
인공신경망
Perceptron
ANN
59 / 125

-- PAGE 60 --

𝑜
ℎ2
ℎ1
기계학습과 데이터
인공신경망
𝑥1
𝑥2
∑
∑
𝜙
𝜙
∑
𝜙
1
1
20
-20
20
-20-10
30
20
20
-30
OR gate
NAND gate
AND gate
60 / 125

-- PAGE 61 --

기계학습과 데이터
인공신경망
• In theory, ANN (Artificial Neural Network) can appropriately separate any given space, and we can identify 
the role of each node and/or layer.
• Nevertheless, people say that ANN is a black box.
• This is because of the                 .
61 / 125

-- PAGE 62 --

기계학습과 데이터
인공신경망
• In theory, ANN (Artificial Neural Network) can appropriately separate any given space, and we can identify 
the role of each node and/or layer.
• Nevertheless, people say that ANN is a black box.
• This is because of the                 .
Unit
62 / 125

-- PAGE 63 --

𝑜
ℎ2
ℎ1
기계학습과 데이터
인공신경망
𝑥1
𝑥2
∑
∑
𝜙
𝜙
∑
𝜙
1
1
20
-20
20
-20-10
30
20
20
-30
OR gate
NAND gate
AND gate
Unit
Boolean
(True/False)
Unit
Boolean
(True/False)
Unit
Boolean
(True/False)
Unit
Pixel
Unit
Pixel
Unit
Pixel
Unit
Pixel
이미지 출처: http://www.amax.com/blog/?p=804
63 / 125

-- PAGE 64 --

기계학습과 데이터
인공신경망
height
weight
blood pressure
lab. test result
smoking habit
…
Unit
64 / 125

-- PAGE 65 --

기계학습과 데이터
인공신경망
height
weight
blood pressure
lab. test result
smoking habit
…
Performance
vs.
Explanatory power
뛰어난 역량, 그러나 도통 속을 알 수 없는 동료,
신뢰할 수 있나요?
Introduction to Deep Learning
김응희
2019.03.14.
Unit
65 / 125

-- PAGE 66 --

기계학습과 데이터
인공신경망
• Oriental medicine vs. Western medicine
이미지 출처: https://www.drwen-acupuncture.co.uk/acupuncture
: https://news.liverpool.ac.uk/2016/11/23/successful-clinical-pharmacology-training-scheme-renewed/
66 / 125

-- PAGE 67 --

기계학습과 데이터
데이터–공간–인공지능
f-6
f-5
f-4
f-3
f-2
f-1
…
…
실제 세계
67 / 125

-- PAGE 68 --

기계학습과 데이터
데이터–공간–인공지능
f-6
f-5
f-4
f-3
f-2
f-1
…
…
1D space
f-01
실제 세계
68 / 125

-- PAGE 69 --

기계학습과 데이터
데이터–공간–인공지능
f-6
f-5
f-4
f-3
f-2
f-1
…
…
f-01
1D space
f-01
2D space
2D space
→
f-02
f-03
f-04
실제 세계
69 / 125

-- PAGE 70 --

기계학습과 데이터
데이터–공간–인공지능
f-6
f-5
f-4
f-3
f-2
f-1
…
…
f-01
1D space
f-01
2D space
2D space
3D space
→
→
f-02
f-03
f-04
f-04
f-06
실제 세계
70 / 125

-- PAGE 71 --

기계학습과 데이터
데이터–공간–인공지능
f-6
f-5
f-4
f-3
f-2
f-1
…
…
f-01
1D space
f-01
초차원 공간
Hyper dimensional space
2D space
2D space
3D space
→
→
→4D → 5D → … → 𝑛D
f-02
f-03
f-04
f-04
f-06
실제 세계
71 / 125

-- PAGE 72 --

기계학습과 데이터
데이터–공간–인공지능
f-6
f-5
f-4
f-3
f-2
f-1
…
…
f-01
1D space
f-01
2D space
2D space
3D space
→
→
→4D → 5D → … → 𝑛D
f-02
f-03
f-04
f-04
f-06
초차원 공간
Hyper dimensional space
실제 세계
∙특질(Feature)
- 공간을 정의하는 요소
∙데이터(Data)
- 공간에 살고있는 거주자
72 / 125

-- PAGE 73 --

기계학습과 데이터
데이터–공간–인공지능
f-6
f-5
f-4
f-3
f-2
f-1
…
…
f-01
1D space
f-01
2D space
2D space
→
→
→4D → 5D → … → 𝑛D
f-02
f-03
f-04
f-04
f-06
∙특질(Feature)
- 공간을 정의하는 요소
∙데이터(Data)
- 공간에 살고있는 거주자
∙인공지능(AI)
- 공간을 분할하는 방법
점
초평면
선
면
3D space
초차원 공간
Hyper dimensional space
실제 세계
73 / 125

-- PAGE 74 --

기계학습과 데이터
데이터–공간–인공지능
𝑥1
𝑥2
𝑥1
𝑥2
𝑥1
𝑥2
𝒙𝟑
유의미한 발견
74 / 125

-- PAGE 75 --

공간을 다룬 사례 I
피아 무기 구분의 공간
• 1956년: 인공지능 연구 시작
B-17
폭격기
75 / 125

-- PAGE 76 --

공간을 다룬 사례 II
치아교정 공간
• 보철 vs. 수술
•
Kim, Bo-Mi, Bo-Yeong Kang, Hong-Gee Kim, and Seung-Hak Baek. 2009. “Prognosis Prediction for Class III 
Malocclusion Treatment by Feature Wrapping Method.” The Angle Orthodontist 79(4):683–91.
76 / 125

-- PAGE 77 --

공간을 다룬 사례 III
피부종양 공간
• AI정밀의료솔루션(닥터앤서 2.0) 개발
•
12개 질환 진단보조 AI의료 SW 24개 개발 및 임상검증
양성종양
기저세포암
편평세포암
악성흑색종
국내 피부암(악성흑생종) 발생률, 10년 사이 2배 이상 증가
건강보험심사평가원, 2021
피부과 표방의원 3만, 피부과전문의 진료 병원 2천 불과
헬스경향, 2022
기저세포암(30~40%), 편평세포암(20~30%), 악성흑색종(10~20%)
보건복지부 중앙암등록본부, 2021
77 / 125

-- PAGE 78 --

공간을 다룬 사례 IV
가정혈압 공간
• AI정밀의료솔루션(닥터앤서 2.0) 개발
•
12개 질환 진단보조 AI의료 SW 24개 개발 및 임상검증
고혈압: 추적관리가 필요한 대표 질환
Lab. test
Questionnaire
History of
blood pressure
Prescription/
Treatment plan
clinical evidences
과거 8주간의
혈압 수치
향후 4주간의
혈압 수치
input
output
additional clinical evidence
lifelog data
78 / 125

-- PAGE 79 --

공간을 다룬 사례 V
따스함을 전달하는 공간
• OO대학교 AI소프트웨어학과 17학번& 18학번
간호학과
AI
소프트웨어학과
타인을 돕는 행위
행복 & 만족
고교 정보 시간
프로그래밍 흥미
"따뜻한" 소프트웨어
서울대학교 어린이병원
중환자실
보호자
웃는 얼굴
인지 모델
사진 캡쳐
보호자
SNS 전송
Bright moment
우수연제논문상
신생아 집중치료실의 딥러닝 기반
부분적 얼굴에 대한 표정인식(2022)
지도학생
79 / 125

-- PAGE 80 --

기계학습과 데이터
기계학습 구성요소
미지의 목적함수
𝑓: 𝒳→𝒴
학습 데이터
𝒙𝟏, 𝑦1 , 𝒙𝟐, 𝑦2 , … , (𝒙𝒏, 𝑦𝑛)
가설집합
ℋ
최종 가설
𝑔≈𝑓
출처: Abu-Mostafa, Y. S.; Magdon-Ismail, M. & Lin, H.-T. (2012), Learning From Data, AMLBook.
학습 알고리즘
𝒜
80 / 125

-- PAGE 81 --

기계학습과 데이터
기계학습 구성요소
미지의 목적함수
𝑓: 𝒳→𝒴
학습 데이터
𝒙𝟏, 𝑦1 , 𝒙𝟐, 𝑦2 , … , (𝒙𝒏, 𝑦𝑛)
가설 집합
ℋ
최종 가설
𝑔≈𝑓
Learning
algorithm
𝒜
특질 데이터
𝒙𝒊
부류
𝑦𝑖
0
250
…
+1
10
150
…
-1
2
90
…
+1
…
…
…
…
출처: Abu-Mostafa, Y. S.; Magdon-Ismail, M. & Lin, H.-T. (2012), Learning From Data, AMLBook.
81 / 125

-- PAGE 82 --

기계학습과 데이터
기계학습 구성요소
미지의 목적함수
𝑓: 𝒳→𝒴
학습 데이터
𝒙𝟏, 𝑦1 , 𝒙𝟐, 𝑦2 , … , (𝒙𝒏, 𝑦𝑛)
가설 집합
ℋ
최종 가설
𝑔≈𝑓
학습 알고리즘
𝒜
∀
입력
데이터
정답
목적
함수
𝑓
입력 공간
𝒳
출력공간
𝒴
출처: Abu-Mostafa, Y. S.; Magdon-Ismail, M. & Lin, H.-T. (2012), Learning From Data, AMLBook.
82 / 125

-- PAGE 83 --

기계학습과 데이터
기계학습 구성요소
미지의 목적함수
𝑓: 𝒳→𝒴
학습 데이터
𝒙𝟏, 𝑦1 , 𝒙𝟐, 𝑦2 , … , (𝒙𝒏, 𝑦𝑛)
가설 집합
ℋ
최종 가설
𝑔≈𝑓
학습 알고리즘
𝒜
∀
입력
데이터
정답
목적
함수
𝑓
입력 공간
𝒳
출력공간
𝒴
출처: Abu-Mostafa, Y. S.; Magdon-Ismail, M. & Lin, H.-T. (2012), Learning From Data, AMLBook.
∙ 오직 신(God)만이…
∙ 끝없는 기계학습 후에도 여전히 ‘unknown’…
∙ FAANG & 네라카쿠배 협력해도…
83 / 125

-- PAGE 84 --

기계학습과 데이터
기계학습 구성요소
미지의 목적함수
𝑓: 𝒳→𝒴
학습 데이터
𝒙𝟏, 𝑦1 , 𝒙𝟐, 𝑦2 , … , (𝒙𝒏, 𝑦𝑛)
가설 집합
ℋ
최종 가설
𝑔≈𝑓
학습 알고리즘
𝒜
∀
입력
데이터
정답
목적
함수
𝑓
입력 공간
𝒳
출력공간
𝒴
출처: Abu-Mostafa, Y. S.; Magdon-Ismail, M. & Lin, H.-T. (2012), Learning From Data, AMLBook.
∙ 오직 신(God)만이…
∙ 끝없는 기계학습 후에도 여전히 ‘unknown’…
∙ FAANG & 네라카쿠배 협력해도…
부류= +1
부류= -1
부류= ?
84 / 125

-- PAGE 85 --

기계학습과 데이터
기계학습 구성요소
미지의 목적함수
𝑓: 𝒳→𝒴
학습 데이터
𝒙𝟏, 𝑦1 , 𝒙𝟐, 𝑦2 , … , (𝒙𝒏, 𝑦𝑛)
가설 집합
ℋ
최종 가설
𝑔≈𝑓
학습 알고리즘
𝒜
출처: Abu-Mostafa, Y. S.; Magdon-Ismail, M. & Lin, H.-T. (2012), Learning From Data, AMLBook.
85 / 125

-- PAGE 86 --

학습 알고리즘
𝒜
기계학습과 데이터
기계학습 구성요소
미지의 목적함수
𝑓: 𝒳→𝒴
학습 데이터
𝒙𝟏, 𝑦1 , 𝒙𝟐, 𝑦2 , … , (𝒙𝒏, 𝑦𝑛)
가설 집합
ℋ
최종 가설
𝑔≈𝑓
…
출처: Abu-Mostafa, Y. S.; Magdon-Ismail, M. & Lin, H.-T. (2012), Learning From Data, AMLBook.
86 / 125

-- PAGE 87 --

학습 알고리즘
𝓐
기계학습과 데이터
기계학습 구성요소
미지의 목적함수
𝑓: 𝒳→𝒴
학습 데이터
𝒙𝟏, 𝑦1 , 𝒙𝟐, 𝑦2 , … , (𝒙𝒏, 𝑦𝑛)
가설 집합
ℋ
Final hypothesis
𝑔≈𝑓
…
출처: Abu-Mostafa, Y. S.; Magdon-Ismail, M. & Lin, H.-T. (2012), Learning From Data, AMLBook.
87 / 125

-- PAGE 88 --

기계학습과 데이터
기계학습 구성요소
미지의 목적함수
𝑓: 𝒳→𝒴
학습 데이터
𝒙𝟏, 𝑦1 , 𝒙𝟐, 𝑦2 , … , (𝒙𝒏, 𝑦𝑛)
가설 집합
ℋ
최종 가설
𝑔≈𝑓
학습 알고리즘
𝒜
출처: Abu-Mostafa, Y. S.; Magdon-Ismail, M. & Lin, H.-T. (2012), Learning From Data, AMLBook.
88 / 125

-- PAGE 89 --

기계학습과 데이터
데이터 기반의 섣부른 판단
WHISKEY
VODKA
OUZO
GIN
ICE
ICE
ICE
ICE
DESTROYS
THE KIDNEYS
DESTROYS
THE LIVER
DESTROYS
THE HEART
DESTROYS
THE BRAIN
출처: https://www.facebook.com/photo.php?fbid=705350161635760&id=100064823465507&set=a.569858281851616
John Doe
@nobody
Ice         is             dangerous.
89 / 125

-- PAGE 90 --

기계학습과 데이터
데이터 기반의 섣부른 판단
91
9
60
40
45
55
34
66
43
57
사망자
중증환자
입원치료를
받은 감염자
감염
전체
0%
25%
50%
75%
100%
접종자
미접종자
마르쿠스 란츠 토크쇼(독일 제2TV, 2021년 11월)
· 감염자 60%: 백신 접종자
· 사망자 43%: 백신 접종자
백신접종
반대
출처: 게르트 기거렌처, 발터 크래머, 카타리나 슐러, 토마스 바우어우리는 왜 숫자에 속을까, 온워드, 2023. 
90 / 125

-- PAGE 91 --

기계학습과 데이터
데이터 기반의 섣부른 판단
10,000명
접종자 9,100명
미접종자 900명
감염 600명 
미감염 8,500명 
감염 400명 
미감염 500명 
· 접종자 중, 감염 비율: 
600
9,100 ≈𝟔. 𝟓%
· 미접종자 중, 감염 비율: 
400
900 ≈𝟒𝟒. 𝟒%
10,000명
접종자 9,100명
미접종자 900명
사망 43명 
생존 9,057명 
사망 57명 
생존 843명 
· 접종자 중, 사망 비율: 
43
9,100 ≈𝟎. 𝟒𝟕%
· 미접종자 중, 사망 비율: 
57
900 ≈𝟔. 𝟑𝟑%
사망자 100명 가정
감염자 1,000명 가정
출처: 게르트 기거렌처, 발터 크래머, 카타리나 슐러, 토마스 바우어우리는 왜 숫자에 속을까, 온워드, 2023. 
91 / 125

-- PAGE 92 --

기계학습과 데이터
데이터 기반의 섣부른 판단
0
1,000
2,000
3,000
4,000
5,000
6,000
7,000
8,000
9,000
전립선암 발생자 현황
발생자
1437 1304
1800 2037
2629
3390 3723
4474
5507
6564
7404
7848
전립선암 발생자 현황 출처: 중앙암등록본부·통계청
피부암
감별
인공지능소프트웨어 의료기기
모발밀도
분석
가정혈압
예측
고혈압 합병증
예측
전립선암
진단보조
2034년까지 한국 남성 전립선암 발생률 148.6% 증가 예상
국립암센터 정재영 교수 연구팀, 2022
한국 남성 4대 암: 폐암(1위), 위암(2위), 대장암(3위), 전립선암(4위)
국가암정보센터, 2021
PSA 검사의 전립선암 진단 정확도 50%~60% 수준
한국보건의료연구원, 2020
2021년 전립선암 총 진료비: 4천2백8십억('17년 대비 82.2% 증가)
국민건강보험, 2022
위험성 증가 인자: 고령, 가족력, 비만, 고지방 식사(동물 지방)
서울아산병원
92 / 125

-- PAGE 93 --

기계학습과 데이터
데이터 기반의 섣부른 판단
0
1,000
2,000
3,000
4,000
5,000
6,000
7,000
8,000
9,000
전립선암 발생자 및 사망자 현황
발생자
사망자
1437 1304
1800 2037
2629
3390 3723
4474
5507
6564
7404
7848
427
545
636
740
783
914
900
1004 1107 1168 1235 1328
10%
15%
20%
25%
30%
35%
40%
45%
전립선암 발생자 대비 사망자 비율
29.71
41.79
35.33
36.33
29.78
26.96
24.17
22.44
20.10
17.79 16.68
16.92
전립선암 발생자 현황 출처: 중앙암등록본부·통계청
93 / 125

-- PAGE 94 --

온톨로지가 기계학습을 만났을 때
94 / 125

-- PAGE 95 --

온톨로지가 기계학습을 만났을 때
온톨로지-기계학습 궁합
온톨로지
기계학습
표현수단
Symbolic concepts/entities + relations + axioms
Vectors/tensors + parameterized models
예시
SNOMED-CT(표준의료용어 체계), CIDOC CRM(문화유산 정보 교환·통합 표준)
피부암 진단보조 AI, 자율주행 AI, 피아식별 AI, 콘텐츠 추천 AI
추론방식
Logical inference based on axioms & rules
Statistical inference based on parameters & numerical computation
예시
타이레놀 제고 검색 → 제고 없음 → 동일 성분 제품 확인 → 대체 약품 추천
이미지 데이터(2D tensor) →Tensor multiplication →이미지 분류
설명력
Explicit semantics
interpretable & explainable
Latent semantics
explainability varies by model (often needs post-hoc explanation)
예시
타이레놀 <has_active_ingredient> 아세트아미노펜
아세트아미노펜 <synonym_of> 파라세타몰
파나돌 <has_active_ingredient> 파라세타몰
Class activation map
95 / 125

-- PAGE 96 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
level 1
topic 1
level 1
topic 2
…
level 1
topic 8
level 2
topic 1
level 2
topic 2
level 2
topic 44
level 2
topic 45
level 2
topic 46
level 3
topic 3
level 3
topic 2
level 3
topic 1
level 3
topic 4
level 3
topic 5
level 3
topic 6
…
level 3
topic 250
…
level 3
topic 249
level 3
topic 248
level 3
topic 247
level 3
topic 246
keyword
3
keyword
1
keyword
2
keyword
4
keyword
5
…
keyword
𝑛−1
keyword
𝑛
ODPia (Open Data Platform + utoPia) social map, 2016
상위 주제
중간 주제
하위 주제
관심 키워드
버즈량
긍/부정
관심도
평판
96 / 125

-- PAGE 97 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
level 1
topic 1
level 1
topic 2
…
level 1
topic 8
level 2
topic 1
level 2
topic 2
level 2
topic 44
level 2
topic 45
level 2
topic 46
level 3
topic 3
level 3
topic 2
level 3
topic 1
level 3
topic 4
level 3
topic 5
level 3
topic 6
…
level 3
topic 250
…
level 3
topic 249
level 3
topic 248
level 3
topic 247
level 3
topic 246
keyword
3
keyword
1
keyword
2
keyword
4
keyword
5
…
keyword
𝑛−1
keyword
𝑛
ODPia (Open Data Platform + utoPia) social map, 2016
상위 주제
중간 주제
하위 주제
관심 키워드
관심 다의어
버즈량
긍/부정
관심도
평판
인물 비
인물 수영
이미지 출처: https://www.newsen.com/news_view.php?uid=200901310018441010
https://www.sedaily.com/NewsView/1VHSSGN9SI
97 / 125

-- PAGE 98 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
• 프로젝트 정의
대상
ODPia social map 내 존재하는 다의어 집합(이하 관심 다의어)
다의어
동일한 syntax를 갖지만, 맥락에 따라 다양한 의미로 해석되는 literal
맥락
관심 다의어가 등장하는 문장/문서
목표
맥락 내 관심 다의어 중의성 해소 (이하 WSD: Word sense disambiguation)
산출물
관심 다의어 WSD 모듈 및 정량적 성능 검증 결과
𝑘𝑖
관심 다의어 𝑘𝑖 × 맥락 𝑐𝑗
관심 다의어 𝑘𝑖 × 맥락 𝑐𝑘
하위 주제 𝑡𝑙
하위 주제 𝑡𝑚
WSD 모듈
𝑔
입력 공간
𝒳
출력공간
𝒴
98 / 125

-- PAGE 99 --

• 연구실 현황 및 발주처 요구사항
연구실 현황
온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
본인
후배 A
후배 B
관심다의어: 5,610개
하위주제: 250개
중간주제: 46개
상위주제: 8개
발주처 요구사항
1. 기한(4개월) 내 가능한높은 분류 성능
2. 기한(4개월) 내 가능한 넓은 적용범위 (관심 다의어 coverage)
최소 80%
가능하다면 95%
최소 50%
약 2,300개
가능하다면 80%
약 4,500개
3. 지속 성장 가능한 파이프라인
신규
다의어
업데이트된
WSD
99 / 125

-- PAGE 100 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
1.
가능한높은 성능 
Candidates
Perceptron
ANN
Artificial Neural Network
SVM
Support Vector Machine
Tree-based algorithm
HMM
Hidden Markov Model
…
Perceptron
ANN
SVM
Tree-based algorithm
100 / 125

-- PAGE 101 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
1.
가능한높은 성능 
Candidates
Perceptron
ANN
Artificial Neural Network
SVM
Support Vector Machine
Tree-based algorithm
HMM
Hidden Markov Model
…
Perceptron
ANN
SVM
Tree-based algorithm
101 / 125

-- PAGE 102 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
1.
가능한높은 성능 
𝑥1
𝑥2
(3, 3)
(−3, 3)
(−3, −3)
(3, −3)
(1, 1)
(1, −1)
(−1, −1)
(−1, 1)
Classifier
Linear classifier
Nonlinear classifier
Perceptron
SVM
…
102 / 125

-- PAGE 103 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
1.
가능한높은 성능 
𝑥1
𝑥2
(3, 3)
(−3, 3)
(−3, −3)
(3, −3)
(1, 1)
(1, −1)
(−1, −1)
(−1, 1)
𝑥1
𝑥2
𝑥1
𝑥2
𝑥1
𝑥2
𝑥3
103 / 125

-- PAGE 104 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
𝑥1
𝑥2
(3, 3)
(−3, 3)
(−3, −3)
(3, −3)
(1, 1)
(1, −1)
(−1, −1)
(−1, 1)
𝑥1
𝑥2
𝑥3
Candidate equations for 
the new dimension 𝑥3
𝑥1 + 𝑥2
𝑥1𝑥2
𝑥12 + 𝑥22
104 / 125

-- PAGE 105 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
New dim.
Label: red
Label: blue
𝑥3
(-3, -3)
(3, -3)
(-3, 3)
(3, 3)
(-1, -1)
(1, -1)
(-1, 1)
(1, 1)
𝑥1 + 𝑥2
-6
0
0
6
-2
0
0
2
𝑥1𝑥2
9
-9
-9
9
1
-1
-1
1
𝑥12 + 𝑥22
18
18
18
18
2
2
2
2
105 / 125

-- PAGE 106 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
𝑥1
𝑥2
𝑥1
𝑥2
𝑥1
𝑥2
𝑥3
equations for 
the new dimension 𝑥3
𝑥12 + 𝑥22
𝑥12 + 𝑥22 = 18
𝑥12 + 𝑥22 = 2
106 / 125

-- PAGE 107 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
𝑥1
𝑥2
𝑥1
𝑥2
𝑥1
𝑥2
𝑥3
equations for 
the new dimension 𝑥3
𝑥12 + 𝑥22
𝑥12 + 𝑥22 = 18
𝑥12 + 𝑥22 = 2
𝑥12 + 𝑥22 = ? ?
107 / 125

-- PAGE 108 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
𝑥1
𝑥2
𝑥1
𝑥2
𝑥1
𝑥2
𝑥3
equations for 
the new dimension 𝑥3
𝑥12 + 𝑥22
𝑥12 + 𝑥22 = 18
𝑥12 + 𝑥22 = 2
𝑥12 + 𝑥22 = 10
108 / 125

-- PAGE 109 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
• Nonlinear classifier
𝑥1
𝑥2
(3, 3)
(−3, 3)
(−3, −3)
(3, −3)
(1, 1)
(1, −1)
(−1, −1)
(−1, 1)
𝑥12 + 𝑥22 = 18
𝑥12 + 𝑥22 = 2
109 / 125

-- PAGE 110 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
• Nonlinear classifier
𝑥1
𝑥2
(3, 3)
(−3, 3)
(−3, −3)
(3, −3)
(1, 1)
(1, −1)
(−1, −1)
(−1, 1)
𝑥12 + 𝑥22 = 10
110 / 125

-- PAGE 111 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
• Nonlinear classifier
𝑥1
𝑥2
(3, 3)
(−3, 3)
(−3, −3)
(3, −3)
(1, 1)
(1, −1)
(−1, −1)
(−1, 1)
𝑥12 + 𝑥22 = 18
𝑥12 + 𝑥22 = 2
𝑥12 + 𝑥22 = 10
111 / 125

-- PAGE 112 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
𝑥1
𝑥2
𝑥1
𝑥2
𝑥3
𝑥1
𝑥3 = 𝑥12 + 𝑥22
𝑥12 + 𝑥22 = 18
𝑥12 + 𝑥22 = 10
𝑥12 + 𝑥22 = 2
112 / 125

-- PAGE 113 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
• Which approach do you more prefer?
≡
113 / 125

-- PAGE 114 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
1.
가능한높은 성능 
Perceptron
ANN
Artificial Neural Network
SVM
Support Vector Machine
Tree-based algorithm
HMM
Hidden Markov Model
…
Linear kernel
Polynomial kernel
Radial basis function kernel
Sigmoid kernel
Laplacian kernel
Exponential kernel
SVM
Kernel
114 / 125

-- PAGE 115 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
1.
가능한높은 성능
•
기계학습 알고리즘 선택: SVM 
•
다의어 본질: 맥락(다의어와 함께 등장하는 단어들)
관심 다의어 𝑘𝑖 × 맥락 𝑐𝑗
관심 다의어 𝑘𝑖 × 맥락 𝑐𝑘
하위 주제 𝑡𝑙
하위 주제 𝑡𝑚
WSD 모듈
𝑔
입력 공간
𝒳
출력공간
𝒴
배우 이민호가 차기작을 확정하며 복귀 행보에 속도를 내고 있다. 제작사 측은 “이민호가 작품의 
중심축을 이끌 예정”이라며 “대본 리딩 단계부터 캐릭터 해석에 적극적으로 참여하고 있다”고 전했다.
업계에서는 이번 작품이 글로벌 플랫폼을 통한 공개를 앞두고 있는 만큼, 국내외 팬들의 관심이 집중될 
것으로 보고 있다.
NC 다이노스의 우완 투수 이민호가 선발 로테이션 한 축으로 자리잡으며 시즌 초반 안정적인 투구를
이어가고 있다. 이민호는 최근 등판에서 5이닝 2실점을 기록하며 경기 운영 능력을 입증했다. 구단 관계자는
“스트라이크 비율이 좋아졌고, 위기 상황에서 변화구 선택이 효과적이었다”며 “다음 등판에서도 투구 수 
관리가 중요할 것”이라고 설명했다.
관심 키워드
ODPia
연예
스포츠
이민호
…
115 / 125

-- PAGE 116 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
1.
가능한높은 성능
•
기계학습 알고리즘 선택: SVM 
•
다의어 본질: 맥락(다의어와 함께 등장하는 단어들)
•
다의어 '맥락' 공간으로의 사상
배우 이민호가 차기작을 확정하며 복귀 행보에 속도를 내고 있다. 제작사 측은 “이민호가 작품의 
중심축을 이끌 예정”이라며 “대본 리딩 단계부터 캐릭터 해석에 적극적으로 참여하고 있다”고 전했다.
업계에서는 이번 작품이 글로벌 플랫폼을 통한 공개를 앞두고 있는 만큼, 국내외 팬들의 관심이 집중될 
것으로 보고 있다.
스포츠
연애
맥락 예
STEP 1
공간 구성 축(특질: feature) 선정
STEP 2
거주자 이주(임베딩: embedding)
116 / 125

-- PAGE 117 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
1.
가능한높은 성능
•
기계학습 알고리즘 선택: SVM 
•
다의어 본질: 맥락(다의어와 함께 등장하는 단어들)
•
다의어 '맥락' 공간으로의 사상
1. 공간 구성 축(특질: feature) 선정
2. 거주자 이주(임베딩: embedding)
맥락
문장/문단/본문
형태소
분석 모듈
명사집합
공통 요소
추출 모듈
관심 키워드
keyword
3
keyword
1
keyword
2
keyword
4
keyword
5
…
맥락 내 
관심 키워드 집합
대응되는
LV. 3 topic
Keyword 1
topic 1
Keyword 2
topic 1
관심 다의어
don’t care
Keyword 3
topic 2 & 4
…
…
ODPia social map LV. 3 
Embedded context
dim 1
dim 2
dim 3
dim 4
…
dim 250
2
0.5
0
0.5
…
3
topic
3
topic
1
topic
2
topic
4
…
topic
250
When, Ontology met Machine learning
117 / 125

-- PAGE 118 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
2.
가능한 넓은 적용범위
다의어 수
다의어-Topic 간 평균 차수
다의어-Topic 간최소 차수
다의어-Topic 간 최대 차수
5,610
2.4
2
8
STRATAGE 1: 똑똑한 1명
8지 선다형 단일 분류기 생성
STRATAGE 2: 상황 맞춤형
차수 기반 다수 분류기 생성 
차수
LV. 3 topics
최대 차수 다의어
이태영
8
법조인
정치인
학술인/
교수
문화예술인
스포츠인
공무원/
교육인
국영/민영 
기업인
대중문화 
연예인
Rank
다의어 수
LV. 3 topics
차수
1
1,016
대중문화연예인, 문화예술인
2
2
585
공무원/교육인, 학술인/교수
2
3
250
대중문화연예인, 스포츠인
2
4
219
공무원/교육인, 문화예술인, 학술인/교수
3
…
…
…
…
118 / 125

-- PAGE 119 --

678건
온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
2.
가능한 넓은 적용범위
STRATAGE 1: 똑똑한 1명
8지 선다형 단일 분류기 생성
LV 3. topics
법조인
정치인
학술인/교수
문화예술인
스포츠인
공무원/교육인
국영/민영 기업인
대중문화연예인
327건
544건
433건
678건
1,159건
457건
676건
452건
학습 데이터
online article
SVM 기반
8부류 분류기
.
.
.
법조인
정치인
학술인/교수
대중문화연예인
발주처 요구사항
최소 50%
약 2,300개
가능하다면 80%
약 4,500개
기한(4개월) 내 가능한 넓은 적용범위 (관심 다의어 coverage)
약 64% 적용 가능 (
ൗ
𝟑,𝟓𝟗𝟎
𝟓,𝟔𝟏𝟎)
119 / 125

-- PAGE 120 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
2.
가능한 넓은 적용범위
STRATAGE 2: 상황 맞춤형
차수 기반 다수 분류기 생성 
Rank
다의어 수
LV. 3 topics
차수
1
1,016
대중문화연예인, 문화예술인
2
2
585
공무원/교육인, 학술인/교수
2
3
250
대중문화연예인, 스포츠인
2
4
219
공무원/교육인, 문화예술인, 학술인/교수
3
…
…
…
…
678건
452건
대중문화연예인
문화예술인
대중문화연예인
문화예술인
SVM 기반
2부류 분류기
학습 데이터
online article
544건
433건
공무원/교육인
학술인/교수
공무원/교육인
학술인/교수
SVM 기반
2부류 분류기
학습 데이터
online article
…
SVM 기반 분류기 12개
발주처 요구사항
최소 50%
약 2,300개
가능하다면 80%
약 4,500개
기한(4개월) 내 가능한 넓은 적용범위 (관심 다의어 coverage)
약 50% 적용 가능 (
ൗ
𝟐,𝟖𝟏𝟏
𝟓,𝟔𝟏𝟎)
120 / 125

-- PAGE 121 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
1.
가능한높은 성능
STRATAGE 1: 똑똑한 1명
8지 선다형 단일 분류기 성능(10-fold cross validation)
예측 부류
법조인
공무원/교육인
학술인/교수
대중문화연예인
문화예술인
스포츠인
정치인
국영/민영기업인
실제 부류
법조인
321
0
1
0
0
0
0
5
공무원/교육인
22
441
41
16
3
0
6
15
학술인/교수
6
16
394
4
3
0
2
8
대중문화연예인
3
156
15
367
95
0
25
17
문화예술인
10
31
29
72
949
0
21
47
스포츠인
0
0
0
0
0
457
0
0
정치인
20
57
14
15
11
83
462
14
국영/민영기업인
14
91
5
9
21
2
3
307
평균 정확도
80.3%
발주처 요구사항
최소 80%
가능하다면 95%
기한(4개월) 내 가능한높은 분류 성능
121 / 125

-- PAGE 122 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
1.
가능한높은 성능
STRATAGE 2: 상황 맞춤형
차수 기반 다수 분류기 성능(10-fold cross validation)
대중문화연예인
문화예술인
대중문화연예인
673
5
문화예술인
67
1092
공무원/교육인
학술인/교수
공무원/교육인
537
7
학술인/교수
0
433
대중문화연예인
스포츠인
대중문화연예인
677
1
스포츠인
0
457
공무원/교육인
정치인
공무원/교육인
540
4
정치인
44
632
법조인
공무원/교육인
법조인
194
133
공무원/교육인
46
498
아나운서/방송제작자
스포츠인
아나운서/방송제작자
562
1
스포츠인
0
457
6개 Binary classifier 성능
122 / 125

-- PAGE 123 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
1.
가능한높은 성능
STRATAGE 2: 상황 맞춤형
차수 기반 다수 분류기 성능(10-fold cross validation)
공무원/교육인
학술인/교수
문화예술인
공무원/교육인
536
5
3
학술인/교수
0
433
0
문화예술인
17
33
1109
대중문화연예인
문화예술인
스포츠인
대중문화연예인
671
7
0
문화예술인
73
1086
0
스포츠인
0
0
457
공무원/교육인
학술인/교수
정치인
공무원/교육인
533
8
3
학술인/교수
0
433
0
정치인
34
8
634
공무원/교육인
학술인/교수
스포츠인
공무원/교육인
534
10
0
학술인/교수
0
433
0
스포츠인
0
0
457
대중문화연예인
문화예술인
국영/민영기업인
대중문화연예인
675
1
2
문화예술인
43
1111
5
국영/민영기업인
3
2
447
5개 3-class classifier 성능
123 / 125

-- PAGE 124 --

온톨로지가 기계학습을 만났을 때
LG CNS 발주 프로젝트
1.
가능한높은 성능
STRATAGE 2: 상황 맞춤형
차수 기반 다수 분류기 성능(10-fold cross validation)
공무원/교육인
학술인/교수
대중문화연예인
문화예술인
공무원/교육인
534
5
4
1
학술인/교수
0
433
0
0
대중문화연예인
14
1
661
2
문화예술인
19
36
60
1044
1개 4-class classifier 성능
12개 classifier 평균 정확도
96.5%
발주처 요구사항
최소 80%
가능하다면 95%
기한(4개월) 내 가능한높은 분류 성능
124 / 125

-- PAGE 125 --

온톨로지 및 지식그래프: 2차 수업
When Ontology Met Machine learning
김응희
eungheekim@snu.ac.kr
2026.01.20.
감사합니다
125 / 125

==== FILE: Ontology_Design_Practice.xlsx ====


-- SHEET: Nodes --

    sort   id  label    description      mode   color value
   Class C001 Person  클래스로서, 사람의 범주    circle #99FF99      
Instance N001    홍길동      개체로서, 홍길동    circle #FF9999      
Property P001   name 속성으로서, 개체의 대표명 rectangle #FFCC00      

-- SHEET: Edges --

sourceID targetID     relation relationType
    N001     C001   instanceOf        개체-범주
    N001     P001 hasAttribute        개체-속성

==== FILE: 참고 자원.xlsx ====


-- SHEET: Resource --

Unnamed: 0 Unnamed: 1                                         대상           유형                                            내용                                                                   URL
                                                                                                                                                                                                 
                                          DH Edu Project Archive     학부 정규 강의           온톨로지 기반 디지털 인문학 강의(고려대, 경희대, 동국대 등)                        https://dh.aks.ac.kr/~jisun/edu/index.php/Main
                                                서울특별시 공원의 탄생과 역사  학부 정규 강의 과제         2023년 1학기 고려대 문과대학 "데이터인문학" 강의 과제 결과물          https://dh.aks.ac.kr/~jisun/edu/index.php/TeamWhenComingKU23
                                              데이터로 읽는 중국문화(2025)     학부 정규 강의                SPARQL 실습을 적용한 디지털 인문학 강의(전남대)                https://dh.aks.ac.kr/~cnudh/wiki/index.php/RCCTD(2025)
                                      중국의 게임시장의 발전:E-sports 중심으로  학부 정규 강의 과제 2025년 2학기 전남대 중어중문학과 "데이터로 읽는 중국문화" 강의 과제 결과물   https://dh.aks.ac.kr/~cnudh/wiki/index.php/RCCTD_WikiDataCuration01
                                      중국 불교의 시공간적 분포와 승려의 사회적 활동  학부 정규 강의 과제 2025년 2학기 전남대 중어중문학과 "데이터로 읽는 중국문화" 강의 과제 결과물   https://dh.aks.ac.kr/~cnudh/wiki/index.php/RCCTD_WikiDataCuration08
                                                          K-MOOC       온라인 강의                        디지털 인문학 개론(전남대, 무크 강의)       https://www.kmooc.kr/view/course/detail/18057?tm=20260119235706
                                          Wikidata Query Service            -                       Wikidata SPARQL 서비스 플랫폼                                           https://query.wikidata.org/
                                  WikiData Query 샘플: 중국 문화를 중심으로            -          데이터로 읽는 중국문화(2025) WikiData Query 샘플 https://dh.aks.ac.kr/~cnudh/wiki/index.php/RCCTD(2025)WikiDataQueries
                                                   지암일기 데이터 아카이브 디지털 인문학 프로젝트                     온톨로지를 활용한 디지털 인문학 프로젝트 사례                                               https://jiamdiary.info/
                                         지암일기 데이터 아카이브의 Ontology  인문학 온톨로지 사례                                             -                                  https://jiamdiary.info/data/datasets
                      China Biographical Database Project (CBDB) 디지털 인문학 프로젝트                     온톨로지를 활용한 디지털 인문학 프로젝트 사례                                           https://cbdb.library.sh.cn/
                                                  CBDB의 Ontology  인문학 온톨로지 사례                                             -                                        https://cbdb.library.sh.cn/ont
                                                        Enslaved 디지털 인문학 프로젝트                     온톨로지를 활용한 디지털 인문학 프로젝트 사례                                                 https://enslaved.org/
                                              Enslaved의 Ontology  인문학 온톨로지 사례                                             -                                        https://enslaved.org/ontology/
                                               O Say Can You See 디지털 인문학 프로젝트                     온톨로지를 활용한 디지털 인문학 프로젝트 사례                                        https://earlywashingtondc.org/
                                     O Say Can You See의 Ontology  인문학 온톨로지 사례                                             -                              https://earlywashingtondc.org/about/data
                                                     Linked Jazz 디지털 인문학 프로젝트                     온톨로지를 활용한 디지털 인문학 프로젝트 사례                                               https://linkedjazz.org/
                                           Linked Jazz의 Ontology  인문학 온톨로지 사례                                             -                                           https://linkedjazz.org/api/

==== FILE: 조별 구성.xlsx ====


-- SHEET: Team --

Unnamed: 0 Unnamed: 1         전공 전공계열 조별구성  성명 성별 Unnamed: 7       전공.1 전공계열.1 조별구성.1 성명.1 성별.1
                                                                                               
                            언어학과   언어  1.0 강규진 여성                  통계학과    통계학    5.0  김승원   여성
                          경제통상학부 사회과학  1.0 강수아 여성                  통계학과    통계학    5.0  남승빈   남성
                            통계학과  통계학  1.0 공의찬 남성                컴퓨터공학부    컴퓨터    5.0  박영민   남성
                          컴퓨터교육과  컴퓨터  1.0 구성은 여성                   법학과   사회과학    5.0  이동희   여성
                          컴퓨터과학부  컴퓨터  1.0 김동현 남성                첨단융합학부     기타    5.0  이현서   남성
                         IT정보공학과 기타공학  1.0 김선재 남성                컴퓨터공학과    컴퓨터    5.0  장은서   여성
                            통계학과  통계학  2.0 권도은 여성                컴퓨터과학부    컴퓨터    6.0  박준서   남성
                             법학과 사회과학  2.0 권찬결 남성            산업정보시스템공학과   기타공학    6.0  임정은   여성
                          컴퓨터공학부  컴퓨터  2.0 김태운 남성                   법학과   사회과학    6.0  전민준   남성
                       생물산업기계공학과 기타공학  2.0 박성은 여성                  통계학과    통계학    6.0  정윤주   여성
                         언어인지과학과   언어  2.0 우서연 여성                컴퓨터공학부    컴퓨터    6.0  주진희   여성
                          컴퓨터공학부  컴퓨터  2.0 이유준 남성                컴퓨터과학부    컴퓨터    6.0  한재훈   남성
                            통계학과  통계학  3.0 김민서 여성                   사학과     기타    7.0  박범준   남성
                          컴퓨터과학부  컴퓨터  3.0 김현수 남성             컴퓨터공학/경영학    컴퓨터    7.0  서동보   남성
                             법학과 사회과학  3.0 민유정 여성                  통계학과    통계학    7.0  서예진   여성
                         전기정보공학부 기타공학  3.0 박세환 남성                컴퓨터공학부    컴퓨터    7.0  소경한   남성
                          컴퓨터공학과  컴퓨터  3.0 변아연 여성                 건축공학과   기타공학    7.0  한정인   여성
                         언어인지과학과   언어  3.0 유수빈 여성               컴퓨터과학전공    컴퓨터    8.0  김성희   여성
                            통계학과  통계학  4.0 김진혁 남성                융합인재학부     기타    8.0  백형준   남성
                          컴퓨터교육과  컴퓨터  4.0 김혜성 남성                  통계학과    통계학    8.0  유도현   남성
                      컴퓨터인공지능공학부  컴퓨터  4.0 안시은 여성             컴퓨터공학/경영학    컴퓨터    8.0  이지우   남성
                          ELLT학과   언어  4.0 이나연 여성                컴퓨터과학부    컴퓨터    8.0  황수진   남성
                         식물생산과학부   기타  4.0 이수아 여성                임상병리학과     기타    8.0  황윤주   여성
                            공통학과 사회과학  4.0 이원준 남성                                              

==== FILE: 온톨로지 시각화 툴ver.02_다이렉트.ipynb ====

# 1. 필수 라이브러리 설치 및 임포트

!pip install pyvis gspread google-auth



import pandas as pd

import networkx as nx

from pyvis.network import Network

from google.colab import auth

import gspread

from google.auth import default
# 2. 구글 시트 인증 및 데이터 불러오기

auth.authenticate_user()

creds, _ = default()

gc = gspread.authorize(creds)



# --- 구글 시트 파일 이름 입력 ---

spreadsheet_name = 'Ontology_Design_Practice'

# -------------------------------------------------------



doc = gc.open(spreadsheet_name)



# nodes 시트 로드

nodes_df = pd.DataFrame(doc.worksheet('Nodes').get_all_records())

# edges 시트 로드

edges_df = pd.DataFrame(doc.worksheet('Edges').get_all_records())
# 3. NetworkX 유향 그래프(DiGraph) 객체 생성

G = nx.DiGraph()
# 4. 노드 추가 (속성 포함)

for _, row in nodes_df.iterrows():

    G.add_node(

        str(row['id']),              # 고유 ID (문자열 변환)

        label=str(row['label']),     # 화면에 표시될 이름

        title=str(row['description']), # 마우스 오버 시 표시될 설명

        color=row['color'],          # 노드 색상

        shape=row['mode'],           # 노드 모양 (ellipse, box, database 등)

        group=row['sort']            # 클래스/인스턴스 등 구분용 그룹

    )
# 5. 엣지(관계) 추가 (속성 포함)

for _, row in edges_df.iterrows():

    G.add_edge(

        str(row['sourceID']),

        str(row['targetID']),

        label=str(row['relation']),  # 선 위에 표시될 관계 명칭

        title=str(row['relationType']) # 마우스 오버 시 표시될 관계 유형

    )
# 6. Pyvis 시각화 설정

# notebook=True와 cdn_resources='remote' 설정

nt = Network(

    height='700px',

    width='100%',

    bgcolor='#ffffff',

    font_color='black',

    directed=True,

    notebook=True,           # 코랩/주피터 환경 명시

    cdn_resources='remote'   # 자바스크립트 라이브러리 온라인 호출

)



# NetworkX 그래프를 Pyvis로 변환

nt.from_nx(G)
# 7. 결과 출력

nt.show_buttons(filter_=['physics'])

output_filename = 'ontology_graph.html'



# 코랩에서는 show() 함수를 호출할 때 파일 이름을 인자로 넣는다

nt.show(output_filename)



# nt.show()로 바로 출력되지 않을 경우 대비 강제 출력 코드

from IPython.display import HTML

HTML(filename=output_filename)

==== FILE: 온톨로지 시각화 툴ver.01_다운로드.ipynb ====

# 1. 필수 라이브러리 설치 및 임포트

!pip install pyvis gspread google-auth



import pandas as pd

import networkx as nx

from pyvis.network import Network

from google.colab import auth

import gspread

from google.auth import default
# 2. 구글 시트 인증 및 데이터 불러오기

auth.authenticate_user()

creds, _ = default()

gc = gspread.authorize(creds)



# --- [수정 포인트] 본인의 구글 시트 파일 이름을 입력하세요 ---

spreadsheet_name = 'Ontology_Design_Practice'

# -------------------------------------------------------



doc = gc.open(spreadsheet_name)



# nodes 시트 로드

nodes_df = pd.DataFrame(doc.worksheet('Nodes').get_all_records())

# edges 시트 로드

edges_df = pd.DataFrame(doc.worksheet('Edges').get_all_records())
# 3. NetworkX 유향 그래프(DiGraph) 객체 생성

G = nx.DiGraph()
# 4. 노드 추가 (속성 포함)

for _, row in nodes_df.iterrows():

    G.add_node(

        str(row['id']),              # 고유 ID (문자열 변환)

        label=str(row['label']),     # 화면에 표시될 이름

        title=str(row['description']), # 마우스 오버 시 표시될 설명

        color=row['color'],          # 노드 색상

        shape=row['mode'],           # 노드 모양 (ellipse, box, database 등)

        group=row['sort']            # 클래스/인스턴스 등 구분용 그룹

    )
# 5. 엣지(관계) 추가 (속성 포함)

for _, row in edges_df.iterrows():

    G.add_edge(

        str(row['sourceID']),

        str(row['targetID']),

        label=str(row['relation']),  # 선 위에 표시될 관계 명칭

        title=str(row['relationType']) # 마우스 오버 시 표시될 관계 유형

    )
# 6. Pyvis를 이용한 시각화 구현

# 높이 800px, 너비 100%, 배경 흰색, 유향 그래프 설정

nt = Network(height='800px', width='100%', bgcolor='#ffffff', font_color='black', directed=True)



# NetworkX 그래프를 Pyvis로 변환

nt.from_nx(G)



# 그래프 레이아웃 및 물리 엔진 설정 (노드 간격 조정)

nt.force_atlas_2based()

nt.show_buttons(filter_=['physics']) # 실행 화면 하단에서 물리 설정을 조절할 수 있게 함
# 7. 결과 출력 (HTML 파일 생성 및 표시)

output_filename = 'ontology_graph.html'

nt.save_graph(output_filename)



from IPython.display import HTML

HTML(filename=output_filename)
